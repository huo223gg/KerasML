{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 4837.6480 - val_loss: 510.9326\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 263.6134 - val_loss: 240.9141\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 217.4787 - val_loss: 223.0151\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 318us/step - loss: 170.1844 - val_loss: 216.3578\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 310us/step - loss: 134.2370 - val_loss: 149.5183\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 99.3641 - val_loss: 123.1439\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 323us/step - loss: 79.0249 - val_loss: 121.5360\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 67.6122 - val_loss: 105.7995\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 47.7105 - val_loss: 95.4169\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 36.6007 - val_loss: 111.1832\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 27.5832 - val_loss: 88.2315\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 24.4165 - val_loss: 88.4551\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 20.6896 - val_loss: 83.8670\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 12.9104 - val_loss: 87.4919\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 9.5603 - val_loss: 81.5807\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 7.0309 - val_loss: 79.6421\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 297us/step - loss: 5.0300 - val_loss: 82.7981\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 3.8297 - val_loss: 79.2423\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 2.8747 - val_loss: 78.4986\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 2.9121 - val_loss: 76.5824\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.7931 - val_loss: 77.1072\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 320us/step - loss: 1.7374 - val_loss: 78.7898\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 1.1288 - val_loss: 78.2247\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 0.8453 - val_loss: 78.2141\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.6900 - val_loss: 82.6703\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.8379 - val_loss: 79.7977\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 0.6225 - val_loss: 78.4680\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 0.3693 - val_loss: 78.4713\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.2300 - val_loss: 78.6848\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.1984 - val_loss: 77.7533\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.1639 - val_loss: 78.1159\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 304us/step - loss: 0.3719 - val_loss: 80.7616\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 0.3974 - val_loss: 79.2167\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 1s 358us/step - loss: 0.4359 - val_loss: 79.0738\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 0.7650 - val_loss: 78.6691\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 1.5311 - val_loss: 77.8847\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 1.9504 - val_loss: 84.0054\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 1.6292 - val_loss: 80.0276\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 3.3898 - val_loss: 81.7638\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 3.4966 - val_loss: 92.4915\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 6.1890 - val_loss: 81.8304\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 316us/step - loss: 5.5988 - val_loss: 80.1966\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 19.8268 - val_loss: 79.5331\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 10.5736 - val_loss: 84.3090\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 7.4087 - val_loss: 81.3890\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 5.6081 - val_loss: 84.1070\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 2.5085 - val_loss: 83.2502\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 1.3393 - val_loss: 78.5976\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 1.7151 - val_loss: 81.9225\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 1s 337us/step - loss: 1.0768 - val_loss: 80.0249\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 2.0038 - val_loss: 78.9694\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 326us/step - loss: 1.1855 - val_loss: 78.6992\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.3065 - val_loss: 83.6304\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 3.3941 - val_loss: 78.4674\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 1.7375 - val_loss: 80.8248\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.2819 - val_loss: 78.2372\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.7683 - val_loss: 79.7831\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 0.6244 - val_loss: 79.8615\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.9527 - val_loss: 79.5181\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 1.2219 - val_loss: 78.4238\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 3.2647 - val_loss: 83.2548\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 2.5082 - val_loss: 78.2532\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 8.7089 - val_loss: 111.1436\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 12.5318 - val_loss: 95.4552\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 11.8682 - val_loss: 87.6404\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 11.7014 - val_loss: 88.3996\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 299us/step - loss: 12.6054 - val_loss: 85.2612\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 17.5699 - val_loss: 103.0095\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 309us/step - loss: 14.2676 - val_loss: 96.9837\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 6.8368 - val_loss: 78.8285\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 3.6050 - val_loss: 78.6471\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 306us/step - loss: 1.6793 - val_loss: 81.1758\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 3.2273 - val_loss: 81.9513\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 3.5031 - val_loss: 80.1018\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 1.2883 - val_loss: 81.3775\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.7273 - val_loss: 79.8389\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.3417 - val_loss: 78.6490\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.2576 - val_loss: 79.5636\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.2336 - val_loss: 80.1106\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.3026 - val_loss: 78.4826\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 331us/step - loss: 0.2425 - val_loss: 79.3931\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 1s 351us/step - loss: 0.2230 - val_loss: 80.1557\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 0.2663 - val_loss: 79.6246\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.3441 - val_loss: 77.4622\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.2875 - val_loss: 78.8280\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 306us/step - loss: 0.7893 - val_loss: 79.5797\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 326us/step - loss: 1.1486 - val_loss: 79.4589\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.9504 - val_loss: 78.4700\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 1s 338us/step - loss: 6.4535 - val_loss: 79.9431\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 17.9142 - val_loss: 81.9995\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 12.9860 - val_loss: 108.9976\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 20.8853 - val_loss: 83.6018\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 8.1154 - val_loss: 83.2359\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 4.4577 - val_loss: 79.8003\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 2.4180 - val_loss: 77.6734\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 4.2706 - val_loss: 82.9199\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 5.4969 - val_loss: 83.7371\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 3.5907 - val_loss: 76.8740\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 2.3288 - val_loss: 80.2884\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 1.6149 - val_loss: 77.7355\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 0.9539 - val_loss: 78.1358\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 0.6160 - val_loss: 77.6103\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.5438 - val_loss: 78.2899\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 0.5011 - val_loss: 78.7572\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.9154 - val_loss: 77.1522\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.9707 - val_loss: 80.9195\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.2769 - val_loss: 79.0192\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.3951 - val_loss: 78.9302\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 0.9032 - val_loss: 82.9189\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 3.4099 - val_loss: 78.5991\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 4.7835 - val_loss: 77.8197\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 322us/step - loss: 7.2266 - val_loss: 92.0111\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 8.5308 - val_loss: 80.4589\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 3.8580 - val_loss: 96.6381\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 1s 355us/step - loss: 6.2088 - val_loss: 80.1722\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 318us/step - loss: 3.1441 - val_loss: 81.3058\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 6.0213 - val_loss: 82.6848\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 6.3805 - val_loss: 79.2921\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 297us/step - loss: 3.0765 - val_loss: 79.1418\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 317us/step - loss: 2.9073 - val_loss: 80.1483\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 2.2439 - val_loss: 80.5157\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 1.8390 - val_loss: 79.2535\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 322us/step - loss: 1.4534 - val_loss: 80.7497\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 320us/step - loss: 0.6131 - val_loss: 78.6867\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.4574 - val_loss: 80.6062\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 1.1450 - val_loss: 81.1776\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.9134 - val_loss: 79.1662\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.8088 - val_loss: 78.1484\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 1.2441 - val_loss: 79.3678\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 2.0019 - val_loss: 80.6282\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 4.0693 - val_loss: 79.1778\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 1.7263 - val_loss: 79.2374\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 1.7185 - val_loss: 81.7607\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 7.0309 - val_loss: 82.5977\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 3.1510 - val_loss: 80.7968\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 3.1693 - val_loss: 81.2311\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 2.4268 - val_loss: 79.3807\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.8055 - val_loss: 79.7303\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 2.0155 - val_loss: 78.6738\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 2.1456 - val_loss: 78.2455\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 1.2156 - val_loss: 78.9286\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 1.2682 - val_loss: 78.3337\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 1.5680 - val_loss: 81.6959\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 5.2880 - val_loss: 86.6295\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 300us/step - loss: 9.5472 - val_loss: 87.0226\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 4.9459 - val_loss: 83.8874\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 4.5575 - val_loss: 80.1156ETA: 0s - loss: 4.86\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 5.8059 - val_loss: 81.0061\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 3.6159 - val_loss: 82.3735\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 2.5029 - val_loss: 81.6589\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 307us/step - loss: 1.8477 - val_loss: 80.9358\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 2.4122 - val_loss: 82.4299\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 330us/step - loss: 2.1146 - val_loss: 86.7483\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 4.7782 - val_loss: 86.4460\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 2.5351 - val_loss: 81.8014\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 2.4534 - val_loss: 82.5076\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 2.4635 - val_loss: 82.6400\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 313us/step - loss: 1.6927 - val_loss: 82.4633\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 2.3107 - val_loss: 82.7380\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 2.8562 - val_loss: 78.5429\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 2.1137 - val_loss: 79.5962\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 1.7908 - val_loss: 81.6105\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 1.5926 - val_loss: 85.2937\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 1.0274 - val_loss: 80.3398\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 2.2761 - val_loss: 79.7860\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 2.1509 - val_loss: 80.5202\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 2.4245 - val_loss: 87.6081\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 3.6403 - val_loss: 82.1621\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 1.4764 - val_loss: 82.0437\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 2.3741 - val_loss: 80.5205\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 2.3977 - val_loss: 98.9997\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 17.0128 - val_loss: 84.1539\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 17.8512 - val_loss: 104.4104\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 17.0311 - val_loss: 84.9852\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 5.6321 - val_loss: 89.6206\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 4.4312 - val_loss: 85.6273\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 2.4897 - val_loss: 84.2367\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 1.2189 - val_loss: 81.1548\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.7981 - val_loss: 80.3966\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.6374 - val_loss: 82.9738\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 1s 335us/step - loss: 0.4903 - val_loss: 80.3757\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.2756 - val_loss: 80.9071\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.2712 - val_loss: 80.6780\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.1924 - val_loss: 79.2120\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.4868 - val_loss: 79.5234\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.2410 - val_loss: 79.4660\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 299us/step - loss: 0.1279 - val_loss: 79.1593\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 0.1784 - val_loss: 80.5071\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.1869 - val_loss: 79.5361\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.5928 - val_loss: 82.2533\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.5491 - val_loss: 79.4846\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.6564 - val_loss: 81.9114\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.1031 - val_loss: 80.2858\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.4569 - val_loss: 80.4879\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 0.2662 - val_loss: 81.0759\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.5475 - val_loss: 79.5164\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.3415 - val_loss: 81.8089\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.9387 - val_loss: 85.8418\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 2.0224 - val_loss: 81.1602\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 8.3612 - val_loss: 86.6523\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 7.5591 - val_loss: 85.7969\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 3.0964 - val_loss: 83.9725\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 4.4049 - val_loss: 79.8076\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 5.6704 - val_loss: 94.8312\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 4.0509 - val_loss: 80.1930\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 315us/step - loss: 2.5651 - val_loss: 81.2456\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 1.4077 - val_loss: 80.1691\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 313us/step - loss: 2.0565 - val_loss: 80.9754\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 1.4072 - val_loss: 78.1725\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.7015 - val_loss: 78.0906\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 0.5212 - val_loss: 79.8822\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.3626 - val_loss: 78.4835\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.3192 - val_loss: 79.7203\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.2736 - val_loss: 79.3958\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.1846 - val_loss: 79.3266\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.1308 - val_loss: 79.0844\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.2459 - val_loss: 79.7316\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 0.3077 - val_loss: 80.4045\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 299us/step - loss: 0.5822 - val_loss: 78.5560\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 2.6232 - val_loss: 84.4269\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 21.9380 - val_loss: 124.6432\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 18.3761 - val_loss: 80.9593\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 6.1881 - val_loss: 79.7582\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 3.7813 - val_loss: 80.4339\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 3.2083 - val_loss: 81.4631\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 305us/step - loss: 2.4289 - val_loss: 82.4557\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 310us/step - loss: 1.2361 - val_loss: 80.4565\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 1.0771 - val_loss: 80.0825\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.7021 - val_loss: 81.8328\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.4673 - val_loss: 80.4045\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.3006 - val_loss: 79.9026\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 0.5694 - val_loss: 80.3958\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 309us/step - loss: 0.3099 - val_loss: 79.4147\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.3503 - val_loss: 79.9887\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.2745 - val_loss: 79.7530\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.9418 - val_loss: 79.9777\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 0.6168 - val_loss: 80.7159\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.3714 - val_loss: 79.9130\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 310us/step - loss: 0.2272 - val_loss: 81.4245\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.2634 - val_loss: 79.8035\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.1481 - val_loss: 79.5748\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.1165 - val_loss: 79.3036\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.2405 - val_loss: 81.7433\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.1775 - val_loss: 80.6383\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.1356 - val_loss: 79.8847\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 0.0945 - val_loss: 79.4548\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.1334 - val_loss: 80.8663\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.6745 - val_loss: 78.5147\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.6981 - val_loss: 80.1674\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 326us/step - loss: 2.5998 - val_loss: 81.9513\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 4.5431 - val_loss: 88.4217\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 14.1714 - val_loss: 79.6764\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 6.9338 - val_loss: 82.7780\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 5.0313 - val_loss: 79.7868\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 6.6628 - val_loss: 83.9482\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 4.1736 - val_loss: 85.8826\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 2.5732 - val_loss: 81.9253\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 3.5081 - val_loss: 85.8553\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 2.9283 - val_loss: 80.6486\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 1.4558 - val_loss: 81.6554\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.0124 - val_loss: 85.3295\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 2.0689 - val_loss: 79.6034\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 1.1918 - val_loss: 79.3499\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.9762 - val_loss: 80.0856\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 1.0413 - val_loss: 80.8418\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.4729 - val_loss: 81.2380\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.8078 - val_loss: 84.1707\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 0.7874 - val_loss: 81.1624\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.4179 - val_loss: 80.1842\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.4339 - val_loss: 80.7668\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.2951 - val_loss: 79.3832\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.1767 - val_loss: 81.3133\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.1732 - val_loss: 80.2076\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.1153 - val_loss: 80.3043\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.0832 - val_loss: 80.2952\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.1034 - val_loss: 80.5220\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 0.0661 - val_loss: 80.3573\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.1369 - val_loss: 80.5433\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.1532 - val_loss: 80.7970\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.1361 - val_loss: 79.8803\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.4341 - val_loss: 80.6492\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.4386 - val_loss: 80.8328\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 1.2177 - val_loss: 83.3946\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 1.6850 - val_loss: 84.5841\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 7.3094 - val_loss: 87.7086\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 6.6585 - val_loss: 89.4938\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 6.4847 - val_loss: 93.1009\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 5.2504 - val_loss: 87.4770\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 2.4014 - val_loss: 80.0917\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 1.6127 - val_loss: 81.1259\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 1.1284 - val_loss: 83.9354\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 1.1457 - val_loss: 78.6506\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 1.1728 - val_loss: 85.3196\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.8691 - val_loss: 79.2413\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.7586 - val_loss: 80.6442\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 1.0263 - val_loss: 80.1506\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 1.2791 - val_loss: 84.0276\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 2.2791 - val_loss: 87.5499\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 1.955 - 0s 274us/step - loss: 1.9229 - val_loss: 84.3486\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 3.1347 - val_loss: 79.1183\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 280us/step - loss: 1.9165 - val_loss: 81.2630\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 10.5894 - val_loss: 98.7228\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 10.7887 - val_loss: 84.9494\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 4.2331 - val_loss: 87.6753\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 1.7353 - val_loss: 78.4385\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 1.0335 - val_loss: 79.7419\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 1.3496 - val_loss: 79.4376\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.5302 - val_loss: 80.2679\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.4501 - val_loss: 79.4913\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 0.3359 - val_loss: 80.5792\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 304us/step - loss: 0.1738 - val_loss: 79.8924\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 310us/step - loss: 0.1362 - val_loss: 81.0560\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.1331 - val_loss: 80.2642\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 323us/step - loss: 0.0833 - val_loss: 81.2516\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.1177 - val_loss: 80.3739\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 314us/step - loss: 0.2000 - val_loss: 80.0693\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.1384 - val_loss: 79.6820\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.3400 - val_loss: 80.2826\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.2690 - val_loss: 79.0920\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.1970 - val_loss: 80.6218\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.1755 - val_loss: 80.6201\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.3372 - val_loss: 79.3779\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.2252 - val_loss: 80.8474\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.2357 - val_loss: 81.0269\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 0.2043 - val_loss: 80.4284\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.3982 - val_loss: 80.4182\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.6438 - val_loss: 80.8695\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.9361 - val_loss: 81.2355\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 4.4749 - val_loss: 80.7248\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 5.6231 - val_loss: 80.6099\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 331us/step - loss: 7.9499 - val_loss: 77.2563\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 5.3909 - val_loss: 89.1443\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 5.6186 - val_loss: 83.4309\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 4.9661 - val_loss: 83.5600\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 2.7438 - val_loss: 78.4607\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.5608 - val_loss: 82.3017\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 1.0462 - val_loss: 80.0093\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.9319 - val_loss: 78.8444\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.4472 - val_loss: 79.9686\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.4868 - val_loss: 81.4968\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.4443 - val_loss: 80.3353\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.2528 - val_loss: 80.2889\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.2045 - val_loss: 79.4272\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.1468 - val_loss: 79.5527\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 0.1166 - val_loss: 80.1580\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 315us/step - loss: 0.1554 - val_loss: 79.6877\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.1813 - val_loss: 80.3727\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 0.1625 - val_loss: 79.8914\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.0946 - val_loss: 79.6025\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.0688 - val_loss: 80.1009\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 0.0632 - val_loss: 80.4443\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.0740 - val_loss: 80.2636\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.0924 - val_loss: 79.5213\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.1258 - val_loss: 79.9271\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.6925 - val_loss: 89.2106\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 2.1867 - val_loss: 81.6061\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 1.9325 - val_loss: 83.9822\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 316us/step - loss: 3.7355 - val_loss: 84.6970\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 4.9236 - val_loss: 89.5038\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 5.2097 - val_loss: 77.6644\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 3.8019 - val_loss: 80.4128\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 2.3047 - val_loss: 81.5027\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 1.9262 - val_loss: 79.2084\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.9786 - val_loss: 78.8807\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.6473 - val_loss: 81.4551\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.5308 - val_loss: 79.9961\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.4743 - val_loss: 79.3006\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.7581 - val_loss: 79.8814\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.3482 - val_loss: 79.5324\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.4878 - val_loss: 81.6763\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.3590 - val_loss: 80.0841\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.2494 - val_loss: 79.7696\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.2378 - val_loss: 80.0082\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.3621 - val_loss: 79.8312\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.2718 - val_loss: 80.4324\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 297us/step - loss: 0.7453 - val_loss: 83.6090\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 1.5800 - val_loss: 81.9243\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 2.2570 - val_loss: 82.4144\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 1.6462 - val_loss: 80.9754\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 2.1660 - val_loss: 83.6954\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 3.2123 - val_loss: 79.9847\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 1.4504 - val_loss: 80.4855\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 328us/step - loss: 1.8356 - val_loss: 80.0120\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 325us/step - loss: 1.6785 - val_loss: 84.6356\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 2.7776 - val_loss: 82.9111\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 1.9999 - val_loss: 80.3656\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 318us/step - loss: 3.2400 - val_loss: 79.4289\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 1.2450 - val_loss: 80.4764\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 0.7227 - val_loss: 80.8494\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.5561 - val_loss: 81.0698\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 0.6414 - val_loss: 80.3590\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.5701 - val_loss: 80.3923\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 1.2951 - val_loss: 80.5879\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 1.0196 - val_loss: 80.5275\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 321us/step - loss: 0.9257 - val_loss: 80.5680\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.7816 - val_loss: 82.6658\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.7927 - val_loss: 84.7845\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 1.7400 - val_loss: 80.9792\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.8268 - val_loss: 81.3896\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.2502 - val_loss: 80.7788\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 1.2085 - val_loss: 79.6221\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 1.3289 - val_loss: 80.6988\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 1.0376 - val_loss: 80.6276\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.8346 - val_loss: 83.5875\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 2.696 - 0s 248us/step - loss: 3.0418 - val_loss: 80.2697\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 2.6180 - val_loss: 80.5910\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 1.4373 - val_loss: 81.2808\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 1.9338 - val_loss: 82.1445\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 2.0786 - val_loss: 81.1151\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 2.0866 - val_loss: 81.8475\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 1.0384 - val_loss: 82.1736\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.6196 - val_loss: 80.2151\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.9603 - val_loss: 81.7188\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 0.9375 - val_loss: 80.0960\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.5486 - val_loss: 79.8256\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 0.4898 - val_loss: 80.9793\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.7723 - val_loss: 83.3593\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 5.4315 - val_loss: 81.1097\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 322us/step - loss: 7.9669 - val_loss: 85.1465\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 3.3406 - val_loss: 81.7063\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 2.3648 - val_loss: 84.1736\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 1.6089 - val_loss: 82.3929\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 1.6277 - val_loss: 81.5997\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 0.5900 - val_loss: 80.2350\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.5113 - val_loss: 80.8879\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 325us/step - loss: 0.3881 - val_loss: 80.6933\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 1.3969 - val_loss: 79.3048\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 1.1854 - val_loss: 81.3430\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 1.2563 - val_loss: 80.3652\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.6290 - val_loss: 81.2985\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.3245 - val_loss: 80.7812\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 0.3361 - val_loss: 82.5843\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.2422 - val_loss: 80.8356\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.1361 - val_loss: 82.0638\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.0805 - val_loss: 80.4492\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.1365 - val_loss: 80.5487\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.2016 - val_loss: 80.6535\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.1110 - val_loss: 80.9343\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.1548 - val_loss: 80.8085\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.3941 - val_loss: 80.5884\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 2.4123 - val_loss: 80.4875\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 6.9678 - val_loss: 83.5659\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 5.1333 - val_loss: 95.1405\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 7.7988 - val_loss: 82.9190\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 3.1806 - val_loss: 79.6840\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 1.6291 - val_loss: 80.5944\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 317us/step - loss: 1.0148 - val_loss: 80.6155\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.5622 - val_loss: 80.7047\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.3305 - val_loss: 79.8355\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.2819 - val_loss: 81.4289\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.1982 - val_loss: 80.3188\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.1844 - val_loss: 80.3300\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.2770 - val_loss: 80.7379\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.1860 - val_loss: 80.9132\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.1422 - val_loss: 80.6420\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.1176 - val_loss: 81.1862\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.0628 - val_loss: 80.7519\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.0489 - val_loss: 80.8881\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.0763 - val_loss: 80.9968\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.1374 - val_loss: 80.1403\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.4234 - val_loss: 80.2441\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 1.2455 - val_loss: 81.4517\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.9553 - val_loss: 80.3554\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.7843 - val_loss: 80.5620\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.9665 - val_loss: 80.5093\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.9897 - val_loss: 81.7639\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.8480 - val_loss: 80.8795\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.8274 - val_loss: 83.0985\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 1.9870 - val_loss: 81.6670\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 1.0458 - val_loss: 80.7598\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.6805 - val_loss: 81.8743\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.6110 - val_loss: 81.5968\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 2.0782 - val_loss: 88.6554\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 8.1883 - val_loss: 83.9610\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 3.1499 - val_loss: 79.4400\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 1.1894 - val_loss: 83.8555\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 1.2919 - val_loss: 78.3753\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 320us/step - loss: 2.6196 - val_loss: 82.5897\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 2.9455 - val_loss: 77.3532\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 1.8184 - val_loss: 80.8917\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.9338 - val_loss: 80.2309\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.5727 - val_loss: 80.2026\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.4281 - val_loss: 80.2010\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.8900 - val_loss: 80.7246\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.4219 - val_loss: 80.8566\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 0.2055 - val_loss: 80.6585\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.1256 - val_loss: 80.2988\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 300us/step - loss: 0.2171 - val_loss: 80.3882\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.1832 - val_loss: 80.3831\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 318us/step - loss: 0.5106 - val_loss: 79.7586\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 0.4870 - val_loss: 79.8680\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 0.9165 - val_loss: 80.4801\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 1.0973 - val_loss: 80.5398\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 319us/step - loss: 1.3261 - val_loss: 81.3384\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 1.0448 - val_loss: 80.0914\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 1.6064 - val_loss: 81.5019\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 1.4271 - val_loss: 79.6702\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.9093 - val_loss: 80.4490\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.5228 - val_loss: 81.6177\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 0.5770 - val_loss: 79.9460\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.7004 - val_loss: 81.0510\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.4154 - val_loss: 80.3821\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 0.4663 - val_loss: 81.5014\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.3908 - val_loss: 82.0248\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.3369 - val_loss: 81.5506\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.4658 - val_loss: 80.0426\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 0.7634 - val_loss: 80.3117\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 1.4663 - val_loss: 80.8313\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 3.8583 - val_loss: 84.6155\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 3.7009 - val_loss: 82.4902\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 4.7403 - val_loss: 81.8143\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 3.8645 - val_loss: 87.3568\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 5.9750 - val_loss: 81.7600\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 2.5634 - val_loss: 82.9092\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 1.1573 - val_loss: 80.0861\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 0.9047 - val_loss: 79.6642\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.5263 - val_loss: 79.2018\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 299us/step - loss: 0.5105 - val_loss: 80.4202\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.2235 - val_loss: 79.2905\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.1589 - val_loss: 79.8436\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.0983 - val_loss: 79.4911\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.1483 - val_loss: 79.6625\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.1176 - val_loss: 79.7115\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 0.0673 - val_loss: 80.6876\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.0664 - val_loss: 79.8228\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.0275 - val_loss: 79.6132\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.0221 - val_loss: 79.7541\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.0218 - val_loss: 79.8125\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.0156 - val_loss: 79.5891\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.0133 - val_loss: 79.8439\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.0279 - val_loss: 79.9926\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.0288 - val_loss: 79.5197\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.029 - 0s 292us/step - loss: 0.0318 - val_loss: 79.8115\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.0637 - val_loss: 79.9846\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.0997 - val_loss: 79.2749\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.3307 - val_loss: 78.4772\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.2179 - val_loss: 79.6300\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.3152 - val_loss: 81.4429\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.4014 - val_loss: 80.0544\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 1.1472 - val_loss: 97.2820\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 8.6957 - val_loss: 85.7105\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 9.1946 - val_loss: 79.3921\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 5.0742 - val_loss: 85.0181\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 3.8414 - val_loss: 79.4474\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 1.7620 - val_loss: 80.2982\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.7912 - val_loss: 79.2673\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.4473 - val_loss: 79.9865\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.2524 - val_loss: 79.5789\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.2023 - val_loss: 79.5939\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.1244 - val_loss: 79.5163\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.1002 - val_loss: 79.5601\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.0975 - val_loss: 79.5510\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.0592 - val_loss: 79.5493\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 297us/step - loss: 0.0384 - val_loss: 79.8510\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 0.0413 - val_loss: 79.1968\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.0420 - val_loss: 79.7827\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.0286 - val_loss: 79.7837\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 0.0248 - val_loss: 79.5162\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.0572 - val_loss: 79.7327\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.0375 - val_loss: 79.5186\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.0969 - val_loss: 79.2845\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.1876 - val_loss: 79.7960\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.4541 - val_loss: 79.9944\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.5679 - val_loss: 81.3556\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.2858 - val_loss: 79.6004\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.3418 - val_loss: 83.6412\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 2.8450 - val_loss: 80.3292\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 3.6587 - val_loss: 84.4618\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 7.6947 - val_loss: 83.9624\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 2.3500 - val_loss: 79.4967\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 2.2705 - val_loss: 81.1390\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 1.4042 - val_loss: 81.8429\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.5768 - val_loss: 80.1883\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.3379 - val_loss: 81.6466\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 0.6174 - val_loss: 80.2072\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 0.5558 - val_loss: 81.3885\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.2644 - val_loss: 80.5989\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.1401 - val_loss: 79.6631\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.1337 - val_loss: 80.3347\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.1209 - val_loss: 80.2410\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.0706 - val_loss: 80.2049\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 1s 358us/step - loss: 0.0412 - val_loss: 80.2195\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.0408 - val_loss: 80.4860\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.0278 - val_loss: 80.0784\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.0258 - val_loss: 79.7484\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.0334 - val_loss: 79.9609\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.0495 - val_loss: 80.2737\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.0529 - val_loss: 80.5274\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.0926 - val_loss: 80.0515\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.6453 - val_loss: 82.6086\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.8404 - val_loss: 82.4174\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 1.2382 - val_loss: 83.5591\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 2.7380 - val_loss: 98.2828\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 3.7286 - val_loss: 82.4946\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 2.5592 - val_loss: 80.0028\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 1.9860 - val_loss: 80.9274\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 1.3457 - val_loss: 81.0467\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.9032 - val_loss: 81.3124\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.4795 - val_loss: 80.3445\n",
      "Epoch 790/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.4646 - val_loss: 81.6894ETA: 0s - loss: 0.4\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.2439 - val_loss: 81.3510\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.1266 - val_loss: 81.0850\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 0.0581 - val_loss: 80.9110\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.0529 - val_loss: 81.1240\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.0976 - val_loss: 81.8726\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.1073 - val_loss: 80.9741\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.0945 - val_loss: 80.7861\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 0.0602 - val_loss: 81.3343\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.0434 - val_loss: 81.2897\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.0987 - val_loss: 81.0487\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.0828 - val_loss: 81.9019\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.0746 - val_loss: 81.5648\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.0705 - val_loss: 81.4968\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.1094 - val_loss: 81.9533\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.4746 - val_loss: 80.7741\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 1.3143 - val_loss: 85.2939\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 2.4162 - val_loss: 84.3707\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 2.5017 - val_loss: 83.2186\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 4.0087 - val_loss: 82.4730\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 4.1013 - val_loss: 81.1206\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 1.8378 - val_loss: 82.3901\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 1.3667 - val_loss: 81.8116\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.5341 - val_loss: 82.5305\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 1.0771 - val_loss: 81.3452\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.5788 - val_loss: 82.2671\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.3798 - val_loss: 80.7547\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 0.2365 - val_loss: 81.5574\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.1100 - val_loss: 81.7469\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.0512 - val_loss: 81.3527\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.0435 - val_loss: 81.3828\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.0384 - val_loss: 81.4946\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 318us/step - loss: 0.0594 - val_loss: 81.3749\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.0576 - val_loss: 80.9082\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.0942 - val_loss: 81.2996\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.0530 - val_loss: 81.0844\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.0442 - val_loss: 81.2102\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.0677 - val_loss: 81.5540\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.8920 - val_loss: 85.0981\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 5.2834 - val_loss: 83.3564\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 2.6447 - val_loss: 81.3744\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 1.0772 - val_loss: 81.9487\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.2836 - val_loss: 83.2208\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.5476 - val_loss: 82.0222\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1849 - val_loss: 81.6062\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.1950 - val_loss: 83.5732\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.137 - 0s 270us/step - loss: 0.1298 - val_loss: 81.6534\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.0965 - val_loss: 81.5136\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.1027 - val_loss: 81.8988\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.0508 - val_loss: 81.9692\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.0546 - val_loss: 81.7573\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 0.1029 - val_loss: 81.3964\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.0889 - val_loss: 81.7152\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 283us/step - loss: 0.1547 - val_loss: 82.6362\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.1597 - val_loss: 82.3221\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 319us/step - loss: 0.1428 - val_loss: 82.4675\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 319us/step - loss: 0.1263 - val_loss: 81.5039\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 0.2756 - val_loss: 81.4447\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.7512 - val_loss: 80.8392\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.5549 - val_loss: 82.0994\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.5236 - val_loss: 81.6253\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.4099 - val_loss: 82.8499\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 2.0021 - val_loss: 85.2951\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 2.2170 - val_loss: 82.6071\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 1.0670 - val_loss: 81.3947\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.7596 - val_loss: 80.9788\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 332us/step - loss: 0.4658 - val_loss: 82.2716\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.6647 - val_loss: 81.7709\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.4463 - val_loss: 82.5425\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.3216 - val_loss: 81.9966\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 310us/step - loss: 0.3236 - val_loss: 81.5582\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 0.4126 - val_loss: 81.4088\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.4006 - val_loss: 80.3946\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.3109 - val_loss: 80.7086\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 180us/step - loss: 0.4438 - val_loss: 80.7114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 299us/step - loss: 0.5418 - val_loss: 81.1526\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.5354 - val_loss: 81.1442\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.5646 - val_loss: 82.3387\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.6105 - val_loss: 81.4610\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.6091 - val_loss: 81.9941\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.7190 - val_loss: 81.2007\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 1.2366 - val_loss: 83.2699\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 2.9431 - val_loss: 83.3552\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 2.4242 - val_loss: 82.7625\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 1.1712 - val_loss: 84.9560\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 1.1321 - val_loss: 83.9182\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.6450 - val_loss: 81.0099\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 0.5172 - val_loss: 80.6982\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.3442 - val_loss: 84.6574\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 0.8035 - val_loss: 85.2281\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.5296 - val_loss: 82.6311\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.2438 - val_loss: 81.9090\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1585 - val_loss: 81.5461\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.2003 - val_loss: 81.7154\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.2623 - val_loss: 81.3706\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.2489 - val_loss: 81.7797\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.3380 - val_loss: 82.8603\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 0.2128 - val_loss: 81.7162\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.2261 - val_loss: 83.9859\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 1.3142 - val_loss: 82.1284\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.5629 - val_loss: 85.4590\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.6214 - val_loss: 83.1576\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.3166 - val_loss: 82.8761\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 309us/step - loss: 0.3983 - val_loss: 82.1972\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.4068 - val_loss: 81.6796\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 0.1833 - val_loss: 81.6112\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.1787 - val_loss: 81.9078\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.1177 - val_loss: 82.1950\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.0768 - val_loss: 82.5547\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 316us/step - loss: 0.1432 - val_loss: 81.6989\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.1034 - val_loss: 81.4841\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1822 - val_loss: 82.2914\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 1s 349us/step - loss: 0.1684 - val_loss: 81.5317\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.5506 - val_loss: 83.9275\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 1.9824 - val_loss: 83.6842\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 2.0028 - val_loss: 81.9116\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 3.6922 - val_loss: 90.5681\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 286us/step - loss: 2.5241 - val_loss: 89.5218\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 2.2816 - val_loss: 83.0960\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 0.8264 - val_loss: 81.8548\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 0.3271 - val_loss: 82.1488\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 325us/step - loss: 0.2867 - val_loss: 83.8753\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 1s 348us/step - loss: 0.4733 - val_loss: 83.0065\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.4660 - val_loss: 82.3964\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 310us/step - loss: 0.1627 - val_loss: 81.8448\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 324us/step - loss: 0.1173 - val_loss: 82.6119\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 0.1740 - val_loss: 82.0331\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.1800 - val_loss: 82.5598\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.1115 - val_loss: 82.4435\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 1s 338us/step - loss: 0.2137 - val_loss: 82.3030\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1420 - val_loss: 82.4926\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.3918 - val_loss: 81.9592\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.3350 - val_loss: 82.0731\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.6289 - val_loss: 81.8498\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 1s 406us/step - loss: 0.3672 - val_loss: 82.3432\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.3972 - val_loss: 82.3985\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.2293 - val_loss: 81.9173\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.2216 - val_loss: 83.2250\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.1599 - val_loss: 82.1984\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.2362 - val_loss: 83.0373\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.2783 - val_loss: 81.9572\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 316us/step - loss: 0.2229 - val_loss: 82.1966\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.3692 - val_loss: 82.8622\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.5261 - val_loss: 83.1301\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.4499 - val_loss: 84.7089\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.3064 - val_loss: 83.8523\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.5767 - val_loss: 83.8203\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 0.9412 - val_loss: 87.2810\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 2.8595 - val_loss: 82.2047\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 4.4275 - val_loss: 87.1801\n",
      "Epoch 940/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 312us/step - loss: 4.1820 - val_loss: 85.1699\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 1.2788 - val_loss: 82.2485\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 1.0483 - val_loss: 85.9374\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 326us/step - loss: 0.8650 - val_loss: 83.2499\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 0.3897 - val_loss: 82.0828\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 309us/step - loss: 0.1826 - val_loss: 82.3377\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.1144 - val_loss: 82.7506\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.0884 - val_loss: 82.4071\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.0563 - val_loss: 82.7387\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.0536 - val_loss: 82.6837\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.0459 - val_loss: 82.6211\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 329us/step - loss: 0.0661 - val_loss: 82.4114\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 0.0723 - val_loss: 82.0246\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.0659 - val_loss: 82.2083\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.0606 - val_loss: 82.2212\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 315us/step - loss: 0.0327 - val_loss: 82.3095\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.0430 - val_loss: 82.3643\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.0322 - val_loss: 82.5022\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.0450 - val_loss: 82.9828\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.0438 - val_loss: 82.2236\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.0263 - val_loss: 82.4240\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.0340 - val_loss: 83.0555\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.1180 - val_loss: 82.4799\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.3694 - val_loss: 81.5097\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.4369 - val_loss: 84.1584\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 2.5153 - val_loss: 84.9210\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 3.4300 - val_loss: 88.0434\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 1.9849 - val_loss: 81.8503\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 333us/step - loss: 1.2325 - val_loss: 83.6361\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 327us/step - loss: 0.6580 - val_loss: 82.6233\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 303us/step - loss: 0.3389 - val_loss: 83.1238\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.3934 - val_loss: 83.1116\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.4907 - val_loss: 84.4311\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 0.5594 - val_loss: 84.2168\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 1s 344us/step - loss: 0.4481 - val_loss: 83.5126\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 1s 354us/step - loss: 0.5787 - val_loss: 83.4856\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 1s 341us/step - loss: 0.6596 - val_loss: 82.3820\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 1s 375us/step - loss: 0.7189 - val_loss: 81.2321\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.3756 - val_loss: 83.1747\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.5345 - val_loss: 82.1341\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 1s 394us/step - loss: 0.3411 - val_loss: 82.8694\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 1s 382us/step - loss: 0.3214 - val_loss: 83.1973\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 0.3228 - val_loss: 81.9611\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 316us/step - loss: 0.3061 - val_loss: 82.3112\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 1.0304 - val_loss: 80.7191\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.8414 - val_loss: 83.3432\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 305us/step - loss: 0.9084 - val_loss: 82.2446\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.4685 - val_loss: 81.8604\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 292us/step - loss: 0.3625 - val_loss: 82.9160\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.4391 - val_loss: 83.4041\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 320us/step - loss: 0.2220 - val_loss: 82.4197\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 0.4381 - val_loss: 82.1349\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.3142 - val_loss: 82.2773\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.2940 - val_loss: 82.4303\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 312us/step - loss: 0.2040 - val_loss: 82.2721\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.7973 - val_loss: 84.0037\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.5223 - val_loss: 82.5165\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.4705 - val_loss: 82.5787\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 1s 396us/step - loss: 0.2716 - val_loss: 82.2878\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.1807 - val_loss: 82.1201\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.3406 - val_loss: 83.4281\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl4VOXZ+PHvPZONQNjCFhYFFVFwQUTFotW6L1W02oqt1lZb7Kt9q7Zv36qvv0pdqrbudUXBfV8QREQFWURZJOwEMOwJARJCEsi+Pb8/njPJJHNmsk4mydyf68o1M+ecOec5mZlzP/sRYwxKKaVUfZ5IJ0AppVT7pAFCKaWUKw0QSimlXGmAUEop5UoDhFJKKVcaIJRSSrkKW4AQkQQRWS4ia0Rkg4j8w1k+TESWiUi6iLwnInHO8njn9RZn/dBwpU0ppVTDwlmCKAPOMcacCIwGLhKRccAjwBPGmOFAHnCTs/1NQJ4x5ijgCWc7pZRSERK2AGGsQudlrPNngHOAD53lrwFXOM8nOK9x1p8rIhKu9CmllAotJpw7FxEvkAocBTwLbAXyjTGVziaZwCDn+SAgA8AYUykiBUAysL/ePicBkwC6du168jHHHNPkdJmqCmTfeg4lpJDUe0CT36+UUh1ZamrqfmNM34a2C2uAMMZUAaNFpCcwHTjWbTPn0a20EDAPiDFmCjAFYOzYsWbFihVNTldpXhYJTx3LwuF/5Kxf3dnk9yulVEcmIjsbs12b9GIyxuQDC4BxQE8R8QWmwUCW8zwTGALgrO8BHAhzysK7e6WU6sDC2Yupr1NyQES6AOcBG4H5wNXOZjcAM5znM53XOOu/NmGbSVCbNpRSqiHhrGJKAV5z2iE8wPvGmFkikga8KyIPAKuAqc72U4E3RGQLtuQwMYxpU0op1QDpyNN9u7VBVFRUkJmZSWlpadD3meoq5OBuSmN7kNC1R7iTGTYJCQkMHjyY2NjYSCdFKdWBiEiqMWZsQ9uFtZE6EjIzM0lKSmLo0KEE6yVbXVmBJ7uCQ/EDSEpOaeMUtg5jDLm5uWRmZjJs2LBIJ0cp1Ql1uqk2SktLSU5ODhocOgsRITk5OWRJSSmlWqLTBQig0wcHn2g5T6VUZHTKAKGUUqrlNEC0svz8fJ577rkmv++SSy4hPz8/DClSSqnm0QDRyoIFiKqqqpDvmz17Nj179gxXspRSqsk6XS+mpmn9Lr533nknW7duZfTo0cTGxtKtWzdSUlJYvXo1aWlpXHHFFWRkZFBaWsptt93GpEmTABg6dCgrVqygsLCQiy++mDPOOIPvvvuOQYMGMWPGDLp06dLqaVVKqVA6dYD4x6cbSMs6GLjCGKgoospzEG9Mo6YkqTFyYHfuvWxU0PUPP/ww69evZ/Xq1SxYsIBLL72U9evX13RFnTZtGr1796akpIRTTjmFq666iuTk5Dr7SE9P55133uGll17iF7/4BR999BHXXXddk9KplFIt1akDRHtw6qmn1hmn8PTTTzN9+nQAMjIySE9PDwgQw4YNY/To0QCcfPLJ7Nixo83Sq5RSPp06QATL6duBcus5FN+fpOSBYU1D165da54vWLCAuXPnsmTJEhITEzn77LNdxzHEx8fXPPd6vZSUlIQ1jUop5SY6G6nDOHwgKSmJQ4cOua4rKCigV69eJCYmsmnTJpYuXRq+hCilVAt16hJEJCQnJzN+/HiOO+44unTpQv/+/WvWXXTRRbzwwguccMIJjBgxgnHjxkUwpUopFVqnm6xv48aNHHus232JalVXVeLZt65NqpjCrTHnq5RS/ho7WV90VjEppZRqkAYIpZRSrjRAKKWUcqUBQimllCsNEEoppVxpgFBKKeUqqgNEe7jdTrdu3SKdBKWUchXVAaIDDwFRSqmwi/KR1K0fIf72t79x+OGHc8sttwAwefJkRIRFixaRl5dHRUUFDzzwABMmTGj1YyulVGvq3AHi8zth77qAxYKB8kK6SBzExru8MYQBx8PFDwddPXHiRG6//faaAPH+++8zZ84c7rjjDrp3787+/fsZN24cl19+ud5TWinVrnXuABEBJ510EtnZ2WRlZZGTk0OvXr1ISUnhjjvuYNGiRXg8Hnbv3s2+ffsYMGBApJOrlFJBde4AESSnL9VVsHctJXH9SOozqNUPe/XVV/Phhx+yd+9eJk6cyFtvvUVOTg6pqanExsYydOhQ12m+lVKqPencASJCJk6cyO9//3v279/PwoULef/99+nXrx+xsbHMnz+fnTubdhc7pZSKhKgOEOHqxDRq1CgOHTrEoEGDSElJ4Ve/+hWXXXYZY8eOZfTo0RxzzDFhOrJSSrWesAUIERkCvA4MAKqBKcaYp0RkMvB7IMfZ9G5jzGznPXcBNwFVwJ+MMV+EK31A+CIEsG5dbeN4nz59WLJkiet2hYWF4UuEUkq1QDhLEJXAX4wxK0UkCUgVka+cdU8YYx7131hERgITgVHAQGCuiBxtjKkKXxJ1IIRSSgUTtoFyxpg9xpiVzvNDwEYgVIvwBOBdY0yZMWY7sAU4NVzpU0opFVqbjKQWkaHAScAyZ9EfRWStiEwTkV7OskFAht/bMgkdUILqyHfJa4poOU+lVGSEPUCISDfgI+B2Y8xB4HngSGA0sAd4zLepy9sDroAiMklEVojIipycnIA3JCQkkJub26iLZ0e+vBpjyM3NJSEhIdJJUUp1UmHtxSQisdjg8JYx5mMAY8w+v/UvAbOcl5nAEL+3Dway6u/TGDMFmAL2ntT11w8ePJjMzEzcgkftTqqhIJsSbwld9h9q6mm1GwkJCQwePDjSyVBKdVLh7MUkwFRgozHmcb/lKcaYPc7LK4H1zvOZwNsi8ji2kXo4sLypx42NjWXYsGGhN6oogQd/xOcD/sDFf3ikqYdQSqmoEM4SxHjgemCdiKx2lt0NXCsio7E1PDuAmwGMMRtE5H0gDdsD6tbw9mBCp3NVSqkQwhYgjDGLcW9XmB3iPQ8CD4YrTbXEd7zwH0oppTqo6L4fRKQToJRS7Vh0BghxTttURzYdSinVjkVngPDGAuCprohwQpRSqv2KzgAhQgUxeDVAKKVUUNEZIIBKYvAaDRBKKRVM1AaIConRKiallAohagOEliCUUiq0KA4QsXhNZaSToZRS7Vb0BgiJwaMlCKWUCipqA0SVaC8mpZQKJWoDRKVoFZNSSoUSvQGCGGK0ikkppYKK2gBRJTFaglBKqRCiNkDYKiYtQSilVDBRGyDKJZ54UxrpZCilVLsVtQGixNuNxOqiSCdDKaXaragNEMWebiQaDRBKKRVM1AaIEk83upoive2oUkoFEbUBotTbDS/VUHYo0klRSql2KWoDRIUn3j6pLItsQpRSqp2K2gBRc9tRvTO1Ukq5itoAISL2id6XWimlXEVtgKgpQWgjtVJKudIAoSUIpZRyFbUBQquYlFIqtKgNENpIrZRSoUVtgBCtYlJKqZCiNkBQU8WkJQillHITtgAhIkNEZL6IbBSRDSJym7O8t4h8JSLpzmMvZ7mIyNMiskVE1orImHClzSZQSxBKKRVKOEsQlcBfjDHHAuOAW0VkJHAnMM8YMxyY57wGuBgY7vxNAp4PY9oQj3ZzVUqpUMIWIIwxe4wxK53nh4CNwCBgAvCas9lrwBXO8wnA68ZaCvQUkZRwpa+mF5M2UiullKs2aYMQkaHAScAyoL8xZg/YIAL0czYbBGT4vS3TWVZ/X5NEZIWIrMjJyWlBmrSKSSmlQgl7gBCRbsBHwO3GmIOhNnVZFpC9N8ZMMcaMNcaM7du3bwsSplVMSikVSlgDhIjEYoPDW8aYj53F+3xVR85jtrM8Exji9/bBQFb40qYlCKWUCiWcvZgEmApsNMY87rdqJnCD8/wGYIbf8l87vZnGAQW+qqgwJdA+aoBQSilXMWHc93jgemCdiKx2lt0NPAy8LyI3AbuAnzvrZgOXAFuAYuC3YUxbbS8mbaRWSilXYQsQxpjFuLcrAJzrsr0Bbg1XeurTKiallAotakdSa4BQSqnQojZA6FQbSikVWtQGCF8bhNEShFJKuYreAOFUMVVVa4BQSik30RsgfCUIDRBKKeUqegOE0wZRXV0V4ZQopVT7FMUBwguA0UZqpZRyFcUBwilBVGkJQiml3ERvgPDYEkS1liCUUspV1AYI3zgIbaRWSil3URsgPE4vJm2kVkopd1EbIPAFCB0op5RSrqI2QHh8czFVaxuEUkq5idoAUTsOQksQSinlJnoDhMc3DkLbIJRSyk30BoiacRBaxaSUUm6iNkB4dDZXpZQKKWoDhGgvJqWUCil6A0RNLyZtg1BKKTdRHCB0qg2llAolagOEx6NTbSilVChRGyBq2iA0QCillKuoDRAep4oJbaRWSilXURsgatqotQShlFKuGhUgROQ2Eeku1lQRWSkiF4Q7ceFUO5JaA4RSSrlpbAniRmPMQeACoC/wW+DhsKWqDfgm69NGaqWUctfYACHO4yXAK8aYNX7LOiSP1zeSWru5KqWUm8YGiFQR+RIbIL4QkSQgZNZbRKaJSLaIrPdbNllEdovIaufvEr91d4nIFhHZLCIXNudkmkS0F5NSSoUS08jtbgJGA9uMMcUi0htbzRTKq8AzwOv1lj9hjHnUf4GIjAQmAqOAgcBcETnahHGqVa+vlVpnc1VKKVeNLUGcDmw2xuSLyHXAPUBBqDcYYxYBBxq5/wnAu8aYMmPMdmALcGoj39ssolVMSikVUmMDxPNAsYicCPwvsJPAkkFj/VFE1jpVUL2cZYOADL9tMp1lAURkkoisEJEVOTk5zUxC7VQbRudiUkopV40NEJXGZrUnAE8ZY54CkppxvOeBI7HVVXuAx5zlbg3erll7Y8wUY8xYY8zYvn37NiMJzgG9Tu2aBgillHLV2ABxSETuAq4HPhOb/Y5t6sGMMfuMMVXGDj54idpqpExgiN+mg4Gspu6/KTw1AaIynIdRSqkOq7EB4hqgDDseYi+2+uffTT2YiKT4vbwS8PVwmglMFJF4ERkGDAeWN3X/TUqLEyCMBgillHLVqF5Mxpi9IvIWcIqI/BRYbowJ2QYhIu8AZwN9RCQTuBc4W0RGY6uPdgA3O/vfICLvA2lAJXBrOHswAXg8TgFIq5iUUspVowKEiPwCW2JYgG0v+I+I/NUY82Gw9xhjrnVZPDXE9g8CDzYmPa1BYpzJ+rQEoZRSrho7DuL/gFOMMdkAItIXmAsEDRDtXW0JQgOEUkq5aWwbhMcXHBy5TXhvu1TTi6mqIrIJUUqpdqqxJYg5IvIF8I7z+hpgdniS1Da8Xi9VRhAdSa2UUq4a20j9VxG5ChiPbYOYYoyZHtaUhZlHoBKvVjEppVQQjS1BYIz5CPgojGlpUx4RDRBKKRVCyAAhIodwH9EsgDHGdA9LqtqAxyNU4UW0m6tSSrkKGSCMMc2ZTqND8IpQiUdLEEopFUSH7onUEh4PVOHV6b6VUiqIqA0QXm2DUEqpkKI3QHiEKjyIBgillHIVtQHC4xEqjVfHQSilVBBRGyBiakoQUT6S2hjI3hTpVCil2qGoDRC14yCivASxYio8dxrsWBzplCil2pmoDRBej1BGLLGVhZFOSmTtXmUfD2yLbDqUUu1O9AYIEdZWH8GAQ+ttNYtSSqk6ojZAeDzCHpNMXFWxdnVVSikXURsgACrEuSdERUlkE9IuSKQToJRqZ6I8QMTZJ5VlkU2IUkq1Q1EdIMpqAkRpZBOilFLtUFQHiEq0BOE+Wa9SSkV5gCj3+AKEtkEopVR9UR0gKn1VTBs/bf5OinJhwyetkyCllGpHojpAVEi8fbLwkebv5P1fwwc3wKG9rZOotuYbAyLai0kpVVdUB4iaEkRLFOyyj6G6yj57Gix4uOXHUkqpNhTdAcLTCgFCvPYx1JxOOZtgwUMtP5ZSSrWhqA4QFa1RgvA4d23VacOVUp1MVAeIKk98y3fiCxCRnq5j1Vuwd10LdqBtEEqpusIWIERkmohki8h6v2W9ReQrEUl3Hns5y0VEnhaRLSKyVkTGhCtd/ir8A0R1dfN24gsQq95s4QW6hWbcAi+cEbnjK6U6nXCWIF4FLqq37E5gnjFmODDPeQ1wMTDc+ZsEPB/GdNWo9MTWvmhuCcDj/AuXPtdBL9A6UC5qZa2CyT0im7FR7VrYAoQxZhFwoN7iCcBrzvPXgCv8lr9urKVATxFJCVfafOpUMTX3znK+EkQwOpW4aq984382z4lsOlS71dZtEP2NMXsAnMd+zvJBQIbfdpnOsgAiMklEVojIipycnBYlpsq/kbqqmQHC14spmLa4Y11maviP0RL702H7okinQgXogO1OJXnNrw5WTdZeGqndvqmuWW9jzBRjzFhjzNi+ffu26KCxMX4X9+ZeyBsqQbRF4/XL57TCTsJY0nlmLLx2Wfj23xls+gzKiyJ08A5Syi3aD48MhYU6pqittHWA2OerOnIes53lmcAQv+0GA1nhTkyM1y8uNbuKqaESRAMB4rFj4Yv/a96xW4OvCsxorixi9m2Ad38Jn/2lbY/rGz3fUapBC53LRdqMyKYjirR1gJgJ3OA8vwGY4bf8105vpnFAga8qKpxiPX6n39wqppYGiENZsOSZ5h27qbI3waJH3de1RVVYR/D1A3b6lLbkKznkbmnb43ZYHbBqrIMKZzfXd4AlwAgRyRSRm4CHgfNFJB0433kNMBvYBmwBXgJuCVe6/MXGCDMSf2ZfNLcEEdMl9Pr2dOGddiF8fb/7tCCtVYIwBjbNhqoOehvXRf9u+xxqzWj8SP3POkgJosOks/NooAK9+Ywx1wZZda7Ltga4NVxpCSbG42GL50j7ItSFfNVbdpzBPdkQU29wXVxi6IOE+tFnb2pcQltLRbF9rCqHWF9ga+Uqpo2fwvvXw/n3w/g/1V1njE4K6Mb3L2nzar52WMVUtB8SeoA3NnBdVXnbpyfKtZdG6oiI9Qplxsm9hapimvcP+1iSF7jO28B0HaECxEs/Cf3ecKl0+aG11sXpwFb7WLjP5bjRfGOmEHyZk7bundPegnV1Nfz7SJgRJK/o+962t3RnrYI170U6FWER5QHCQ7lx/gWNqWJyCyL1Sx71c2OhAoQvR9+aChvR9bfK5ULdWlVhZYfsY3xS4LpQt3bNz4A177qvO7Advn4QXp8AxfWH1kRAZXnrpsOXM27zKqZ2dqH1/R7Wvu++3u172x68PRGmT4JDLpmiDi6qA0SM10NptVOCaEwPEte6+3oX1vpBpLV+9MGqAfal1X295auG9+WWkw9VgsjfZUfcps9teN+5TgnCF3D2rq9dV5ARuL3Pmz+D6Te7d/V8fQIs+hdsWwCr32o4Da0hVLXL9Enwr2GNr5opLQh98fB9HhGb8LGdVDH5fl/BSgjttQTqC2y+0nMwB7NC3xagYDd8PAnKw5BxbKaoDhCxHuF7RtkXmd9D9sbQb3DL8dfPedevJ22NnPm8++HJ4+0P5JNbYO0HteueP73e8YOUhJZNqU2ba4AIkc5dy+zjiqk2WIQ6J9+0DaX59vGF8bXr3gnWLAUUOSUft2q84tza53Hdgu+jNYWqctww3T6WFjRuX8+Og8eObvhYbd2hob11c63wZQ4aChDtrOTj68lYkh98m73r4PFj4cEBwUv5s/8Ka9+DbfNbP43NFNUBIsYrFFX7tSE09IN3DRD1SggBAaIVShDfPGpz33vW2Bz0x7+zy93GTxRlBy5b9yF8/le/NDaxBOE7h82zbaC6r7cdHR2wXZUNIGDrZT+8se76g7uDH8PXG8yt6sZ/tHpcV/f3Fx+Agsza13k7gwf8b5+GPWuDpwUad5/yokZU55UV2q7Mofi+Mwe2Bs89VlU2/P3M3Vpbggul/tiXSI2BWfsBZK6ofe0792AlCN/31m19dRVM/y/7vavv0D57wy63nnXVVTDjj/a3VV9JPnw/FRY8Untb4fSv4NWf1g3mvsGyoT6f76fWPn/0KPdtivc7+4utraqNsKgOELFeDxVVfj+OssLAjXI21za4vnIxPHq0vfisfscu2/8DJA2s3T5UFdP8f9r3Nlfm93XT6jZ+YvuiwBzh5s/rvvYvQfguDqFyr25BbtpF8NCQ2oAA9n/la8vJ/B7Wf1T3PUedH/wYvl5Vu5YGrvO/IPin0xhYMQ2WvmCrfJ4YVXvuT50Az42zF0z/e47nZ8BX/w9ePNPeTzyYiiDtJUW59gcM8NXfg7/f571f1T4P1vXXP1Ox6F8u6yvhgX7w8GGh25j+M8b+BRuRXV4ES56Df/S0/xffcRvqHVR8ADKWh96mKTK+txffj38HL/t1amyoiiZUFVNBBqx5G6acHbhu7mR7w67vnoblL9XtpJGzGVa9EZiZqa6GVy+Fz/4MC/4JH/zGHv+tq2HHN3Bgm91u+ze1GYVP/gBZq+vuZ+86m1FJfaXucv+qpupq+3vOcErqb/8cHhoMi5+wGbED2+3/bNtC2Pq1TcuyKYHHCoOwdXPtCGoCxNl32S/QW1fZrqzvXQenToLh58MXd9d9U+E+e/EBOOIsGyAALn8GZv7RfnmOv7p2e/+L68JHoPQgXPwwpL5ad7+b58AIv8lv5/4DegyCsTfVLvNPy0MuU1WdcI0tor56Kfx2tg0We9YEXgD8f2i+oLhimu2RdfJvIKG7XVZRaktNbo3LvtzOptkw7g/2+dZ59rFbf/deTIm9A5f5dB9oLxCf/xXG/BpiE/xW+gU8X86+vNjW6c66o+5+8ndBz8NqX085G8oOwhl/tstn3V67buvXcNxVtltu7yPgnHtq11W4XGQP7oHHj6l9vXk27PgWho6vu111lQ28O76x7SY+y56HH/134H79Px+3EtTGGbVVgGvehnG3BHYDXflG7fPXLocrX4A+w+3rkjx7UfSv5tr6dW1mpijHro9x6ZFXVghTL4DcdPjf7RCTYC94Gz6G5KNs7jntEzjyHOh5OOxYDPvWw0+fhP2bbWeFXsOgx2DY+Z193/cv1z3GfX3qdhKproR3fglHnA0jL7fbJ/SAL53PJ66rTZcnxn5negy2pWSfyT1g0Fi4eir0Glq73NcbccMn0HuYvfD6uq3nboHHR8F1H9nP7pWL6pUIDDx7au3L6TdDUgpsmlX3XKacZR8POx12LQn8f/o8OMD+//oeY4NUrkuJfO5k++dmw3Q4839g4Ojgx2gFYtpL/WMzjB071qxYsaLhDYN4YFYaby/fRdrfxtrudQA3zYWp59nnv54Jc+6E7DT3HVz4EHxxl31+5RTbeAkw6mdw9TT7fNt8eONKv0TfCOf+3c4pU98pv7M5k+EX2OMC3PyNze02xk/ugfkP2Of/vdLmJoO5O8v+0B4fWbfqp2tfuHU5PHkClDvFXPGEroYYeYUNpjNutcEBgcK9gdsNvxD6Hg3f/Qd+9pIzqO5TKM6DnYvrbnvpYzDySnvheGyE+3Hje0BZvWJ9/+Oh1+GBP9zG6HuMvT2sv5QTbbvHzm+Dv++8yfb/1udomBqilBSXBH/eYKtV+h8HSf3t8vv71VafHHdV7XfH54EBgVVeV75oj5c0ALbOt+N06ut9hL1Abv3aPT1HXww/+JUuf/G67UE0+pe2RJe9MTCDpJrnJ/dA+peQ6ZTEPLGQfKT9vbuV4Ca+badfqc/3W+zSC278AvoG+W00QERSjTFjG9wumgPEI3M28fI320h/4GJb7Aa46OHai3NTXD0tsJga1w3KXaqtxt5oc+zNccJEGH9bYOP00DPhJ3fbarDGiunSuLr2pqZv79rgQbW9GDQWdjf/u9MkJ14L6z4IrKrrPhgOZgZuf+S5cGgvZG+wF3lfdUZjxCaGp/t0cx15rk1/3vbAdT2G1O3ZNvRMW81S/4I5/jabY+7ndCj5oV6Vqf/vbPxtdm6rLXOh30hbKi47ZDNdA46333fx2lJl177w6W1w/n129Pyws+pOBDj+Nluy2vSZLV1mb4CjzoPDx8MPc2zpKG2G/XyTnQxmZRkkJttSW3kRdO1jL+gJPWr36xswWl3tDFpNsKW59R/B0DOg2wDwxsDCf8NR58C718GgMXD1K+6lvGbQANEIj3/1A0/PS2f7Q5cgn/8Nlr8YfOOz7rS5yB3fuK+/9l14Z2LzEpJ8VMPz8Fz4T1uM73esfT3Z+cKd8ns48y+2+iYm3tZLLnjIfoF9eh9htxGvvbHRXpcG2rPutO/3FcPdxCXBHeth/oN2/xOetbO0jpwAx15uf9znTbYXt1Cll5FX2GoJAG883DgncNCgN87+eOK62dzsRQ/DRzfV3ab3kbbUdcRZtqExJt7+OE/9vc1d7/8BFj9pf+iHj4fVb9rc+3mT7f5fnwB7VsOdu+wI3i69bLXC/Aftj7v7IPjx/9gfdNonMPAkGDjG/kgn+/3gf/WRvfCseddWY618A4acCmf+2ZZITrre5h7fu672PUkD7Xvcem3588TaUlT3QTZ9XfvYC+vBLOg5xDbAxsTVTg/yh8WQ+potRY260gamxGR7/lmr6v4Pz70XDhtnt+8+EDC2of/IcwCxde9HX2wvTmDPqfhAbbuBJwbu2GA/n7Xv24vgp7fbXO2vZ9j1vpkGlr5gc7/D/UpYvYfZUkpiH+jmNzPzmnftZ3nMZfZC6S9vp734p4y26WrtQXMHttn0+KpZOykNEI3w7Pwt/PuLzWy6/yISYr3w6Aj3qpGBY2CS0/Vs5eu2/vOLu2DACfZie849cPp/24aooy+0oyp3p9aOSbj2XVu6cMvZjbwCrppq64H3rrU5pYoS+OkT9gf2wnh7wb0zo269/Oq37YX/sHGB+6yuqm0Ei3fpFvr6BFs3fsOndrqPw06zVSluqqvt/EQnTrQXHZ+Gps3IWm1n3xx+vm2PyFhuL75jrq9N46G9tp0Fai+4426xObKUEwL3ObmHrcL67ef23Ft6cfB995uzn8JseNSp45/cyO6u5cX2wuc/wWN+Bix5Fs67115oK8vsNsbY70tMF5sDrX+hrK8o1wacHoNDb2cMZK20mRL/XG1T+D6rvx8InKyy9KANvnXakFR7owGiEaYt3s59s9JY/ffz6ZkYZ3+oi5+AW5Y5ucn82h9RQ7O2utm+yOacL8mKAAAXOklEQVQ645Nsr41vHrNF4YFjbGPfsT+1OcSGfvzRYNtCWz0y5JTg2xzMsp9LzTxSEbZvgw3Egxv8nXUuWavt5+CfYVAdSmMDRFRfmRJi7UW/tMJpgD39VpuD9eUoQ/W6aYxhP6593qUnXHB/y/bXmR1xVsPbdB/Y8DZtqf+oSKcgMsLcc0a1H1E9DqJLnD390gq/vvXtbSIwpZSKkKgOEAnOLUdLKkIMElNKqSgV3QGipopJA4RSStWnAQItQSillJsoDxAubRBKKaWAKA8QcTH29MsrO25XX6WUCpeoDhCxXnv6lW19q0ellOoANEBA3Sm/lVJKAVEeIGI8dsxDRZVWMSmlVH1RHSB8bRCVGiCUUipAVAeI2hKEVjEppVR90R0gtA1CKaWCiuoAEVcTILSKSSml6ovqABHjtVVMlVqCUEqpABGZ7ltEdgCHgCqg0hgzVkR6A+8BQ4EdwC+MMQ3cbqtlatogqrUEoZRS9UWyBPETY8xov5tW3AnMM8YMB+Y5r8NKRIj1irZBKKWUi/ZUxTQBeM15/hpwRVscNMbj0SompZRyEakAYYAvRSRVRCY5y/obY/YAOI/92iIhtgShVUxKKVVfpG45Ot4YkyUi/YCvRGRTY9/oBJRJAIcddliLExLr9WgVk1JKuYhICcIYk+U8ZgPTgVOBfSKSAuA8Zgd57xRjzFhjzNi+ffu2OC1xMR7KKjVAKKVUfW0eIESkq4gk+Z4DFwDrgZnADc5mNwAz2iI9XeK8esMgpZRyEYkqpv7AdBHxHf9tY8wcEfkeeF9EbgJ2AT9vi8R0ifVSUq4BQiml6mvzAGGM2Qac6LI8Fzi3rdOTGKcBQiml3LSnbq4R0SUuhmKtYlJKqQAaIGI9lJRXRjoZSinV7kR9gEiMi9FGaqWUchH1AaKLtkEopZQrDRCxXoo1QCilVICoDxCJzjgIY3S6DaWU8hf1AaJLnBdj0NHUSilVjwaIWC+AVjMppVQ9UR8gEuN8AUK7uiqllL+oDxBd4uxgcu3JpJRSdWmA0CompZRyFfUBom9SPADZh8oinBKllGpfoj5ADOrZBYDdecURTolSSrUvUR8g+nSLIz7Gw+78kkgnRSml2pWoDxAiwqBeXcjMi84AkXGgmCuf+5bcQq1iU0rVFfUBAmw1U1YDJYjCskq25RQ2a/9/eCOVoXd+1qz3htu0b7ezalc+H6/cHemkKKXaGQ0QQHLXOPJLKkJuc/3UZZzz2MJm7X/Ohr3Nel9bqG2kL41wSpRS7Y0GCKBbQgyFpaEHyq3alQ9AZZX7lBzTFm/n+x0HApY3VDJpDdXVht+9toK3l+1q8nv7dLUBIrewvLWTpZTq4DRAAN3iYzlU1riR1G53nzPGcN+sNH7+wpKAdV9vyq6zXTisycxn7sZ93D19XZPfa7BpqqjWyQqVUnVpgACSEmIor6ymrLLhwXLFZYHbhBpk1zXeW/O8MkwX4cJGBjc35VU2TdUNpK2guEJHmysVZTRAAF2d+ZiKXC7+9bnN2RSqeiYhpjZAhGvG2PIW7NdXZVbVQIA48b4vufTpb5p9HKVUx6MBAuiRGAtAXnHD9fD1Swt5ReX8+N/zg27vHxRKw3RrU/8A0dRqrApfgGjE+7btL2pawpRSHZoGCGBIr0QAdh0IPpo6xiNAYIDYUq/ra/2qGv+gEK4ShP9+K6qaGiAaV8XUEqk78/jTO6u0ikqpDkYDBDC0T1cAdoTIIXdxqqHqDyjbU2C7h/5szCAACutVQZX4BwiXEkRjLprfpOfwy5eWBq0G8i9BlDSxlOIrQYRqH2lp4/p/vZnKzDVZbN53qEX76czW7y5g6uLtbX7c7fuLWtSGpTo3DRDYcRDd4mPYmRu8BNG/ewIAGfXmbMo+aAPEiP5JAAHdZUsrql2fAyzblsuxf5/Dkq25IdN3y5sr+W5rLjlBJhQs8+t66xaEAB6YlcalT38TcLH3BYhQ7Rj10x3K/sIyDpbWHVNS7hyjIMRYk/e+38Vna/c0+jgt8egXm1m1K8913YGicp5fsDVkiWrfwVLOeWwBO3Nbr8rtp/9ZzP2z0oJWQ5ZVVvHm0p0NthU1hTGGnzy6gBtf/b7V9qk6Fw0Q2Ok2hvZJZGuQkdLGGLZk23Xp++puk1dcjtcjDHQm/at/cfT/wecW1b3Av7Pcjlu4+Y0VLPohp866cx5bwG9fWQ7U5u6DXZD8g0KwEsTLi7ezIesgWQV1B8RVOlVMoXpw+TfML6yXzvou+89iTpj8JQeKattzfNVzB0MEiL99tI5b314Zct+tIa+onGfmb+H6qctd14+5/ysembOJVRn5Qfcxc3UW23KKePW7HY06pjGG9EaWnrIPumcCXliwjXs+Wc+M1a034j3HKQ0v3x44fkcp0ABRY2RKd9bvLnCtTtm0t/bHXf/CUVBSQfeEGAb0sCWMvfUuwP7F9+unLue7LftrXvt+oAdLK/n1tLoXrG05RczfbC/GvlzjNVOWsjWnMOBiU+5XggiVSwcY//DXdYKW7715xcHf59/ucsM09wurj6/KzRf8ALxOgAiWNv9R3PM27nPdprSiintnrGfZttClrYakO4FeXNYV+X1Woar+fOfT2Habm99I5fwnFrFxz8EGt9170H1E+54CO+CyqBXbcTIO2H3GxXTuy0BVteGvH6xhQ1ZBRNNRWVVd5zvWEXTub0YTnDYsmbziCpZuC8xN+S5ag3p2YWduEVXVhnkb91FRVc2SrbkkxsXUNHQ/MTe9Tikir6ic/t3ja17/9cO1gL24/FCvNOILBE989UOd5f5jKc59bCHnP7GoJpBlHCjmxYXbatYv3Bw6hw+wxO8i6ytB7MwtCvrlza8XPLKDXMQAEmLtV8o38hxgn5Mrzg/SS2zBpto0v7M8w3Wbz9bu4bUlO3no800B64rKKsk4UEzOoTL2uaStwC/9vgttfKw3YDv/Krz9ISYvdOIDFdWmwSqfr9L28WWa/f7sDjIhpH+mZMVO99x8Qx0c0rIOcs6jC/j3F5sCMjlV1Ya1mYElos1Oxsf/+xlMa1ZtNWRvQWnQdq8Zq3czZ717VWRBcQVXPvctL3+zrc7y3XklfJCa2eSqtIqq6ka1v6XuPMC7yxuexeDpeemMuveLoDUBpRVVzF63J2wDapuj3QUIEblIRDaLyBYRubOtjnvRcQNIjPNy7UtL61SplJRX8eiX9oI96cdHUFFluGHacm56bQX3fZrG1pwidueX0M+Z02hNRj5vLNlZ8/684nL6JSXU7q+iiupqw9acwoA2hf98nQ7AU/PSa5ZNePZb8oorOHFwjzrbDrtrNne8t5oz/zW/Jmc+MqU7i/1KKGAvevXbF+7+eF1A20O1gRcXbnX936zdbS8ulx6fAsCp/5zHDy5VJqUVVTXtFVtzCjHG8Of3V9es377fvY1n54EiYjzCT09IYd3ufNcL3F8+WAPYC6F/9dWu3GJG3fsFZ/5rPqc8OJfT/jkPsBfdrPwS1mbmc+J9XzLhmcWs3JVX8z/fX1gWELD8g0KGS4+21Rn5pO7MY22mzYm+vWwX1728rM42xpg635/pqzJrnmcVuAcI/4v/MpcMCtjR8hA8A/DHd1aybX8Rz87fGtCW9tz8LVz+jL1w/mvOJm5/dxWL0/fX5Kh7dolz3SfYzEBa1kGOvHs2i9Ptd+uBWWm8+m1gg7oxho9SMxtVZTVl0VaG3vkZW7Jrv0fZh0q56dXvGffQPB78bGPAe8orq7nt3dX84c2VHCoNLI0+/XU6q3bl88LCugFiv1O1G2y80mdr99Qp2YP9zv34X/P5XydDV3+dT3W14arnl3Dnx+saLKH4OiGk7nRv/3rgszRueWtlwG84kmIinQB/IuIFngXOBzKB70VkpjEmLdzH7hofw60/OYp/f7GZy5/5lpvOGMbJh/fin7PtF/WO847mtCN6A9R8gG8stYHgqjGD8XiEuBgP5ZXVLPwhh8tOGEhOYSnzN+dw6rDePPyz43n1ux1s2nuIW99eyefr7QR+s/77DOJjPDwx9weenJvOk3PT66RrjVOldfnoQXRLiOHbLbW5/+mrauujkxJiGH9UMq98u4PZ6/bQv3sCq3bl8cBnG2uqEK4ZO4Rl23PZkVvM/bPSuH7c4azPKmD0kJ70S4rnuQVb6ZEYR0VVNYlxXi49PoXKasNr3+0guWscf79sJJ+ts7m3C55YxMmH9+K/zjqSMYf3okusl4U/2GlFThjcg7WZBZzz2EK2+/UM+2hlJsemJHHhqAGI2MbvamNYt/sgA3okcNbRfZm1dg/3z9rIxFOH0D8pgYQ4T81FcUD3BHIKy/jTO6s4/chkxh2RzO9fXxHwWZ7/+EK27S+q80Nek1nAz577jlhvbeXS6Pu+on/3eG46Yxg/P3kIq53/dWKcl09W7+ai4wbQLymBxHgvt7y1kq/SAqu/lmzL5da3VvJfZx9J6s487p25AYDf/GgoZ4/oy6pd+Zx3bH/WZuYzfdVuxh/Vh4E9upAQ60FEqKyqZqVfg3nqzjy2ZB9icK9E4rweiiuqWJdZwLYc+3+cu3EfL3+zjctHDyQxLgaP2GpM/x54d328jgevPI7EuBh25xczzbmYP+B30Z2zYS/dE+z4n7Q9B5m1NovzR/YnPsaLMYZqA7PWZnHbu7UB/uY3VvDML8fwsnOhW7b9AMP7J5FbWIbXI6zfXcBKp+R4RJ+unDK0d03m6aj+3bj4uBSqqg0bsgr452xbEjzv8UU8NXE0/bsnMHNNFvOcqWleXrydn40ZzFH9upFfUs7egtI6Mw7f/EYqT14zmj7d4qk2hrziCt50fo/7C8v4zSvLeWriSfToEltT4q2sNnyTnsNpw5LxCBwoLufFhdtqLtyP/fxEDk9OpKCkgpW78thTUMoHqTbAn3tsf0YMSOLemRtYv7uAZ649iaMHJNUETYB/zEzj7kuP5ci+XdmSXUhGXgkjU7pjjGHT3kM11YOvfreDHx/dl55dYvF6hGpjSytz0+y5/+frLRSVVZKVX0pytzjS9hykvLKaU4fa609OYRnHDerBgO4JNW2f4SLtqTgjIqcDk40xFzqv7wIwxjzktv3YsWPNihWBF4iWeGPJDh6cvbFOz52fjOjL89edTEKsl3s+WcebS3cxon8S23OLOGVoL175zanExXjYd7CUZ+dv4XW/EgTA/RNGcf3pQzHGTqrn+xGMTOnO9Ft/RHyMl9KKKi59+hu25hQxMqU7f7ngaMYe3psPUjPIOFDMXy4cQUKMl5LyKuJjPezMLebz9XswBg5PTuSCUQPYW1DCxClL2e+SU+qeEMPqv1/Atv2FXPL04jqlilvOPpIrThrEpNdXsCNIT64Jowfy1MST2HewlEuf/sb1GACDe3Xhsz+dydPz0pm9bg/9kuJ58MrjKamocp2ryufG8cP428UjmPR6qmtDeEKshxX3nM9/5qXz4qK6OcSfnzyYEQOS6NElln98mlan3Wd4v26UVlZxyfEpTFm0DWPglKG9OKpfN9fqrOSucTx+zWh++8pyQtWqDOyRwFkj+jJvY3ad29X26RZfpyTiEZh6wynsPVjKvTM31PzfYzxCtXMh9m33wBXHc+/M9UHHsky+bCSPzNkctCPCe5PG8UFqJh+mZrquP35QD/YdLK2T3jOH9+Gb9MjkWIf16VonA+GT3DWO3CL379fpRyRzzjH9eHB2YAlDBN6bdDq/eLH2e+b1SLOrx7weISkhJqCKtb74GA8TRg/k/RXu/3efLrFezh/Zn0/XZhHsshvjkUZPyfObHw1l8uWjGrVtfSKSaowZ2+B27SxAXA1cZIz5nfP6euA0Y8wf/baZBExyXo4ANjfzcH2A9lOWaxt6ztFBzzk6tOScDzfG9G1oo3ZVxYR755I6EcwYMwWY0uIDiaxoTATtTPSco4Oec3Roi3Nub43UmcAQv9eDgawIpUUppaJaewsQ3wPDRWSYiMQBE4GZEU6TUkpFpXZVxWSMqRSRPwJfAF5gmjFmQ5gO1+Jqqg5Izzk66DlHh7Cfc7tqpFZKKdV+tLcqJqWUUu2EBgillFKuojJARGo6j3ATkSEiMl9ENorIBhG5zVneW0S+EpF057GXs1xE5Gnn/7BWRMZE9gyaR0S8IrJKRGY5r4eJyDLnfN9zOjwgIvHO6y3O+qGRTHdLiEhPEflQRDY5n/fpnflzFpE7nO/0ehF5R0QSOuPnLCLTRCRbRNb7LWvy5yoiNzjbp4vIDc1NT9QFCL/pPC4GRgLXisjIyKaq1VQCfzHGHAuMA251zu1OYJ4xZjgwz3kN9n8w3PmbBDzf9kluFbcB/kNrHwGecM43D7jJWX4TkGeMOQp4wtmuo3oKmGOMOQY4EXv+nfJzFpFBwJ+AscaY47AdWCbSOT/nV4GL6i1r0ucqIr2Be4HTgFOBe31BpcmMMVH1B5wOfOH3+i7grkinK0znOgM7r9VmIMVZlgJsdp6/CFzrt33Ndh3lDztWZh5wDjALO9hyPxBT//PG9o473Xke42wnkT6HZpxzd2B7/bR31s8ZGARkAL2dz20WcGFn/ZyBocD65n6uwLXAi37L62zXlL+oK0FQ+2XzyXSWdSpOsfokYBnQ3xizB8B57Ods1hn+F08C/wv4JpdKBvKNMb4JmfzPqeZ8nfUFzvYdzRFADvCKU7X2soh0pZN+zsaY3cCjwC5gD/ZzS6Xzf84+Tf1cW+3zjsYA0eB0Hh2diHQDPgJuN8aEuktNh/5fiMhPgWxjTKr/YpdNTSPWdSQxwBjgeWPMSUARtdUObjr0eTvVIxOAYcBAoCu2eqW+zvY5NyTYebba+UdjgOjU03mISCw2OLxljPnYWbxPRFKc9SlAtrO8o/8vxgOXi8gO4F1sNdOTQE8R8Q0C9T+nmvN11vcAOuL9NjOBTGOM72YUH2IDRmf9nM8DthtjcowxFcDHwI/o/J+zT1M/11b7vKMxQHTa6TxERICpwEZjzON+q2YCvp4MN2DbJnzLf+30hhgHFPiKsh2BMeYuY8xgY8xQ7Of4tTHmV8B84Gpns/rn6/s/XO1s3+FylsaYvUCGiIxwFp0LpNFJP2ds1dI4EUl0vuO+8+3Un7Ofpn6uXwAXiEgvp/R1gbOs6SLdIBOhRqBLgB+ArcD/RTo9rXheZ2CLkmuB1c7fJdj613lAuvPY29lesD26tgLrsL1EIn4ezTz3s4FZzvMjgOXAFuADIN5ZnuC83uKsPyLS6W7B+Y4GVjif9SdAr878OQP/ADYB64E3gPjO+DkD72DbWSqwJYGbmvO5Ajc6578F+G1z06NTbSillHIVjVVMSimlGkEDhFJKKVcaIJRSSrnSAKGUUsqVBgillFKuNEAoFSEicrZvBlql2iMNEEoppVxpgFCqASJynYgsF5HVIvKic/+JQhF5TERWisg8EenrbDtaRJY68/NP95u7/ygRmSsia5z3HOnsvpvffR3eckYKK9UuaIBQKgQRORa4BhhvjBkNVAG/wk4Yt9IYMwZYiJ1/H+B14G/GmBOwo1t9y98CnjXGnIidR8g31cVJwO3Ye5McgZ1fSql2IabhTZSKaucCJwPfO5n7LtjJ0qqB95xt3gQ+FpEeQE9jzEJn+WvAByKSBAwyxkwHMMaUAjj7W26MyXRer8beC2Bx+E9LqYZpgFAqNAFeM8bcVWehyP+rt12oOWtCVRuV+T2vQn+Tqh3RKialQpsHXC0i/aDm/sCHY387vplEfwksNsYUAHkicqaz/HpgobH35MgUkSucfcSLSGKbnoVSzaC5FaVCMMakicg9wJci4sHOsnkr9iY9o0QkFXvHsmuct9wAvOAEgG3Ab53l1wMvish9zj5+3oanoVSz6GyuSjWDiBQaY7pFOh1KhZNWMSmllHKlJQillFKutAShlFLKlQYIpZRSrjRAKKWUcqUBQimllCsNEEoppVz9f+EfSTh5i4YWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 256us/step\n",
      "72.58733993530274\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJPCAYAAABhMuBTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3XvYJEV96PHvb7nrgoCgCF5WLoJghKjxjnAEop7EJIoQA0dAxUuM98QTNImCYjRI1HhFo7JGxQvGoCZHES8oeIkxeEVBFCEirooI7C6o0a3zR9VrZofpeavf7X6nZ/l+nmeenXeqp6q6q6v7N91dW5FSQpIkSdOtmHUFJEmS5oFBkyRJUgWDJkmSpAoGTZIkSRUMmiRJkioYNEmSJFUwaJIkSaowiKApIq6IiJsiYl1ErImI1RGxcsryp0fEZRGxNiIuiYjjxtJTRKwv+a2LiLeMpJ0cEf89krYuIvZsKOfQiNhQllkbEZdGxOMblr1/RJwXEddGxE8i4uyIuENtuRGxRUScGhFXl7K+HBE7NpS1c0S8NyKuKa93RcQOzVt4+SyhLY+OiM9FxI0Rcf6E9Glt+eyIuDwibijb7VURsWVDOatKXgv5XBERJ02p15tLe2+IiBPG0k6IiF+PteWhE/I4pJR56lLXf9a6bs+R5Y4v2+bEkc92jIi3R8SPy+vkKd/vrD3HlvtkyXfLkc9WRcSnyjpdEhGHT/n+aRHx/bJPXhkRf9W07HLroW8+MiK+UfL7XETsP5J2j4g4txyfFv3PAMf6+Q8i4pURscWE5W4XEe8u/f36iPhsRNxvbJljyrZfHxHnRMTOI2lPj4gvRcQvImJ1Rb2eU7bV9RHxtojYZrHvDMES2rrxnBoRu5Tt/NOIuC4iPh8RD5qS1+qI+GUp+9rI58X9GpZ9XtmH1kbE9yLieWPpbfre1LigK4MImopHppRWAgcBvw08f8qy64FHArcBjgf+ISIeOLbMgSmlleV14ljae0fSVqaULp9S1tWlXjsAfwn84+jBYcROwJuBVcBdgLXAmS3KPQV4IPCAUtbjgJ831OnUUt6ewF7A7YGTp6zDcmvTltcCrwZePmWZprb8MHCvlNIOwD2AA4FnLlK3HUvd/gR4YUQ8vGG5rwJPAy5qSP/8WFueP5oYEVsB/wD8+yL1qVn/Weu0PSNip5LHxWNJrwJuRe5D9wUeFw0/UkZ01Z5ExLHApKD73cCXgdsCfwW8PyJ2bcjmrcB+ZZ98IHBMRDx6kXVYTp20ZUTsA7wLeCqwI7kvfmgk2Pxv4H3AE1vU7cBSt8OAY4AnTVhmJfAfwL2BnYG3A/+2EBBExAHAm8jHz9sDNwJvGPn+1eTj59sWq0xEPAw4qdRnFfl4e0qL9Zm1rs6p64AnALuSzzt/B3w4Gn6gFqeVsu8I/BhY3bBcAMeVfB8OPD0iHjuS3qbv1cQFm2xIQRMAKaU1wLnkhm5a5kUppUtSShtSSv8OXEAONvqsV0opnQP8DLhZ0JRS+khK6eyU0g0ppRuB1wGN0fiochJ5NvCklNKVpaxvpJSagqa7AueUsq4H/gU4YCnr1afKtvx4Sul95INZ2/y/m1K6rvwZwAZg78rvfp580r5HQ/rrU0qfoDlwXcyfAx8DLlmkHkte/+XWYXu+DHgNcM3Y548kH2xvTCldQQ5AnlBZt01qz4i4DfAi4P+OfX434F7Ai1JKN6WU/hn4OnBkQzmXppTWj3xUvU8upw7a8mHABSmlC1NKvyKfSPcADinfvTSl9FZuHhjX1O0S8jH9Zm2ZUro8pfTKlNIPU0q/Tim9Gdga2Lcscizw4ZTSZ1JK64C/AR4dEduX73+gHMd/WlGV44G3ppQuTin9DHgJcELb9Zm1TT2nppR+XtpzA/k4+2tykLNzU34j+d4InEVzvzwtpXRRSulXKaVLgQ9SzptL6HvLEhcMLmiKiDsCjwC+U7n8dsDvcPPO+ZlyWfIDEbFqLO2R5bLhxRHxp5XlrIiIR5F/VX294isPmVCnpnJ/C/gV8JhS529HxJ9Nyfv1wO9HxE4l4DoS+EjNeiyntm05RWNblkvxN5BPwAeSf2UuVq8ol5cPIP+KWYrfLrcevh0RfxMb3865C/lk/+Il5j1IXbRnRNwXuA9wRtMiY+8nHmzH8uyiPf8WeCOwZuzzA4DLU0prRz77KlN+pETESRGxDrgKuDX5pDEoHbRlcPO2qmqvRTPOV/IPpqItI+IgctC0sB4HkNsHyD+sgF8Cd1tCVTbKq7y/fUTcdgl5zUxX59SI+Br5R8eHgLeklH5ckddKciBb05ZBbveFclv3vcXWoQtDCprOiYi1wPfJl/NeVPm9M8gb8tyRzw4hX07dj/wr6V9HTmrvA+5OvtT4JPIl/T+Zkv/uEXEd+aT8IuBxJSJuFBH3BF4IjN6fnVbuHcmXFO9Gvor0GODkiDiioYiLyAeKn5bXr9n4EvSsLbUtJ5nWlqSUziq3Qu5G3hd+tEh+15BvO7wFOKlcfWjrM+STw+3IAeufsHFbvwb4m/JLd3PQSXtGfkblDcAzyq/WcR8FToqI7SNib3LgeatFst3k9oyI+5B/3b52QvJK4Pqxz64Htm/KL6X08pJ+L+AdE74/S131zfOAQyI/97k18ALyMWmx9prmooj4GflW31u4+eMNG4n8HOc7gFPKFXdYQntNMZ7Xwvul5DULXZ5TSSndk/zoyDHAhYvk8RflvPkd8nY8oaLck8kxyUK7b0pbTlyHLgwpaPqjlNL2wKHkE+Qui30hIl5BPnkdndL/zDxcLs3+sty6eRY5ELl7SftmSunqcmn3c+TnTh4zpZirU0o7ppR2TikdlFJ6zyJ12pt81edZKaULRuo0rdybyr8vLpchvwa8B/jfDcWcDXybvPPsAHwXeOe0ei2z1m3ZZFpbji13GflXxWLB4y4ppZ1SSndPKb1miXW6PKX0vXIZ+OvkK0qPgfxwLLB9Sum9S8l7oLpqz6cBXyu30iZ5JrkvXEa+TP9u8tWaaTapPSNiBXmfeVa5zTRuHbmPjdqB/Mxio3KL/cvk9RnSczCdtGW5hXY8+TGEH5Z8vsni7TXNvUpb7pVS+uuGwBr4zZWEDwNfSCm9bCRpSe3VYDyvhfdLyWsWOjunLii36t5N/nFz4JSsTi/nzd1SSn9QrvhNK/fp5Gebfi+l9Ivy8ZLacrF12FRDCpoASCl9mvzQ2OnTlouIU8iXHH83pXTDYtmy8aXk2rRWym2ZjwMvSSm9o0WdvjbyWY0DgTellNaXqxln0BxgzUxtW7bNlub22pL8YPxyG63TYcB9yu3ENcAfA8+OiA/OoF6d6qA9DwMeNbJtHgj8fUS8ruR/bUrp2HKgPYB8fPpiB1WfZgfy7cL3ljr9R/n8qohYuFWw58IzMcWB1F/2n9U+OVUXfTOl9P6U0j1SSrclX8W4C/+z/XoTeQTbOcAPgKeMJV9Mbp+FZfcEtiH/yGxro7zK+x+llGqehxqMns6pW5EfjN9kEfEEygP3KaXRoLt132u5DkuTUpr5C7gCOHzk713JT8If1LD888m/Ru8wIe0A8gNvW5Av770auBTYqqT/IfkhtiCP0PkBcHxDOYcCV1Wuwx7kKz7Pa0ifWi75ls+byB387uTLqYc15PUp8q2E7crrDcBnZ92OS2zLLYBtyaNwPlPeL7TVYm15InC78n5/cmd6ZUM5q8jBzZaV67F1qctnybdTtwVWlLRHALcv7/cDvkF+WBHy1b/dRl7vJY8K27nt+g/h1XF77ji2bT4HPBe4TUnfizxKZouyja8BDuizPUt/HK3T75R89wC2Lt/9AvmEsy3wKOA6YNcJZawgn8RH+/kPgWfOuh27bsuSfu+yzK5lPz9rJC3K8vuX7bktsM2UuiVg74p12Ip8hemcSW1PPmbcQH425tbkK/DvGUnfstTlZeRbe9s27UPk0VxryjrsBHwSePms27Gntp52Tr0/8ODSh7YjjyJfC+zekNdq4NTKeh5btvHdG9Kr+t5i69Dptp11405q4PLZG4F/blg+Ab8gX75beL2gpD2UfGJdTw48zgH2Gfnuu8nPAa0jj2xqPKDRLmh6UanXaJ3W1ZZLPkh/tKRfDjxlbMe6eOTvu5YDx0/Jz3N8dHQd56wtTyjbbfS1urItzyQ/w7S+lPsKYNuGclbR7iR7/oR6HVrSTh8p93Ly7bmJgQ5jB5AJbdm4/kN4ddmeDdv4xJG/jyY/t3Yj8BXgYVPq1Vl7LpZv+ex88q22S9n4ZPSb9iQHTR8tfXId+erGC4CYdTv20Zbk51rWlvV9E3DrCdtx9HXFlLrVBk2HlGVvZONj7cEjyxwD/Ffpnx9k5AcL+bmZ8XqdXNLuXPK688jyzyX39RvIx5vGwG9IryW09bRz6iHk54MW2vrTwEOmlL2a+qDpe+T/nmK03DPG9qNF+95i69DlK0phkiRJmmJwzzRJkiQNkUGTJElSBYMmSZKkCgZNkiRJFQyaJEmSKkybpbhzG9bsM3Go3sN2nzyP4LlXf2Xi55OWb1q2raa6NGlbbhd1b7u9Vux2WSf/eeeoprZs0na7TtJmf5i2/Cx0sY8DnLfh7M7bEuCIFUcNfhht223Vdz5d6KM9m9qyz/Xuu6910cZ97yf2zZubRZ/qSlN7eqVJkiSpgkGTJElSBYMmSZKkCgZNkiRJFQyaJEmSKizr6Lm2T9K3Wb7vEVRDGh0wpFFhm6rPdRlS28zzyL822tS7q/bpc1Rd33XsQ9uyuqhb3yPT+hyl3FTmPI/8Wm63pG3llSZJkqQKBk2SJEkVDJokSZIqGDRJkiRVMGiSJEmqsKyj52Yxgqht3rMYbTePI6hm0WZN+h7Z2Gdbtp/fauLHm5Uh7fdd7VvL2Z5dzXM4DyNbZzFv3tBHig1ppPfmyCtNkiRJFQyaJEmSKhg0SZIkVTBokiRJqmDQJEmSVGFZR881mcWIq67MYp6nJvM44mpI88N1NWqvTd59j+Ks1dUIojZzfg1NnyOx5nHkUpu27HsEWhcjArsaJTj0/XlI+9rm1B8WeKVJkiSpgkGTJElSBYMmSZKkCgZNkiRJFQbxIHgX+n7gbEhTnQypLuNm8TD1LKZLmbb8cufdhb6nf+kij1k8VNq2zCE84NrnvtZ323S1vbtYpyZDOM7OiyH0h655pUmSJKmCQZMkSVIFgyZJkqQKBk2SJEkVDJokSZIqLOvouT5HOfU9CmkW0580aTvCZHOZRqXv0VZdjBSb15E1fY5M63sKma6m8Oiz7ZZzv+hz/YY25UgXfXNzm+pjc1sfaHfO75tXmiRJkioYNEmSJFUwaJIkSapg0CRJklTBoEmSJKnCso6em8XolKHM7dWlIYyC6HOERld59718n3kv90jIvufv66LMWcwvObTRYptShyEdC2cx39uQ1r9PbdZzCOeSGkOqp1eaJEmSKhg0SZIkVTBokiRJqmDQJEmSVMGgSZIkqcKyjp5r0sXcYV3NP9Wkz/mt5mG0y7hZjLaa1XaaxciN5W7jvuf1a5NH32YxB9uQ54XsYrRVVyMbhzRv2uY0xycMawRakyG1fxOvNEmSJFUwaJIkSapg0CRJklTBoEmSJKmCQZMkSVKFQYye68IsRnNNK7eLkX9DGCXXVtvRD32OtprFSJ8+50GD5R+hMw/zkjXpYkTgrI4rfehz1GBXI1i76rNdzIG4OR2X50Wfo+S6Ou57pUmSJKmCQZMkSVIFgyZJkqQKBk2SJEkVDJokSZIqDGL03DzOvbagbV26mM+pyVBGXC23rvaHPuc96ntuxCGb1bxksxiJ02Qe+2YXI1u7Gpk2i1HKbfefvtpyHuZjmwddbS+vNEmSJFUwaJIkSapg0CRJklTBoEmSJKmCQZMkSVKFZR09Nw9z/MxivrKuDGFUYZ/bo+9Rhk26GKEzD/t+G2224ZD6SNv8h94ObfS5D7Zt41n0h81pHsGuODKvPa80SZIkVTBokiRJqmDQJEmSVMGgSZIkqYJBkyRJUoVlHT3X1aiDLuZE6koX+Xc1+msIozq6GI3R1ciNvkeAtJlHsMlQ5rfqe46wLurSlTbr2vdo2j70WedZHWP6POYN4bg5TZ/71BD21+XSVZ/1SpMkSVIFgyZJkqQKBk2SJEkVDJokSZIqLOuD4G118YDirKZwmMWDi01l9vXwcJs6dDEVSVf6fIh36A+VNulq+pdNXXaaIT2UPbSpYfooaxYPxneVf5u6D3lgTd/67jtDGjDRVZleaZIkSapg0CRJklTBoEmSJKmCQZMkSVIFgyZJkqQKkVJatsKOWHHUxMK6GKXQ92iWeR5hsWK3y6LrPDes2afVjtPnaIm+R072OYqz/UjIsztvS2huzyFNszCLkT59H1eWs28OacTfLPpmV3k3Ld9HW0LzefOWru/jflN7eqVJkiSpgkGTJElSBYMmSZKkCgZNkiRJFQyaJEmSKmz2c8+1zbspn3kYJbecutp+XYx+6XuE1y2h7WcxurHJPM8R1nY7Lue8kH2OUu5z7sIu82mTt+rNw8jWJm3nbPVKkyRJUgWDJkmSpAoGTZIkSRUMmiRJkioYNEmSJFVY1tFzbUc6zGK0R9/5T1q+//nKJn682ei7Lbswi31/KPqeZ6zPEVp9z2/Vh75HrM3CkEb+3ZLNalvNYo7BJl5pkiRJqmDQJEmSVMGgSZIkqYJBkyRJUgWDJkmSpAqRUpp1HSRJkgbPK02SJEkVDJokSZIqGDRJkiRVGETQFBFXRMRNEbEuItZExOqIWDll+dMj4rKIWBsRl0TEcSNpu0TEZyPipxFxXUR8PiIeNPb955Ryro+It0XENg3lrIqIVOq1rtTzpIZl7xYRH4yIn0TEtRFxbkTsW1tuKetTEXFjWafDp6z/NuX7N5T8ntu07NB02dYl/c0RcWlEbIiIExYpe3VE/LKUfW1EnBcR+zUs+7yI+EYp93sR8byRtNtFxLsj4urSlp+NiPtVrPvWZR2uWmzZoVhCex0dEZ8r+/H5Y2kHj/SlhVeKiCNL+mNLW14fET+OiLdHxA5TykoRsb7k84OIeGVEbNGw7Esi4usR8auIOHks7QVjdbqp7E+7lPQ9St++NiKuioinLrLNnlH2mRsi4ksR8eBpyw/FEtr6tIj4flnPKyPir0bSprb1hLza9M1nR8TlpdyrI+JVEbHlSPpBEXFB2Y+uiogXTlmHiIhTy/5zfUScHxEH1G2x2VpCey35WBoRZ4y15S8iYu2Usqr6ZlQcSyPimLJ/rY+IcyJi57H0x0bEt0r6dyPi4Cn1qjr3T5VSmvkLuAI4vLzfDfgq8NIpy58C7EcO+u4H/Ax4YEnbFti3pAXwR8C1wJYl/WHAj4ADgJ2A84GXN5SzCkgj330AcCPw8AnL3hd4IrAzsBXwEuCSkfSp5QKfB14JbAccCVwH7NpQr5cBF5R87g6smVSnIb66bOuS/mfAYcCXgBMWKXs1cGp5fyvgXcAXGpb9v8C9yFMN7QtcCTy2pO0JPBe4A7AF8GTgGmDlIuX/FfAZ4KpZt0OP7XU4cDTwQuD8RfI+FFgL3Lr8fSdgl/J+ZWmf10z5fgL2Lu/3K/3gqQ3LHg88AvggcPIi9ToZ+OTI358CXl369YHk48n/avju/YD1wL3Jx58/BX4CbDHrtuyhrfcdabs9gIuBR9e09YT0Nn1zL2DH8n5n4JPAc0fSvwm8tPTNvYAfAn/QkNfRwNWlT29BPrZeNOu26Km9uj6Wvm1KelXfZJFjKfl8uRZ4SDkmnAW8Z+T7R5CPzfcv67UHsEdDnarP/VPXfdYNP9745e/TgH9r8f0PAX8+4fMVwCNLA96ufHYW8LcjyxwGrGnIdxUjQVP57D+Av6io087lu7ddrFzgbsAvgO1H0i+YtJOVtB8Avzvy90tGd6Qhv3ps6wsrO/qpI3//HrCustzXAK+dkn4DcO8p6XcFvkU+cc9l0NSmvYATWTxoOhM4syFtJfBPwP+b8v3fHJjL32cDr1ukzHcyJWgiBzrfBY4fqUdi5AcM8GbgHQ3f/2PgiyN/37p8/w6zbsu+2rosuwfwdeD/tm3rkr6kvgncFvg48IaRz24E9h/bL57f8P2/BN438vcBwM9n3RZ9t1dZfknH0rJPrwUOmbJM6745suxvjqXA3wJnjaTtBfyScq4EPgc8sTLf6nP/tNcgbs+Niog7kk8s36lcfjvgd8i/ckY//xrwc/KO8ZaU0o9L0gHkiHzBV4HbR8RtFyknIt/mOwD4ckXVHkJukJ9WlHsAcHlKae1Y+s0uE0fETsDuE/Kai0vKo7pq6yWWvRI4loq2jIgADm4qNyIOArZm+nq8FngBcFPryg5E2/ZaJK9bAY8B3j72+YMj4nryQflI8hWemvz2J7dRTd+c5mDg9sA/L2Q99u/C+3s0fP8jwBYRcb9yO+IJwFfIv7TnRm1bR8RJEbEOuIp8Mj1rwjIT23pKnov2zXLL5gbyVYkDgTeNJL8aOC4itor8iMQDyIHVJO8B9o78eMVW5CuSH62p55As87H0SPLV089UllXdNyccSzc6b6aUvksOmu5W+td9gF0j4jvlVuzryrpNsqRz/7ghBU3nlHuk3wd+DLyo8ntnkFf+3NEPU0r3BHYAjiFHzgtWAteP/L3wfvspZVxDviT/FuCklNInplWo7MCvJ192rCl3PG0hfVKdVo6kL7bsUHXa1i39RURcR+6UK4ETKr5zMrmvnDmeEPmZm3cAp6SUxttwYZlHka9W/ssS6zxrS22vaY4k96tPj36YUrowpXQb4I7AK8i/pqe5KCJ+BnyY3D9v1kYtHQ+8P6W0rtRnLfBZ4G8iYtuIuFep+60avr+WHHBdSL56/CLgyan8tJ0Drdo6pfRy8rHnXuR+MKkPTGzrCar7ZkrprJTSDuSr9GeQb7ss+FdykHYTcAnw1pTSfzRk9UPyVf1Ly/JHAc9ZpJ5DMotj6fHAP1Xs0636ZsOxdNq58fbkW+aPIQdlBwG/Dfx1QxFLOfffzJCCpj9KKW1Pvve9H7DLYl+IiFeQf/EdPakBU0o/Tym9GzgpIg4sH68jB1MLFt43PtRGfs5ip5TS3VNKr1mkTrsCHyNfLn73SNK0csfTFtIn1Wnd2PenLTtUnbd1C6enlHZMKe2WUvqD8stlWrlPB44Dfi+l9IuxtO3IB4QvpJRe1vD9W5Mvmz9jE+o8a63bq8LUA29K6QfkX/zvWSSfe5W+uVdK6a9TShuWWqHSnkdx8ysix5Jvr34feCP5eZumh/lPJF9dOoD8i/n/AP8aEbsvtV7LrHVbp+zL5KDjlAmL1J5kW/XNUvZl5KslbwAoDwl/FHgx+fnWOwEPi4inNWTxIvIVlzuV5U8BPlmujs2DZT2WRsSdgEPIt84XU903pxxLp50bF67avzal9MOU0jXk54L/d0MxSzn338yQgiYAUkqfJt/fPn3achFxCvly5O+mlG5YJNutyA+cQe5gB46kHQj8aOQ22pKVW2cfAz6UUnrpWPK0ci8G9oyI7cfSb3bpNKX0M/Kvo/G8NvmW1XLrqa07ExFPAE4CDkspXTWWtg1wDvn5sqdMyWYf8rNxF0TEGuADwB3KCI5VPVS7N7XttZhy4D2UxQ+8W5KfYVgujyZfUT5/9MOU0pUppd9PKe2aUrof+TmaLzbkcSDw4ZTSt1NKG1JKHyX31wf2WO/OLbGtb9ZeLdp6U4yWuyfw65TSP6WUflX67XtoPpEeCLw3pXRVWX41+SHh/Xusb+eW8Vh6HPC5lNLlS/huU52mHUs3Om9GxJ7ANsC3y7nwKvLzUzW6Ofe3fQiqjxc3f6BtV/IIlIMaln8+cBkTHq4kP0X/YPKvvO3ID/qtBXYv6Q8nP1+wP7lzfJLK0XOLrMMO5APpxIfdFisX+AJ5h98WeBTTR8+9nHypeyfyr4sfMoej5za1rUv61mWbfRZ4Unm/omHZ1Yw8bLpIPY8t7XX3CWlbkX8VnbPYvkE+oO828no0ebTObszZiKrK9tqitMFTyc88bAtsNbbMC4DPNGzzO5OfGbpL2cc/MKVuGz1sush6bFXqchZwanm/xdgyHwNePOG7dydfwl+4cnTNlL55PPBt8sk7yKN7bgT2m3VbdtnW5B/cTynHoCCPHv4h8Myatp6QX5u+eSL/M7Bnf/LJ8JXl7x3Ix85jSh13I49MnjiqjHyl6ULyrZ4VwOPKOu846/bosr1K+iYfS8m3MZ9QUbeqvskix1LyFdsbyLffbk0eyDE6eu7F5MFZtyv74gXASxrKqj73T63zrBt+UuOXz94I/POUBvkF+XLbwusFJe0Q8r3ateRfjZ8GHjL2/eeS74HfQL7Puk1DOauoD5qOL8uuH6vXnWvKLWWdT77keOlYZzgWuHjk722At5V8fsTIcNuhv7ps65J+fllm9HVoQ16rqT8wfw/477FyzxjZxxL5ZDiafnBJP5iGkT/kX91zO3quor1OmNAeq8eWuYQJI17Iw8SvKn3oKvIotdtOqVuboGn1hHqdMJK+B/CrSfkBzyY/+LqefIK9z1j6aNsH+UD+X+Rj0LeAx826Hbtua3KA8VHyMXYdOVB8AWU+08XauqF9avvmmeTj3vpS51cA246kP5R8Ir2efJL8R+BWJe3OjByXyYHB68kB3w3ARczpD9Bp7VXSNulYSn6gfj0jo7yn1K02aJp6LC3LHFP603ryfxmy80jaVuRbs9eVtn7Nwr4w3tbls6pz/7SXE/ZKkiRVGNwzTZIkSUNk0CRJklTBoEmSJKmCQZMkSVIFgyZJkqQKWy5nYUesOKrVUL1zr/7KJpf5sN0ParV8U5lN+bRdvk9NdVmx22UxMWETbFizz8S2nMV6z4Ou9pPzNpzdeVvCbPpmk7Z9re982uTdZDn7Ztu2bDKpzkPr323asu+6L3ff7Ko/dJF3F2V2pe9jrVeaJEmSKhg0SZIkVTBokiRJqmDQJEmSVGFZHwSfh4em29alz7p39aDfeRu6qE1dWZpsXrfXLB6abptPnw+I9133PvrmPJiH4++8msU26WqgVJvlZzVoyytNkiRJFQyaJEmSKhg0SZIkVTBokiRJqmDQJEmSVGFZR8+11ec0CG3NokxtrO91+NdMAAAgAElEQVTRl7OYlmAoo3/6rF+f23Xa8kNap3nU5745lP1+HvS5r3XVR9rWcRbr1BWvNEmSJFUwaJIkSapg0CRJklTBoEmSJKmCQZMkSVKFQYye6+IJ/lnMfdOVvkcXbS76Xu9b6naF+R4p5Si5fvQ5F98sDH0Ea5NZjA6e1dyATeUOqR96pUmSJKmCQZMkSVIFgyZJkqQKBk2SJEkVIqW0bIVtWLPPxMK6eCi77wfF+nzQvO/pYlbsdll0ktGII1YctXw7jn7jvA1nd96W0F3f7CKPoS3fp+Xsm1083DuvD1Mvh+Xum036bM+++1QXde9KU9/0SpMkSVIFgyZJkqQKBk2SJEkVDJokSZIqGDRJkiRVGMQ0Kk26GIHWZEj/LXuTrkaknLehk2zmjiN9+tOmb7bta32P0JmHqZL6KGse9vsh1X1IdZmki3Ne31O09HlentUIP680SZIkVTBokiRJqmDQJEmSVMGgSZIkqYJBkyRJUoVlHT03DyPc+h6h00XeQxm9MRRDH+UyD/rcVl2Nculbn6Nym/LpY2TrLNqySdvtMQ+jrYauz/WZ1Tm8zXyzfbebV5okSZIqGDRJkiRVMGiSJEmqYNAkSZJUwaBJkiSpwrKOnpuHUWJd1bGLUQN95r05GdIol3nYx9voe/RTF2U26aL/zGJOrc1J3/t3F3MgDr0P9qnvbdL33Habuiy0H9nqlSZJkqQKBk2SJEkVDJokSZIqGDRJkiRVMGiSJEmqsKyj55p0MSfQrEZGtC23z1EAt1RDGhUzryMe+9yGQ2qftuUOvd3m1byM2hqCWcyZ19V5bUijy7vaJ7zSJEmSVMGgSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRWWdfTcPIwCaJtP3+V2UeZyljWkEWtDMg91nKSLUTHO09Z+fqt5M4s5Cm8pZtEfuhr11udcnLM6TnilSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRUMmiRJkios6+i5IY2KGdLor662y3KO0BnSdprnkThDWae2o2W6mBeyq7r0ua26yntIx74+zHMfHLo+R7INaS65vnV1/PBKkyRJUgWDJkmSpAoGTZIkSRUMmiRJkioYNEmSJFVY1tFzbXXxRH7fT/v3Oa/WLXVEyqzmC7wlz5vXVX/oYoRO3/M8drF/zcNooVpDGcGpyYY072nf+32fde8qFvBKkyRJUgWDJkmSpAoGTZIkSRUMmiRJkioM4kHwPh9Q2xz/O/gm81z3UV09gOqDrJtuFlOU9D0QoE25fe+LfUxx1JU+t0ebMrsqd14feO9zGpWu6tJnmU36HmDSxCtNkiRJFQyaJEmSKhg0SZIkVTBokiRJqmDQJEmSVGEQo+fmedRX2xEZ8/Bf2UsLZjHipit9jpAd+oirNmZxTOpq+7U5/vY9+vKWoO/px9qMfGt7jnX0nCRJ0jIyaJIkSapg0CRJklTBoEmSJKmCQZMkSVKFSCktW2Eb1uwzsbAu5qByRFmzFbtdFl3necSKoya2pSNO+nXehrM7b0to7pt96nsEVVtt6tPVaLE+2rOpb6pfy903ZzEf35DmhWyrbR2b2tMrTZIkSRUMmiRJkioYNEmSJFUwaJIkSapg0CRJklRhWeeea/v0epvl+55vps9yZ1X3PjhKrp1bwmjDrvbvPudzhG7mt9Km6XNU1dBGa26qPrdVV+vY5/FtVu3plSZJkqQKBk2SJEkVDJokSZIqGDRJkiRVMGiSJEmqsKxzz0mSJM0rrzRJkiRVMGiSJEmqYNAkSZJUYS6Cpoi4IiJuioh1EbEmIlZHxMqK7+0cET+JiAsb0l8UESkiDq8s+0cRceZiZUfEPhHx84h458hnh0bEhpLPwuv4KXlsERGnRsTVEbE2Ir4cETsuts5D17YtI+L0iLisbINLIuK4sfSHRsRFEXFDRFweEU+ektfJEfHfpezrIuJzEfGAhmWPj4j/LPleFRGnRcSWY8s8NiK+FRHrI+K7EXHwlLL3jIh/LetxTUSc1ryVhmMJ7XV02a43RsT5U5Y7vvS9E0c+2zEi3h4RPy6vk6d8f1X5/kJfuiIiTpqy/Jsj4tLSB0+YkN7YPhHx9Ij4UkT8IiJWN5VRln1sKef6sg5vj4gdpn1nKJbQ1qdFxPdLH7kyIv5qJO1uEfHBcvy9NiLOjYh9p+S1OiJ+Wcq+NiLOi4j9GpZ9XkR8o7TV9yLieWPpB0XEBaUNroqIFy6y3vbNnJ7KsWyhT71lJG302Lnw2rOhnNFz3drSHx7fsOzWEfH+si4pIg6dstwlEXHVyGdt97Gp55JacxE0FY9MKa0EDgJ+G3h+xXf+DvjWpISI2At4DPDDFmXfC/gd4K8XWf71wH9M+PzqlNLKkdfbp+RxCvBA4AHADsDjgJ9X1HUetGnL9cAjgdsAxwP/EBEPBIiIrYB/Ad5U0v8YeGVEHDglv/eWsncFLgQ+EBExYblbAc8GdgHuBxwG/MVCYkQcQd6/Hg9sDzwEuHxSgRGxNXAe8ElgN+COwDsnLTtQbdrrWuDVwMubFoiInUoeF48lvYq83VcB9wUe13SwHbFjqdufAC+MiIc3LPdV4GnARRPqs1j7XA2cCrxtkboAfBZ4UErpNsCe5KmqTq343lC0aeu3AvullHYgH6uOiYhHl7QdgQ8B+wK3B74IfHCRsk8rZd8R+DGwumG5AI4DdgIeDjw9Ih47kn4W8BlgZ+AQ4E8j4g8mZmTfHHfgyPnpxLG0946dvyYe74qrS712AP4S+MeI2L9h2QuB/wOsmZLf88j7xKi2+1jjuaSNeQqaAEgprQHOJe8kjSJfQbgHcGbDIq8jN+YvW5T9A+AjJd+mch8LXAd8ojbfCXnsRD5hPymldGXKvpFS2lyCJqCuLVNKL0opXZJS2pBS+nfgAnIgCfmguAPwjrKN/oMcJDd1ztF8/xt4O/lAedsJ6W9MKV2QUvplafd3AQ8aWeQU4MUppS+Uuv2gLDfJCeSDyCtTSutTSj9PKX1tsToOTWV7fTyl9D5yoNHkZcBrgGvGPn8k+cR5Y0rpCvJJ+QmVdfs8OQib2DdTSq9PKX2CyT88TmBK+6SUPpBSOgf4aUU9vp9SGl2vXwN716zDkFS29aUppfUjH22grGtK6YsppbemlK4tfe1VwL4RcbO+NiHfG8mBT1NbnpZSuiil9KuU0qXkE+Vo31wFvCul9OuU0nfJJ+UDGoo7Aftmn/VKpe/8jAnH5XJ8fXVK6UJyX7mZiLgrOah62dh3W+1ji5xLqs1d0BQRdwQeAXxnyjJbkK/2PB242f+pEBFHAb9MKf2/lmXfCfjfwJcb0ncAXgz8eUMWt4t8i+97EfGqiLh1w3K/BfwKeEy57PrtiPizNnWdBzVtObb8duQrfRcDpJR+BLwbeHzk25kPAO5CPkgultc25APmVWMnuSYPWSi37F/3AXaNiO+UWwCvK/Wb5P7AFRHxkXL5//yI+K2KMgelbXs15HFf8rY7o2mRsfeNP1BG8oyIeBD5xDixby6i0/aJiAdHxPXAWuBI8q/7uVLb1hFxUkSsA64Cbk0OdiZ5CLAmpbRo4FluMR1LRVuWq8QHs/FVy1cDx0XEVuV2zQOAjzdkYd/c2GfKOecDEbFqLO2R5TbYxRHxp5X1WhERjyJfFfr6Euv0WuAFwE2LLNdmH9voXNJKSmnwL+AKYB35IJTIV3F2nLL8c4A3lvcnABeOpK0ELgPuOpL34RVlXwdcCbwB2K5h2X8A/rK8Pxl450jabuRIewVwV/Ll4zc15HNMWc+3AtsB9wR+Ahwx67ZY7rYc++7bgY9S/n+x8tkjgR+Rg8xfka/ONX3/ZPKVxevIl3o/Cdy7otzHk08Ku5S/dy91/xJwB/ItvM8CL234/seA/yYf1LYmX2q+HNh61u3RV3sBJwLnj322RdlmDyh/nw+cOJL+TuAD5NudewPfBX7RkP+qUp/ryL9ivwU8s6JeFwInLKV9yLfZVrfYdnuUfe5us27Hnts6yLeGTgG2n5B+R+AHwJ9MyWM1+SrgdeTbNB8C9qoo+xTyrddtRj57IDl4+FVZj1OmfN+++T+fP6Rsgx3Jd2K+AWxZ0vYnH/e2KNv3h03tCRxKvup4HfmW4FeAx1bU6yrg0LHPHgV8dCTfqxq+u+g+Nrb8zc4l1dt91g3fYuc4vLw/pGycvRuW3R34HrBz+fsENg6a/h544aS8Fyt7kToeRI5aty5/n8xI0DRh+fsDP21Ie1TpBHcZ+ey1wKtm3RbL2ZZj33sF8J/ADiOf7QfcCDyMHIzuSw6If68hj6lt0vCdPyIHZb818tlOpX2OH/nsSODLDXl8EPjUyN8BXE9+fmDmbdJTe00Kmp4BvG3k7/PZOGjamXwbdE3pS6cC323If1Vpgy1brs+koKmqfWgZNJXv3B+4aNbt2Gdbj3z/JOCVY5/tCnwT+KtFvrsaOLVlfZ9OPtbfcWwfuoH8zNOW5JPpF4CnNeRh35y8zBbkZ4B+qyH9JOCfG9IOpSG4WaTMjYIm8pXLy4B9puVbu4+NLH+zc0mb19zdnkspfZrcwU5vWOS+5F//34yINeSrP/ctlxy3ID/Q+8zy9xrgTsD7IuIvN7Fqh5IP5P9V8v0L4MiIuNmDpwurwsa3IkZ9bWSZzVZFWwIQEaeQfwn+bkrphpGkewCXppTOTfk+9aXAv5VlN1l5qPgfyQ9b/ubSckrpZ+QOXts+X2ux7GDVttcUhwGPGul7DwT+PiJeV/K/NqV0bEppt5TSAeRA+IsdVH0xfbbPlsBePeXdmyW29UbrWp7N/BjwoZTSS7usX0Q8gXziPiyldNVI0p7Ar1NK/5TyM09XAe8hP1YxiX1zSrY0n6OmpXVlH/I59YJyvPgAcIdy/FgF7fexKeeSerOOlisjwysYudpDjizXAwdNWHYb8q2whdezgH8Hdivptx1L/z5wFLCypuwpdbzVWL6nA+8Hdh2Jku9M3tHuBHwKOHNKfp8hjwrbBrg7+XbSYbNui+Vsy5L+fPKvjTtMSNuLfHn6oWW77kW+LD/xFh0trjSVPH8KPKQh/cXkEZK3I195ugB4ScOy+5KviB1O/gX3HPKtp3m5BdCmvbYAtgWeWvbhbYGtStqOY33kc8BzgduMtOdtSx6PID8ofkBDOatocaWJfNthW/Jt1CeV9ytq2occDGxLfhD1HeX9xHLJz+Is9PO7AJ8GPjDrduy6rckB7VPKvh/kH6s/pNwiJQ/Q+CLwusqyV1N5pals4zXA3Sek7UC+LXRMqeNuwOdpvnVu38xpB5DvlmxBfoTl1cClI+l/ONbWP2DkSvtYOYfS4koT+Ry3LfmH6O+W91H63ejx4tHkh9h3K/Vsu481nktabfdZN/xSdo7y2RtpuDw4ttwJjNyeq8m7TfqU753Mxs80PbfsaDeSA7XXMnL/nzwq7wUjf+9Bvue6jnyP/SmzbodZtCX5xPiLsh0WXqPb6Wjyvfe1pdP9HeVkuFibLFLPT5GfiRgt9yMj6VuRn29beAbjNcC2Je3OZfk7jyz/aHJAdwP5ttTEYGBoryW01wmlzUZfqxuWPZ+Nb88dXQ6KN5Kfg3jYlHqtol3QdP6Eeh1a0z5lvxn/7smT2hp4adkP15d/3wzcdtbt2HVbkwOSj5KfWVkHfJv8sO7CfKbHl+20fqwP3bmh7NXUB03fIz+HNJrvGSPpDyX/oLm+9M1/BG41qb0Wa/shv7rsm2WbXVra68fAOZTbYiX93eQfkeuAS5jy/CDtg6YrJtRr1WL5LraPkYPri0eWn3ouqX05Ya8kSVKFuXumSZIkaRYMmiRJkioYNEmSJFUwaJIkSapg0CRJklRhy+Us7IgVRy37UL1zr/7KxM8ftvvkeQ3bLt+Fvss8b8PZnf8nZF215aR173Nbz7s+2hJgw5p9WrVn2/7Tha72iy7q2NXxY8h9c551cVwZQltCv+3Z1bmn7/Nsn322SVN7eqVJkiSpgkGTJElSBYMmSZKkCgZNkiRJFQyaJEmSKizr6LlZjExrm/c8jNyaxXbcVPNY58X0OfKvz1FobXQxmqWrkTjzsA/NYlShbq7NPjEP+1VfuhrdNotRcn2P8GvilSZJkqQKBk2SJEkVDJokSZIqGDRJkiRVMGiSJEmqsKyj5+ZhNMI8jKSYxxE6s9h+fbdlFyN02uZ93oZW2WxyeV3Uu6t1b9L3SJ8+69JXe7bRRT/pew6zttqUO6RjextDmie1b22OK333e680SZIkVTBokiRJqmDQJEmSVMGgSZIkqYJBkyRJUoVBzz03i1EdfdalSd/z/wxhhM4sDGlUzJDqMkmfo5/6Hu3Z52i7IY9I7cosjmF91uWWos++2VWZberSNv++R9k2nTe90iRJklTBoEmSJKmCQZMkSVIFgyZJkqQKg55GZUjThQzpv6afh6lehmAWAw/mVZ9Ty2yOD1N3tW9tLjbHvjP0derzIfu+17GL/GfVp7zSJEmSVMGgSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRWWdfRcV4YyeqErXf138Ju7rqaVabK57VdtdDUSp00+fU+D0FW5m4t5mApqSIZSxz77Zt/T3/Q5PVPbunTFK02SJEkVDJokSZIqGDRJkiRVMGiSJEmqYNAkSZJUYVlHz/X5JP2sRuLMwjzUsQ+31PXeXPU9GrILbUcFtV2n8zYsrV5L0ecIp3k+nt5S9Dn33Czm+ZzVOd8rTZIkSRUMmiRJkioYNEmSJFUwaJIkSapg0CRJklRhWUfPdfUkfZ9zJbXV1aiBLvJwpMrG5nk7Lff8gn3PQdVF3kObD6uNIc8XOaTj6SwM/TgxpP1yVttkSPuoV5okSZIqGDRJkiRVMGiSJEmqYNAkSZJUwaBJkiSpwrKOnmsylFEKS9HnKLmulr+lcjvVm8Xorr73+3mYU205554b+iixWdnc1r+LvtzVyNM+97lZ7c9eaZIkSapg0CRJklTBoEmSJKmCQZMkSVIFgyZJkqQKgxg916TPEWh963N0QJ9l1pqHkTh913FS/n2P8FrO0VbT3FJG6PQ9R+VyGlLf1Kbr4vzQlMcQ9tfFdDVfZlteaZIkSapg0CRJklTBoEmSJKmCQZMkSVIFgyZJkqQKyzp6ru0ol1v6aI8hr/+Q67ag7zoOaXRWX/ocsdbVKJd5GA2pTTPkkcSzMg/rOIv5IvueF9IrTZIkSRUMmiRJkioYNEmSJFUwaJIkSapg0CRJklRhWUfPzcPT/qozpNEs8zAP3tDNYlv1PTJtHva5ocwl2Je+++YtoY93tQ37nC+yzzK7yqerueq80iRJklTBoEmSJKmCQZMkSVIFgyZJkqQKy/ogeJ98GHh5p3AY0nYdUl3aGsq0G31OcTSrvtnFOrXNYx6PQ33WeR4e+B56m81iG/Z9XOrioeyuHuxuysdpVCRJkjaBQZMkSVIFgyZJkqQKBk2SJEkVDJokSZIqDGL0XBejF4Yy0mEpuhq90XYUwBBMWveu2nLoo2Jg85t2o8/27HsKhy7qPqR9q1YXdZ7VaKs25uF4MEmf9e57dOgs+n7fI1u90iRJklTBoEmSJKmCQZMkSVIFgyZJkqQKBk2SJEkVIqW0bIUdseKo5StMv3HehrOj6zxn0ZbzOvqlS320JcCGNfu0as+u5n1qk/cs9D0qbMVul828b26O/arPUZxNhtI3h2QWczR2lXdTe3qlSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRUMmiRJkioMYu65W5JZjOpYTn2OiticttNi+h61Na7POaL6Xpc+8+9qlOCQ54XcHPvV5rROfc+52IU+R9O2zafvunilSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRUMmiRJkios69xzkiRJ88orTZIkSRUMmiRJkioYNEmSJFUYfNAUEVdExE0RsS4i1kTE6ohYOWX50yPisohYGxGXRMRxDcsdHxEpIk6cktf5EfHzUvY1EfGBiLhD23Ij4uCSx+grRcSRDXkdHRGfi4gbI+L8xo2zGVpCe1dvq4g4NCI2lLzXRsSlEfH4KcsfVtryxoj4VETcpbLe6yLiY1UrPHBd97+IeHPZ7hsi4oSxtHtExLmlry36sGXpQ+tL3X4QEa+MiC0mLHe7iHh3RFwdEddHxGcj4n4j6b8XERdGxHVlHf8xIrYfSb94rO/+KiI+XFG/M0sd915s2eWwnMfSyP4uIn5aXqdFRDR8v7pfRsT9I+K8iLg2In4SEWePHpMj4tkRcXlE3FDa+1URseVI+ksi4uulDU9eZHt9ZKzdfxkRX5/2neXUZXtGxC6lX/y09IPPR8SDRtJn1Tf/V2mv60rd/iUi9hhJ3yMiPlj2h6si4qmL1OuYiLiy1O2ciNh5sXW5mZTSoF/AFcDh5f1uwFeBl05Z/hRgP3JAeD/gZ8ADx5bZCbgE+AZw4pS8zl9IB3YGPgm8Z6nljix7KLAWuHVD+uHA0cALgfNn3QYDb+/qbVW2+1XlfQB/BPwK2H/CsrsA1wNHAdsCrwC+UFPvzenVdf8D/gw4DPgScMLYd/cFngj8YT40LVq3BOxd3u8HrAGeOmG5PYHnAncAtgCeDFwDrCzpxwAPB25Vjg0fAc5oKDOAy4HjFqnbg4HPjNZx1q+u27IsM/FYCjwFuBS4I7AH8M1JbVOWbdMvH1H65A6lvd4GfHQkfS9gx/J+4Zj93JH040seHwRObrn9zgdeOOt27KM9yce4fUvaQhtcC2xZ0mfVN28P7F7ebwOcBnxo5PufAl4NbAUcWOr8vxrqdAD5vPsQYCVwFg3n86nrNuuGb7NjlL9PA/6txfc/BPz52GdnAE9jJChq+O5G6eQD/jeWWu5I2pnAmRV5nMgtOGhq094124qRg/PIZz8BHjNh2ScDnxv5+9bATcB+NfXeXF599L/y+YWMBU0jaXu3PTCXv88GXldZrxuAezekPRr4ekPaIcA6Gn7wlGW2BL4M3HO8jptbWzYdS4HPAU8e+fuJNPzoaNMvJ3z3XsDahrTbAh8H3jAh7Z20CJqAVcCvgbvOuh37bM/y+QrgkWXfvd1Y2sz6JjloehnwzfL3ylLOriPLvBl4R0O+fwucNfL3XsAvge3bbPfB354bFRF3JP9K+E7l8tsBvwNcPPLZfYH7kDt7m7J3AY4kHwxblzuSdivgMcDb25R/S9S2vVvmvSIiHgXsCEy65H4A+ZcbACml9cB3y+dN3lVuGXwsIg7stMID0EX/60tE7A8cTF3/PAjYmub1eAjNdT4eeH/ZH5o8B/hMSulri9VlVpbhWLpR/ynvp/WdhTwX65fjbtZW5RbMDeQrFgcCb6rIZzHHAReklL7XQV6d66pvRsTXgJ+TA6q3pJR+3EHdNqlvRsSdI+I68o/WvyAHh5CviI3+u/D+Hg3Zjx/Tv0sOmu5WtSLFlosvMgjnlPuoK8mXW19U+b0zyBvpXIByT/UNwDNSShsabrGPe01EnA6sJ/+aem7bcsccSe7Mn64p/BZqqe1dY/fSATcA/wU8LqV06YTlVpJ/7Y66Hth+wrIAxwIXkTvts4BzI2K/lNJ13VR7pjrpfz25KCJ+Tb4s/xbyVdxGEbED8A7glJTS9RPSjyAHRvebkLbwg+cPpuR/J/KtqXu3WIfltFzH0pXk/rLgemBlREQqP/PH1PbL34iIe5Jvy//h6OcppbOAsyJiH3Kw86O6VZzqOODUDvLpWqd9M6V0z4jYFngUOXjZFJ30zZTSfwE7luePnkS+HUxKaW1EfBb4m4h4HrA/+fw6ftxeML5PwvRj+kTzcqXpj1JK25Mv4+5Hft5kqoh4BTniPHqkkz4N+FpK6fMtyn5mSmnHlNIeKaVjU0pNDTKt3FHHA//UkKasdXu3cHVpz51TSgellN7TsNw68nMTo3Yg3xO/mZTSZ1NKN6WUbkwpvQy4jvzranPQVf/rw71SSjullPZKKf11SmnDlDptB3yYfJvoZRPS709+zuExKaVvT8ji0eQTwLQfPK8GXjwpIBuI5TqWjvefHYB1U/aF2n65UKe9yc+ePSuldMGkZVJKl5GvpLxhWl6LiYgHk58Zev+m5NOTzvtmSunnKaV3Aydt4hXzzvpmqde15Ds0H4z/ebj/WOCuwPeBNwLvAq5qKKbVMb3JvARNAKSUPg2sBk6ftlxEnEK+VPm7KaUbRpIOAx5VRhqsAR4I/H1EvK6L+k0pdyH9TuSd+5+6KG9zV9vePbmYfGkfgIi4NfkeeO2tpsTGl43nXgf9b2YiYhvgHOAH5CtB4+m/Tb4l8YSU0icasqn5wXMY8IqRYwzA5yPimKXXvnvLcCzdqP+U953cpo08ivXjwEtSSu9YZPEtyf12UxwPfCCltG4T8+lNT31zK/KD2r1arG+O2RK4HSX4SSldmVL6/ZTSriml+5GfY/tiw3fHj+l7kp+TmvQDqVmbB6Bm8eLmD7vtSr5VdlDD8s8HLgPuMCFtR/IvhoXX58i3227TkNf5THlQvLbckWVeQH7WYbG8tiCPZngqeQTOtsBWs26LgbZ39bZiwgOnU+qxK/nS7ZElz7+j+UHWOwMPIl/O3hZ4HvkS8W1nvT1n0B5T+8HINvos+VL7tsCKkhbl7/3JQee2wDZT6lb1kDX54P9h8oF5ywnp9yDfwvnjKXnckTyia69Fyrrd2DEmAfcHttuc2nKxY2npj98ij5zbnXzCWnT0XMU67EF+tvB5DeknUh5eLvvRxcArx/aFbclXFE8t77eYUt525KvGD511+/Xcnvcnj/jcuqzzX5KvwCyMXJtV33w0/zOqb1fgfcBFI+l3J99e2xr4P+RHX3ZtKOsA8kPmB5MH9ryTW8LoufLZG4F/ntJYvyBfilt4vaBh2fNpMXpukXouWi75XuwTJ3z3WODikb9PKPmNvlbPui0G2t7V24oWB+ey/OGlzW4q+8KqkbQzKMPSS2f8Wjlg/RT4BHCfWW/LGbXH1NAb1mYAABkbSURBVH5QtuN4ex1a0lZNSLtiSt1qD8yHlGVvHKvXwSX9TPKzNKNpF4/l8Xzyg8CT8v9NXkut4zy25diy57Px6LkgP7B7bXmdRpnrdMJ3q/sl+ZmdNFandSPpZ5ID4PVlfV8BbDuSvnrCPnZCSTt4NK/y2Z8AVzbVfXNpz9JHvkoOlBZuQT9k5Luz6pvPAL5X2nMN8B7gLiPffzb5B+p68ojc+4zlv1HfJP/3Iv9Vlv8gsHPb7e6EvZIkSRXm6pkmSZKkWTFokiRJqmDQJEmSVMGgSZIkqYJBkyRJUoVlnUbliBVHDWao3rlXf2Xi5w/b/aBlrkmzrup43oazO/9PFofUlrckfbQlwIY1+0xsz6Z9rWnfbKPPvLsqt21fa9tnl7Nvtt2ubda97XrPoo27quNytiU0980mXezffbdnF+fZrvahtu3plSZJkqQKBk2SJEkVDJokSZIqGDRJkiRVWNYHwWdhVg98d1HukB5K1y1TFw94NuXR1cOjbfNp0zfb9uMh9NlZPPA9K30+1N9kaNtg3Czq13ff7EJXdfRKkyRJUgWDJkmSpAoGTZIkSRUMmiRJkioYNEmSJFUYxOi5Pke4zcMoOWlz0WYkSt9TbPTZB4c2bchy1aFt3rMaadbniMDmaTdaZbPJZrGvzWK6lKZ8ZrVveaVJkiSpgkGTJElSBYMmSZKkCgZNkiRJFQyaJEmSKgxi9Nw8jzSb57pLC2Yx0qxJ27q0HUXUxXxlbUeLLeeIq3mee6xt/k36HCk4FH3OC9n3PH19jozve//3SpMkSVIFgyZJkqQKBk2SJEkVDJokSZIqLOuD4E45Is2XWUwXMqRpVLqqy5CnUWnTxl091N82n1k83D6raTo21RCm8lmqLgZpNOlq/b3SJEmSVMGgSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRWWdfRcV0+731JG293S11+z18VInK6mOWlrHqaZ6GMalbaG1MZ9jpyc1ci/vsziPDCkPtv3KNumvumVJkmSpAoGTZIkSRUMmiRJkioYNEmSJFUwaJIkSaoQKaVlK+yIFUctX2H6jfM2nB1d52lbzkYfbQmwYc0+rdqzzWiZrkYttc1/FqPC2lqx22Wdt2dTW/Y5V9es5gEb0lxlfbQltO+bTYY06rqLUXh9j8xsak+vNEmSJFUwaJIkSapg0CRJklTBoEmSJKmCQZMkSVKFZZ17bp4NaR64IdVFWqqu9tchzXs2hPnK+hx92LRs3yMkm/Q5V9kQ2rJLbUYUzus6Qv9190qTJElSBYMmSZKkCgZNkiRJFQyaJEmSKhg0SZIkVRj06LkhjRLraoROn3WRlqrv+d76zLvv5fvM+7wN1UVusrajirqYv60r8zyaa7m12Tdn0XemmYf5Dr3SJEmSVMGgSZIkqYJBkyRJUgWDJkmSpAoGTZIkSRWWdfRc2yfv52GU2DzUUVrMLEYndTGaq8vluzCE40Gfc+51tU2HNOfZENpsKfrchvPQ12bFK02SJEkVDJokSZIqGDRJkiRVMGiSJEmqYNAkSZJUYVlHzw1pfitJ3WszX1nbETd9j7iah3mvavS5nWY16q2Lcoc0f2gbffafrta97748lLYArzRJkiRVMWiSJEmqYNAkSZJUwaBJkiSpgkGTJElShWUdPdekiyfm5+Gpe2moZtFP5rlvDnmurSHXbUGf8+O1LbPt8k11PG9D6yptklmMZOyq3WYxt11X28srTZIkSRUMmiRJkioYNEmSJFUwaJIkSaowiAfBu/gv24f2UGmfD6b70LtmbR4eNu5iqoZ5WM++dHE8GfJ0M4uZ1ZQxteXNYtsOaUqkvh8+b+KVJkmSpAoGTZIkSRUMmiRJkioYNEmSJFUwaJIkSaowiNFzbc3DKLE+p4CZh/XXfOlz9EsXo9iWYhZTNQzZLEbudrVftdXFCOuhT6PS52i4WeXTJv9Z9VevNEmSJFUwaJIkSapg0CRJklTBoEmSJKmCQZMkSVKFuRw918as5mlrU66j4TYft5R5AduMXBnaKLkuRra2tZwjrmYxZ1rf86O1zaeL0VabW58d0gi0Jn3OSdek7TbwSpMkSVIFgyZJkqQKBk2SJEkVDJokSZIqGDRJkiRV2GxGzw1t1NLmNvJCdea13fucO6yrOeC6GEHVNv+uRuIMbZRSjSG1ZZ/zrM1j2/St723VVV9uo6u6e6VJkiSpgkGTJElSBYMmSZKkCgZNkiRJFQyaJEmSKkRKadZ1kCRJGjyvNEmSJFUwaJIkSapg0CRJklRhEEFTRFwRETdFxLqIWBMRqyNi5ZTlj46Iz0XEjRFx/oT0gyLiP0v6f0bEQWPp94qIz5TyfhQRz2ooZ1VEpLLculLPk6bU680RcWlEbIiIE8bS7hER50bENRGRxtK2iYi3RsSVEbE2Ir4cEY+YUs42EfGqiLg6In4WEW+IiK2alh+SJbT1zhHx3rLdromId0XEDg35rYuIj03Ja3VE/LIsd21EnBcR+zUsu2NEvD0iflxeJzcsd0jZR06dUu7pEXFZadtLIuK4pmU3J0to69H2WXht0bDsCRHx67LMDRHxlYj4/YZlDy19cjTf46fU46ERcVHJ9/KIeHL7tR+eHo6zW0TEqeU4tHDc2rGknTG2vX8REWunlJUiYn1Z9gcR8copbf+SiPh6RPxqvF9GxAvGyr2ptP0uJf20iPh+adsrI+KvptSp1X6z3JbQnlOPQzHlvBkRzy594YbS3q+KiIkzikS3581Fz3UR8diI+FbZf74bEQc3lNN4Dm4lpTTzF3AFcHh5vxvwVeClU5Y/HDgaeCFw/lja1sCVwHOAbYBnlr+3Lum7AD8Gji3p2wN3byhnFZCALcvfDwBuBB7esPyfAYcBXwJOGEvbF3gi8Id5s2+Udmvg5FLeCuD3gbXAqoZyXgRcAOwM7Ap8AThl1u3YU1u/AfgYsANwG+DjwCsn5VdR9mrg1PL+VsC7gC80LHsmcHZZbhXwXeDxY8tsBXylbP9Tp5R7CrBfadv7AT8DHjjrthhgW6+eth3Hlj0BuLC8XwE8o/TNnScseyhwVWW+WwHXA08BAvgdYB1w4Ky35wzao/E4W9JPBT4J3KVsq3sA205p27dNKSsBe5f3+wFrgKc2LHs88Ajgg8DJi6zzycAnR/7eF7h1eb8HcDHw6IbvVu83c9KejcchFj9v7gXsWN7vXNr9uQ3lrKK78+bUcx1wRKnn/ct67QHs0VBO4zm4zWsQV5pGpZTWAOcCjZPNpJQ+nlJ6H3D1hORDyXPqvTql9IuU0mvIHfqhJf25wLkppXeV9LUppW9V1u3z5E52j4b016eUPgH8fELapSmlt5bvj6etTymdnFK6IqW0IaX0r8D3gHs3VOWRwGtSStemlH4CvAZ4Qs06DElNWwN3Bc5JKd2QUroe+BfggA7KvhE4i4a2JG/j01JKN6aUroD/396dx0xSlHEc/z0bQAiHonLIsaAcEVAQJQY0qIkBIx5RF7xQhAQ1Xki8ggpRSIwaiTGgolFkURGNGg9UwBNFjUo43HhwKRhBFwFBsoIK7OMfVS87mZ2eeXqmarrn3e8nebO8TL/VNV3d1c9U1zOlc7XxMX67UkB37YR9vc/dr81t+2ulTuCwWeq/aIJtPW3Z6yV9TtJWkh43Y3GPVArQv+DJFZL+KGn/GcvtlVn7WTPbXtLJkl7r7n/Jx+p37r5R32dmW0taJen8YN2uVbpGmvrZ8939YqUPlo3MzCS9enC/uR/+98Bm6yXtHalXnwXbc1w/9CyNuW+6+5/c/e68ranFcZvlvqnJ97rTJZ3h7r/K7+tWd7+1YT+N9+A2ehc0mdluSp8ibpyyiAMkrfEcWmZrtOFGe6ikf+Zh53+Y2UVmtjJQLzOzp+dyrp6ybiFmtpOkfdXcuJZ/Bn/fzcweXrNepQXb+hOSnm9m2+eOepWki4e2ucDMbjez75vZQcF9b6M02jiuLYeP8UMXvZntoXTxnhHZ38DfbaU0ejHThbtoWlzXb7T06PRKM1sVLHszSScqjQjd0LDZjpYexd+Uh/u3HrWRu98m6UJJJ+THT4cpjaT8PFKXRVGgn32ipAckHZ0fDV1vZm9q2HaVpNsl/SxYt/0lHa7Z+9nDJe0k6etD5Z9iZusk3aI0yv+lMWWEzpuutW3PEf3QpPumzOyVZnaPpDskHSTp04H9zHrfbLzXWXp8e4ikHczsRjO7xcw+nt9bNX0Kmr5p6Zn3X5Uen71vynK2URpeH/QvpcdwkrSb0vDuWyWtVBrRuXBCmXdI+qekz0o6JUfFVeTntRdIOj9/4hrlYklvNbMdzGxnpaFUKT1KWgRt2voqpaHjO/PPg0qP7JYcqzQcvIekn0i61PK8igbvMLO7lTqXbZQe84xyiaRTzGxbM9tbKUAaPL5nSTrN3deN2dcon1IaRr+05d8tqjZtfZakfSTtKOk0Satzh9vk0NyWayW9QtKL82jksGuVPoE/RumT81MkfXRMuRcqPZL6r9Kn8fe6+1/HbL9ISvWzuyk9Lt9XaTT4aEnvN7MjRmz7GkmfH7ohj3KVmd0l6SKlvva8Kes2uN+vDV+j7v4hpfvBkyV9QRvfL5a0PW+6MG17DvdDk+6bcvcvuft2Sm3+KUm3TdhHifvmuHvdTkqP049WCpCfJOlgSadOsZ+wPgVNL3L3bZWGCR+vNPdoGuuUhtcHbacNQ7n3SfqGu1+Rh5JPl/S0CaM0j3b37d19vzxsWYWZrVC6iP8n6c1jNv2AUtR+jaRfSvqmpPuVLppF0KatvyrpeqWLdzuluUVfXHrR3X/h7vflx2gflHS30gXU5Ex3f4S77+zuL3T3PzVsd5LSuXKD0tyJC5U+mcrMXiBpW3f/yuS3uoGZfURptOqlgRvIchFua3e/yt3vdPcH3P17Sh8eXjKm7F/ltny0ux/q7j9sKHetu/8hD9/fJOldSh3tRiwlBnxF0nFKwfoBkt5lZs+b/FYXQql+9r787xn5+lsj6cuSjhrcyMx2l/RMSZ8PlPnk3M/u5e6n5seuU8mjDceo4ZFgfpx4dX4fpzdsEz5vOtS6PRv6oUn3zYe4+w1KI1SfHH5tSIn75rh73dI5eLa7/93d71AKao8aVVApfQqaJEnu/lOlSYNnTlnE7yUdmJ9nLzlQG4Yh1yhNUntol/nfwe3nLtf3XKXoeZW739+0be6k3uzuu7r745RGYK509wfnVN0igm19kKRPe5r3tU7pE864i8JVoC3zM/Rjc3B1gNK18pv88rMlHZIfS6yV9DJJJ5vZt5rKM7PTlYbPj3T3e2at36KZ8rou0pYty32CpOvc/dJ8s7xO0neV2m7ZKNDPrlkqasJ2x0n6pbv/ecr9TOslSqMcl03YbjOlSc4Rtc7HmUXbc0w/NOm+OazNcZvauHudu9+l9EF2rh9Aexc0ZR+TdIQNfVXAkjzXYEulhlthZlsOpCFepvQI56Scrrg0YvPj/O95kl5sKb1yc6XHAD8fmOQ2NTPbItfLJG2e67Uiv2b5tS3y71ua2cMG/vwcSftJeoG73zdc9tB+djWzXXKZh+b3MO0we9fGtrWkKySdaGZb5U+Pr1MaVpaZrTSzpy8ddzN7p9InrV/MWikz28vMHpXPtefm/S59rcBpSkPUT8o/35b0GUknNJT1bkmvlHSEu985a90W2KTr+mgz28bMVpjZkZJepXRsZ2IpdXxlvl52l/QhpdHDUa6WtI+lrx0wM9tLKZv1t7PWo4em7mfzCO3lkt6b+9n9lD48fGeomOOUbubFmNnmuV4rJG2W6zX89QQbPRLM59XrLc2PNDN7qlLm1sjHRi3Pmz6Y1J7j+qHLNOa+aWYnmtmO+b/3l/RuNRy3tibcNyfd686T9BYz29E2JCcMn4NL+5l0D47xnqVODvy/cyR9vWH745Wiy8Gf1QOvHyzpSqXhu6skHTz092+QdKtSyuVFknZv2M+eGkidDLyPy0bU61lDZQ3+3Jxf2yP//h+lYdKln2Pz6yvz7yvz78/Ix+xeSdctbbcIP1O09WNzG92p9MnxEkn75NcOUPrE++/8+o8kHTJm36sVT2l/qVLW0L1KQ8PPiZarNM/q9wO/u9L8mMG2fU/XbdHDtr5caR7FPUpBysvHlH288lcOBOrxtny936s09+NspcerS69fPNgeue1/p/Ro4hZJH5a0ouvj2UF7HD+iz1o98Pqu+XpcJ+nPkl4/9PeH5Wtz20DdHvrKgcC2q0fU6/ihej0wXJ5SkHVJ7kfWKT32f4/yGqx5m3WSDo+cN13/TNGeY/shjblvKgUnt+X2vFnSR9T89RJ7qtx9c+y9TmlO0yeVpmWsVZoXuWV+bfi+ueeI/dzc9rizYC8AAEBAXx/PAQAA9ApBEwAAQABBEwAAQABBEwAAQABBEwAAQMBm89zZESuOKZKqd+nfrglv+5xdRn/9T5syptG03xKa6t60zx+s/2rxL2Qr1ZZ90vacKNHGfWhLaXm25yKo0Z7r1+7Tm7Zse42U6pdH7bf29V3r2mxqz5rHtk/tVrL8Nvtsak9GmgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAALmuvZc2yyAtplFfdKm7qXeZ1M5K3a+YW7ZcyUyVDaVdp+mnBptKZE915V5ZrZ2cW2W2r5Jm3JK9R/zvjbbZkO2eZ81j/c8ymlTdpO27clIEwAAQABBEwAAQABBEwAAQABBEwAAQABBEwAAQMBc155bjtlPbWf7t9m+bV2a19AJ7zKsZpZY386TNu+1VN3n2ZZYXmr3YSXKqL0OXIm15/qidtZfm312cW61VercauprGWkCAAAIIGgCAAAIIGgCAAAIIGgCAAAIIGgCAAAImGv2XJNFXmtsU9VFJk7tNQq7yAzhHMe81Mxkqr0mWZNN4d5R6hi2ySjs23HtUzYkI00AAAABBE0AAAABBE0AAAABBE0AAAABvZgIXnuCb4m6lNq+5rIhfVgmoNREzi7UXKphOU1MRb8tQv9Y6rpvU59F7ptqWeR+qYulzSRGmgAAAEIImgAAAAIImgAAAAIImgAAAAIImgAAAAJ6kT1XQt+ylmrWp23ZP1g/8y6rWeTsjTaZkF0s0YJNUxd9Ydt9dpHJVjtLe979bBf3kq70qT9kpAkAACCAoAkAACCAoAkAACCAoAkAACCAoAkAACCg19lzNdcVqq1Npkbf6j5PJY5HV2v31Tw/FzETsiuLkgE0LzWvh9pZb6Xqvsj3jmGlMmzbvM9S11TNjMVSGclt+1pGmgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAALmmj1Xe7Z7rTJKlj/q/5fKgujD+jw116CqnYnTRRYNmV+z41jFdHGu1c6Ga9MndHH/qaltvdscq76toVlznc+2GGkCAAAIIGgCAAAIIGgCAAAIIGgCAAAIIGgCAAAI6MXaczVn5Nee1V9zLabltF5ZmzYulf1QOyuxRN37komD5aPvWV9S/Uy2mmta9iFLeRo1M7dLbV8iG7Lt9m3ryEgTAABAAEETAABAAEETAABAAEETAABAAEETAABAwFyz52qvQzRKF1ka4/Qpg2UWNd93qbapfaxLZOgApdXOMi2xzz6tC1mqL6uVpdyn9duadLEOXBfnucRIEwAAQAhBEwAAQABBEwAAQABBEwAAQABBEwAAQECv155rUnO9sia1s+pKmOc+ax/XEmXUzmQrcR4uwjphWCw119Xsas3OJiXWhSy1z1rI3O7XGqWMNAEAAAQQNAEAAAQQNAEAAAQQNAEAAAQQNAEAAAT0InuuZgZaqRn2NbM9Ss32n+eaSH3KoqmdzVIz62SRM1rQT12cU11lKdfUdp+11p5bZKXu7TXXzWuLkSYAAIAAgiYAAIAAgiYAAIAAgiYAAICAuU4EbzvJr81EvNqTqWtOKC91XPqwjEoXEzn7NJm6T3Vpo08TcPtUl0XUp+PXp6VLak5K7pM27Vz7vXRxrFhGBQAAoAcImgAAAAIImgAAAAIImgAAAAIImgAAAALmmj1XO8OtRF26WHZlEZdR6ZNSbVYio7JUhs68M536lJlWuy59yi6bp5rvu6tllWpm1bXdvlY/WyrTu41FuBZqZ8A3tScjTQAAAAEETQAAAAEETQAAAAEETQAAAAEETQAAAAFzzZ6rqYust2n22ybjqskiZDbMouYaheN0sZ5eH9YR3NQs9+uni3Oqq/OYzNY6ulqbtcT5UjvbkJEmAACAAIImAACAAIImAACAAIImAACAAIImAACAgF5nz9XMjKidcVVq+1H6kFnVp0yc2tklfVrrcDmtI7iprgG3KNpc46X6g5qZT33oN6fRVTbxoqqdyclIEwAAQABBEwAAQABBEwAAQABBEwAAQABBEwAAQIC5e9d1AAAA6D1GmgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAIImgAAAAL+D0HVrQuNY8iAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "tb_hist= keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val), callbacks=[tb_hist])\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 927us/step - loss: 11929.1166 - val_loss: 1732.8936\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 1465.2144 - val_loss: 1200.6951\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 1020.2825 - val_loss: 916.8154\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 736.0012 - val_loss: 609.6219\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 436.8907 - val_loss: 358.0414\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 1s 555us/step - loss: 303.1219 - val_loss: 312.5365\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 1s 576us/step - loss: 280.5474 - val_loss: 290.5482\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 1s 574us/step - loss: 261.5319 - val_loss: 287.9986\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 254.6834 - val_loss: 277.6985\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 1s 528us/step - loss: 244.3533 - val_loss: 279.6024\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 1s 519us/step - loss: 252.5254 - val_loss: 271.1136\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 229.8664 - val_loss: 260.2457\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 222.7295 - val_loss: 344.1615\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 1s 473us/step - loss: 225.5012 - val_loss: 241.1146\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 1s 592us/step - loss: 198.5558 - val_loss: 289.4333\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 1s 618us/step - loss: 198.9438 - val_loss: 281.0739\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 200.4096 - val_loss: 239.1547\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 202.6238 - val_loss: 224.5430\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 181.0569 - val_loss: 213.5303\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 166.4365 - val_loss: 222.1952\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 1s 492us/step - loss: 168.6849 - val_loss: 215.0314\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 166.2690 - val_loss: 212.1250\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 166.2521 - val_loss: 206.3894\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 1s 595us/step - loss: 162.2887 - val_loss: 202.1794\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 1s 574us/step - loss: 160.7564 - val_loss: 203.5455\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 159.0882 - val_loss: 198.7720\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 151.0127 - val_loss: 199.2067\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 147.7732 - val_loss: 194.9702\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 1s 468us/step - loss: 142.4088 - val_loss: 193.0447\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 147.6512 - val_loss: 201.4313\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 1s 506us/step - loss: 138.9461 - val_loss: 190.9864\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 142.6591 - val_loss: 195.4036\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 134.4347 - val_loss: 196.1798\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 139.1175 - val_loss: 187.8425\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 133.3773 - val_loss: 203.7371\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 134.7778 - val_loss: 196.7108\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 1s 521us/step - loss: 134.6892 - val_loss: 181.4412\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 1s 602us/step - loss: 125.5999 - val_loss: 181.1312\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 120.6025 - val_loss: 187.7138\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 1s 582us/step - loss: 120.0481 - val_loss: 177.9456\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 1s 585us/step - loss: 119.1240 - val_loss: 197.7185\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 127.9946 - val_loss: 193.9764\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 148.339 - 1s 525us/step - loss: 146.9805 - val_loss: 186.0677\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 1s 586us/step - loss: 121.1971 - val_loss: 189.2717\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 1s 569us/step - loss: 110.5938 - val_loss: 179.1138\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 114.2200 - val_loss: 197.1143\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 110.6195 - val_loss: 185.0786\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 107.4977 - val_loss: 181.3968\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 1s 574us/step - loss: 111.4266 - val_loss: 177.5262\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 108.3260 - val_loss: 180.1516\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 114.4047 - val_loss: 174.9748\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 1s 579us/step - loss: 102.8571 - val_loss: 169.5070\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 105.0170 - val_loss: 171.8363\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 1s 613us/step - loss: 97.5270 - val_loss: 169.8006\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 1s 521us/step - loss: 99.4286 - val_loss: 174.7047\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 94.6541 - val_loss: 171.9590\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 93.3533 - val_loss: 198.0436\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 102.3110 - val_loss: 174.0943\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 1s 547us/step - loss: 101.8569 - val_loss: 167.3810\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 1s 498us/step - loss: 97.1730 - val_loss: 180.8750\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 99.3613 - val_loss: 169.5338\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 98.9701 - val_loss: 180.2577\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 1s 536us/step - loss: 88.9546 - val_loss: 170.8455\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 1s 592us/step - loss: 90.2974 - val_loss: 185.1834\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 85.3212 - val_loss: 181.4137\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 84.2001 - val_loss: 167.1294\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 88.3417 - val_loss: 182.0829\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 1s 513us/step - loss: 88.0214 - val_loss: 169.2656\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 1s 497us/step - loss: 82.3291 - val_loss: 196.4589\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 81.7719 - val_loss: 168.2957\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 1s 552us/step - loss: 80.1279 - val_loss: 168.8676\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 77.2252 - val_loss: 167.1624\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 1s 499us/step - loss: 74.0372 - val_loss: 167.5505\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 519us/step - loss: 83.5503 - val_loss: 211.8498\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 1s 498us/step - loss: 84.3524 - val_loss: 169.0738\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 1s 555us/step - loss: 72.4364 - val_loss: 185.5876\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 1s 567us/step - loss: 70.5702 - val_loss: 170.0475\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 71.9513 - val_loss: 174.7132\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 84.7263 - val_loss: 215.4246\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 80.8667 - val_loss: 175.9563\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 1s 510us/step - loss: 67.8596 - val_loss: 168.5548\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 67.9504 - val_loss: 171.9951\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 1s 522us/step - loss: 71.5714 - val_loss: 168.9121\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 1s 492us/step - loss: 74.5027 - val_loss: 190.0057\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 66.2792 - val_loss: 169.3580\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 1s 522us/step - loss: 62.9619 - val_loss: 175.8726\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 68.2931 - val_loss: 170.8898\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 63.5823 - val_loss: 171.3100\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 59.4098 - val_loss: 171.1814\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 1s 528us/step - loss: 60.1393 - val_loss: 176.9580\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 1s 572us/step - loss: 60.7688 - val_loss: 173.1290\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 1s 589us/step - loss: 59.1954 - val_loss: 174.0903\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 1s 552us/step - loss: 57.0021 - val_loss: 172.3717\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 1s 557us/step - loss: 56.8973 - val_loss: 172.8658\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 54.1373 - val_loss: 187.2628\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 60.0249 - val_loss: 171.7310\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 1s 557us/step - loss: 57.3282 - val_loss: 188.6511\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 1s 603us/step - loss: 51.5228 - val_loss: 204.8719\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 63.0140 - val_loss: 175.9264\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 1s 582us/step - loss: 64.5687 - val_loss: 176.9159\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 51.5412 - val_loss: 181.9662\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 1s 623us/step - loss: 51.1341 - val_loss: 178.6750\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 1s 505us/step - loss: 48.6687 - val_loss: 178.2016\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 1s 536us/step - loss: 47.9128 - val_loss: 176.9703\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 47.2052 - val_loss: 180.8434\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 1s 517us/step - loss: 49.5859 - val_loss: 179.5551\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 52.3620 - val_loss: 197.4871\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 1s 497us/step - loss: 55.5923 - val_loss: 183.8705\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 1s 513us/step - loss: 57.6369 - val_loss: 179.7213\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 46.4439 - val_loss: 182.1013\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 43.3757 - val_loss: 182.2423\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 1s 513us/step - loss: 42.0361 - val_loss: 185.0057\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 1s 560us/step - loss: 42.7941 - val_loss: 193.2032\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 44.1509 - val_loss: 200.2315\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 39.7729 - val_loss: 198.0204\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 40.0743 - val_loss: 184.7810\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 1s 471us/step - loss: 39.5661 - val_loss: 186.9580\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 39.0695 - val_loss: 186.9946\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 35.9823 - val_loss: 194.8846\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 1s 488us/step - loss: 36.4507 - val_loss: 189.5566\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 40.5726 - val_loss: 192.2448\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 34.9381 - val_loss: 192.3662\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 34.3630 - val_loss: 197.1770\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 32.6560 - val_loss: 202.2989\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 1s 572us/step - loss: 37.1615 - val_loss: 193.0786\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 1s 579us/step - loss: 40.2052 - val_loss: 200.3865\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 36.4635 - val_loss: 201.9465\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 31.5168 - val_loss: 199.3172\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 1s 545us/step - loss: 31.4742 - val_loss: 200.6150\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 1s 469us/step - loss: 31.2493 - val_loss: 204.7122\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 1s 469us/step - loss: 32.3368 - val_loss: 199.9413\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 1s 510us/step - loss: 31.5122 - val_loss: 198.9265\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 1s 533us/step - loss: 37.5231 - val_loss: 202.8242\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 28.0758 - val_loss: 200.5258\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 1s 453us/step - loss: 26.6860 - val_loss: 202.4881\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 1s 572us/step - loss: 27.5492 - val_loss: 233.0883\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 1s 555us/step - loss: 34.1128 - val_loss: 203.7210\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 1s 620us/step - loss: 25.9785 - val_loss: 203.3753\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 25.9259 - val_loss: 225.5765\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 1s 509us/step - loss: 33.0838 - val_loss: 209.4269\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 29.1280 - val_loss: 217.5311\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 22.9633 - val_loss: 207.4627\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 1s 469us/step - loss: 23.1719 - val_loss: 211.2973\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 1s 586us/step - loss: 26.3923 - val_loss: 230.5718\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 1s 504us/step - loss: 24.9244 - val_loss: 212.5985\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 1s 513us/step - loss: 23.1847 - val_loss: 209.7898\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 1s 596us/step - loss: 20.4513 - val_loss: 212.3796\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 518us/step - loss: 20.9013 - val_loss: 219.5088\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 1s 500us/step - loss: 26.2585 - val_loss: 228.3162\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 1s 515us/step - loss: 21.9733 - val_loss: 212.2289\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 1s 511us/step - loss: 19.0303 - val_loss: 218.0288\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 1s 518us/step - loss: 17.7524 - val_loss: 216.6186\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 1s 511us/step - loss: 18.2744 - val_loss: 214.4647\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 1s 585us/step - loss: 16.1877 - val_loss: 217.0246\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 1s 557us/step - loss: 16.9982 - val_loss: 215.6112\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 19.4329 - val_loss: 229.0795\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 17.2536 - val_loss: 217.3254\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 1s 545us/step - loss: 16.8140 - val_loss: 218.2785\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 1s 579us/step - loss: 16.0017 - val_loss: 218.6382\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 1s 544us/step - loss: 14.9641 - val_loss: 220.3434\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 1s 499us/step - loss: 15.0961 - val_loss: 222.8909\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 1s 594us/step - loss: 14.5768 - val_loss: 221.5690\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 1s 593us/step - loss: 13.1394 - val_loss: 220.6789\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 13.7260 - val_loss: 222.5979\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 1s 581us/step - loss: 13.4988 - val_loss: 223.8054\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 14.2432 - val_loss: 224.9392\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 12.5899 - val_loss: 238.6134\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 18.2362 - val_loss: 227.7029\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 1s 511us/step - loss: 13.8613 - val_loss: 233.6617\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 1s 518us/step - loss: 14.2878 - val_loss: 225.3270\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 12.0976 - val_loss: 224.6231\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 11.3869 - val_loss: 226.7110\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 11.0469 - val_loss: 227.9550\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 1s 566us/step - loss: 11.0568 - val_loss: 226.0229\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 12.0916 - val_loss: 225.5766\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 10.0828 - val_loss: 227.1210\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 10.1036 - val_loss: 231.1018\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 1s 541us/step - loss: 10.2738 - val_loss: 229.4388\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 8.4491 - val_loss: 229.0481\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 1s 596us/step - loss: 8.4238 - val_loss: 233.9825\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 1s 557us/step - loss: 8.4403 - val_loss: 229.3911\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 1s 536us/step - loss: 8.4498 - val_loss: 231.1843\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 1s 547us/step - loss: 7.2522 - val_loss: 231.1133\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 7.7989 - val_loss: 237.5546\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 7.9299 - val_loss: 233.3462\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 7.0841 - val_loss: 232.7468\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 1s 494us/step - loss: 6.9696 - val_loss: 232.6648\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 1s 558us/step - loss: 6.3766 - val_loss: 234.8159\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 1s 522us/step - loss: 7.1397 - val_loss: 239.9765\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 1s 587us/step - loss: 10.5385 - val_loss: 234.7782\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 6.9885 - val_loss: 235.6250\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 6.9971 - val_loss: 233.4765\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 9.8875 - val_loss: 234.6991\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 5.6424 - val_loss: 235.4656\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 1s 581us/step - loss: 5.2312 - val_loss: 239.3247\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 6.4063 - val_loss: 235.2908\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 1s 475us/step - loss: 6.2291 - val_loss: 235.2554\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 5.4074 - val_loss: 237.8312\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 1s 570us/step - loss: 4.9036 - val_loss: 236.2079\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 1s 542us/step - loss: 4.3478 - val_loss: 236.3162\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 1s 504us/step - loss: 4.1512 - val_loss: 237.4843\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 1s 454us/step - loss: 5.1411 - val_loss: 237.2319\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 1s 572us/step - loss: 5.8315 - val_loss: 235.6954\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 1s 491us/step - loss: 4.2307 - val_loss: 237.2952\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 1s 521us/step - loss: 3.7465 - val_loss: 237.6755\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 1s 540us/step - loss: 3.8496 - val_loss: 244.6139\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 3.7116 - val_loss: 242.0802\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 3.7963 - val_loss: 240.7566\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 1s 498us/step - loss: 3.4260 - val_loss: 240.7292\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 3.9346 - val_loss: 238.4442\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 3.6587 - val_loss: 239.7584\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 1s 533us/step - loss: 3.0593 - val_loss: 239.2903\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 3.0921 - val_loss: 239.9811\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 2.7892 - val_loss: 241.2884\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 2.5765 - val_loss: 240.1629\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 1s 513us/step - loss: 3.1306 - val_loss: 241.6138\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 3.2025 - val_loss: 241.2264\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 1s 515us/step - loss: 2.9683 - val_loss: 241.1762\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 2.4815 - val_loss: 243.8088\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 1s 520us/step - loss: 2.0356 - val_loss: 241.8068\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 2.2576 - val_loss: 243.7724\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 515us/step - loss: 2.6388 - val_loss: 241.8016\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 1s 512us/step - loss: 1.9276 - val_loss: 242.0646\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 3.2325 - val_loss: 245.9878\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 1s 509us/step - loss: 2.9322 - val_loss: 243.6626\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 1s 510us/step - loss: 1.9096 - val_loss: 243.4884\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 1s 556us/step - loss: 2.8209 - val_loss: 244.1776\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 1.6736 - val_loss: 241.8418\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 1.6655 - val_loss: 244.0152\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 1.5402 - val_loss: 246.3256\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 1s 519us/step - loss: 1.8526 - val_loss: 244.1032\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 1s 544us/step - loss: 1.4706 - val_loss: 245.1230\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 1.3075 - val_loss: 244.4046\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 3.9367 - val_loss: 242.9939\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 1s 556us/step - loss: 2.2208 - val_loss: 246.2819\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 1.9941 - val_loss: 245.2918\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 1.7485 - val_loss: 245.4259\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 1s 498us/step - loss: 2.1816 - val_loss: 246.8239\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 1s 582us/step - loss: 1.5094 - val_loss: 247.6543\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 1.3717 - val_loss: 246.7650\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 1s 544us/step - loss: 1.8719 - val_loss: 251.2935\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 2.4881 - val_loss: 245.1084\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 1.8247 - val_loss: 245.0497\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 1s 477us/step - loss: 0.9586 - val_loss: 246.4951\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 1s 555us/step - loss: 0.8163 - val_loss: 245.7234\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 1.5122 - val_loss: 245.3267\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 1.0733 - val_loss: 250.4497\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 1s 570us/step - loss: 1.5069 - val_loss: 249.3311\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 1s 497us/step - loss: 1.0867 - val_loss: 247.1653\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 0.8592 - val_loss: 246.6899\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 0.7917 - val_loss: 247.0298\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 0.9069 - val_loss: 252.6136\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 2.2073 - val_loss: 249.5735\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 1s 587us/step - loss: 4.2834 - val_loss: 252.4669\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 2.3097 - val_loss: 248.0160\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 1.0478 - val_loss: 246.2645\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 0.8107 - val_loss: 247.0612\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 1s 558us/step - loss: 0.8703 - val_loss: 247.8494\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 1s 525us/step - loss: 0.9102 - val_loss: 246.3796\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 0.8235 - val_loss: 247.0026\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 1s 552us/step - loss: 0.4537 - val_loss: 247.6647\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 0.6847 - val_loss: 247.9543\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 1s 541us/step - loss: 0.9843 - val_loss: 249.2910\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 1s 570us/step - loss: 1.2469 - val_loss: 247.6137\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 1s 503us/step - loss: 0.7303 - val_loss: 249.0721\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 1s 557us/step - loss: 0.6325 - val_loss: 248.8542\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 1s 544us/step - loss: 0.8184 - val_loss: 247.7047\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 1.8509 - val_loss: 249.1446\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 1s 579us/step - loss: 3.4383 - val_loss: 249.7436\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 1s 583us/step - loss: 2.9773 - val_loss: 254.1508\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 2.3184 - val_loss: 249.1079\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 1s 542us/step - loss: 2.5173 - val_loss: 251.2587\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 1.0775 - val_loss: 249.5260\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 1s 483us/step - loss: 0.7084 - val_loss: 249.0541\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 1s 556us/step - loss: 0.4525 - val_loss: 249.1110\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 1.6034 - val_loss: 249.8503\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 0.9534 - val_loss: 248.6441\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 1.6096 - val_loss: 251.0052\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 0.9574 - val_loss: 247.1646\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 1s 560us/step - loss: 0.9437 - val_loss: 247.5991\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 1s 501us/step - loss: 1.0268 - val_loss: 248.1765\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 1s 536us/step - loss: 0.9699 - val_loss: 248.1543\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 1s 517us/step - loss: 0.8851 - val_loss: 251.8257\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 1.7014 - val_loss: 247.7601\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 0.8776 - val_loss: 249.4515\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.6196 - val_loss: 248.9724\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 0.4630 - val_loss: 248.8991\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 1s 524us/step - loss: 0.3289 - val_loss: 249.8489\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 1s 497us/step - loss: 0.3878 - val_loss: 249.0079\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 1s 509us/step - loss: 0.5085 - val_loss: 248.8912\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 0.5753 - val_loss: 247.7844\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 1s 522us/step - loss: 1.4377 - val_loss: 250.4756\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 1s 493us/step - loss: 4.2782 - val_loss: 242.4074\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 1s 481us/step - loss: 2.7551 - val_loss: 246.8441\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 1s 542us/step - loss: 1.0625 - val_loss: 249.3503\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 491us/step - loss: 0.8930 - val_loss: 248.4207\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 0.4637 - val_loss: 248.3816\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 1s 511us/step - loss: 0.5201 - val_loss: 249.0171\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 1s 578us/step - loss: 0.5608 - val_loss: 248.7385\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 0.4038 - val_loss: 249.9567\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 1s 584us/step - loss: 0.6085 - val_loss: 249.0667\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 2.8001 - val_loss: 249.1540\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 2.4062 - val_loss: 248.5540\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 1s 558us/step - loss: 0.6586 - val_loss: 247.9930\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 0.5006 - val_loss: 247.7658\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 1s 570us/step - loss: 0.3070 - val_loss: 249.1846\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 0.2730 - val_loss: 248.7767\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 0.5216 - val_loss: 249.9126\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 1s 537us/step - loss: 0.4552 - val_loss: 249.5660\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 0.7194 - val_loss: 249.0347\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 1s 493us/step - loss: 3.4729 - val_loss: 248.9933\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 1s 533us/step - loss: 5.0247 - val_loss: 248.1254\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 1s 519us/step - loss: 1.8582 - val_loss: 251.6994\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 1.5140 - val_loss: 247.0891\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 1.0309 - val_loss: 250.3721\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 0.6653 - val_loss: 250.4554\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 0.6084 - val_loss: 248.9838\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 0.3576 - val_loss: 249.2290\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 1s 483us/step - loss: 0.2722 - val_loss: 249.0214\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 1s 555us/step - loss: 0.4028 - val_loss: 248.6021\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 1s 547us/step - loss: 0.2831 - val_loss: 248.9229\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 0.5053 - val_loss: 251.1153\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 0.8677 - val_loss: 250.8705\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 1.0425 - val_loss: 247.7670\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 1s 557us/step - loss: 1.2265 - val_loss: 249.7698\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 1s 572us/step - loss: 1.7604 - val_loss: 251.9336\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 8.0430 - val_loss: 249.4316\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 1s 522us/step - loss: 3.4398 - val_loss: 250.2191\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 3.3688 - val_loss: 249.9637\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 1s 508us/step - loss: 1.8128 - val_loss: 248.1805\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 1s 581us/step - loss: 1.0280 - val_loss: 248.8943\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 0.5322 - val_loss: 248.8279\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 0.5264 - val_loss: 247.2844\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 1s 541us/step - loss: 0.4180 - val_loss: 248.4359\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 0.2594 - val_loss: 248.8817\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 1s 562us/step - loss: 0.1776 - val_loss: 248.3809\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 1s 570us/step - loss: 0.3200 - val_loss: 247.9453\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 1s 524us/step - loss: 0.2933 - val_loss: 249.1505\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 0.2315 - val_loss: 248.9935\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 1s 579us/step - loss: 0.1794 - val_loss: 249.0580\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 1s 466us/step - loss: 0.3668 - val_loss: 248.4426\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 1s 541us/step - loss: 0.2809 - val_loss: 248.3433\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 0.1899 - val_loss: 248.3993\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 1s 552us/step - loss: 0.1319 - val_loss: 248.5808\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.2084 - val_loss: 249.1856\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 0.3510 - val_loss: 248.5317\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 1s 514us/step - loss: 0.2222 - val_loss: 248.7544\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 0.4812 - val_loss: 248.1106\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 1s 572us/step - loss: 0.8452 - val_loss: 248.6714\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 1s 520us/step - loss: 1.2405 - val_loss: 248.7356\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 1s 545us/step - loss: 6.6024 - val_loss: 252.9487\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 1s 512us/step - loss: 6.5998 - val_loss: 246.3292\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 1s 531us/step - loss: 3.0198 - val_loss: 246.3544\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 1s 541us/step - loss: 3.0138 - val_loss: 246.0546\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 1s 456us/step - loss: 1.0085 - val_loss: 246.8019\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 0.4702 - val_loss: 247.3019\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 0.3066 - val_loss: 247.3003\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 0.2284 - val_loss: 247.3242\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 1s 513us/step - loss: 0.1794 - val_loss: 247.7171\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 1s 497us/step - loss: 0.3249 - val_loss: 247.5881\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 1s 519us/step - loss: 0.8657 - val_loss: 248.4863\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 0.7048 - val_loss: 249.1167\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 1s 537us/step - loss: 0.4001 - val_loss: 248.2940\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 1s 542us/step - loss: 0.2192 - val_loss: 247.7663\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 0.1494 - val_loss: 247.6810\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 0.4837 - val_loss: 248.0100\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 0.3588 - val_loss: 249.8272\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 1s 540us/step - loss: 1.7814 - val_loss: 249.6643\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 1s 413us/step - loss: 4.9479 - val_loss: 249.4133\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 548us/step - loss: 3.4784 - val_loss: 252.1364\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 2.7800 - val_loss: 249.4166\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 1s 541us/step - loss: 1.3632 - val_loss: 247.2787\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 1.5990 - val_loss: 248.0173\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 1s 482us/step - loss: 1.0079 - val_loss: 249.3137\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 0.6776 - val_loss: 248.9051\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 1s 574us/step - loss: 0.4925 - val_loss: 247.3949\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 0.4823 - val_loss: 247.1435\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 1s 516us/step - loss: 0.2733 - val_loss: 248.0811\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.2496 - val_loss: 247.0145\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 1s 563us/step - loss: 0.2795 - val_loss: 247.4590\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 1s 488us/step - loss: 0.2232 - val_loss: 248.1038\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 0.3345 - val_loss: 247.4255\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 1s 497us/step - loss: 0.4121 - val_loss: 247.6535\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 1s 552us/step - loss: 0.3265 - val_loss: 247.8053\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 0.2287 - val_loss: 246.5174\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 0.3152 - val_loss: 247.7233\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 1s 521us/step - loss: 1.1151 - val_loss: 247.6985\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 1s 606us/step - loss: 4.0210 - val_loss: 249.2045\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 1.5460 - val_loss: 245.0450\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 1s 600us/step - loss: 1.1220 - val_loss: 247.1249\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 1s 576us/step - loss: 0.5784 - val_loss: 247.1503\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 1s 578us/step - loss: 0.4027 - val_loss: 246.7815\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 0.2583 - val_loss: 247.4567\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 1s 582us/step - loss: 0.2843 - val_loss: 248.9423\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 1s 574us/step - loss: 0.4642 - val_loss: 248.1479\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 1s 586us/step - loss: 1.6834 - val_loss: 248.5951\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 1s 611us/step - loss: 1.9500 - val_loss: 254.6271\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 1s 635us/step - loss: 2.4966 - val_loss: 256.2205\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 1s 547us/step - loss: 3.6611 - val_loss: 249.0981\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 2.1581 - val_loss: 247.9098\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 1s 566us/step - loss: 0.8756 - val_loss: 246.3029\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 1.7927 - val_loss: 249.6118\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 1s 556us/step - loss: 2.5483 - val_loss: 247.0596\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 0.9942 - val_loss: 248.0321\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 1.8561 - val_loss: 245.8502\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 1s 547us/step - loss: 1.1410 - val_loss: 245.2079\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 1s 544us/step - loss: 0.5873 - val_loss: 246.2096\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 1s 594us/step - loss: 0.3623 - val_loss: 245.8570\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 1s 533us/step - loss: 0.2026 - val_loss: 245.3742\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 1s 449us/step - loss: 0.1333 - val_loss: 245.8855\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 1s 527us/step - loss: 0.3508 - val_loss: 245.8512\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 1s 593us/step - loss: 0.2296 - val_loss: 245.5937\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 1s 596us/step - loss: 0.2628 - val_loss: 245.3881\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 0.1703 - val_loss: 245.7194\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 1s 614us/step - loss: 0.1126 - val_loss: 246.3393\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 1s 524us/step - loss: 0.1768 - val_loss: 245.9341\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 1s 587us/step - loss: 0.1516 - val_loss: 247.2701\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 1s 560us/step - loss: 0.2100 - val_loss: 246.7032\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 1s 515us/step - loss: 0.1696 - val_loss: 246.5900\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 0.1335 - val_loss: 246.6129\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 1s 490us/step - loss: 0.1479 - val_loss: 246.1791\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 0.6530 - val_loss: 245.9846\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 1s 552us/step - loss: 1.2219 - val_loss: 246.9538\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 1s 544us/step - loss: 1.9370 - val_loss: 246.5596\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 1s 600us/step - loss: 4.7577 - val_loss: 247.8062\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 2.2103 - val_loss: 247.3992\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 1.6875 - val_loss: 247.1556\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 1s 517us/step - loss: 1.7819 - val_loss: 247.9400\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 1.0634 - val_loss: 246.7265\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 1.6638 - val_loss: 247.1214\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 1s 526us/step - loss: 0.9011 - val_loss: 250.5200\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 1s 566us/step - loss: 1.4591 - val_loss: 247.3323\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 1s 609us/step - loss: 0.7764 - val_loss: 245.7659\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 0.7390 - val_loss: 245.8157\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 1s 528us/step - loss: 0.6711 - val_loss: 246.6786\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 1s 560us/step - loss: 0.3054 - val_loss: 246.1375\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 0.3363 - val_loss: 246.6389\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 1s 608us/step - loss: 0.2211 - val_loss: 245.2138\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 0.2440 - val_loss: 245.7662\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 1s 538us/step - loss: 0.4444 - val_loss: 246.1553\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 1s 451us/step - loss: 0.3267 - val_loss: 245.6440\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 0.2065 - val_loss: 245.1927\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 1s 506us/step - loss: 0.1162 - val_loss: 245.7722\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 532us/step - loss: 0.2249 - val_loss: 246.2723\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 0.1465 - val_loss: 245.9832\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 0.2723 - val_loss: 245.7573\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 1s 514us/step - loss: 0.2473 - val_loss: 246.6538\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 1s 610us/step - loss: 0.5676 - val_loss: 247.5205\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 1s 561us/step - loss: 0.5244 - val_loss: 245.9730\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 1.1438 - val_loss: 246.5474\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 1.413 - 1s 541us/step - loss: 1.5369 - val_loss: 246.5839\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 1s 566us/step - loss: 3.7332 - val_loss: 246.0935\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 4.0191 - val_loss: 242.9579\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 2.8576 - val_loss: 244.5442\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 4.9032 - val_loss: 239.3411\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 1s 515us/step - loss: 4.6260 - val_loss: 244.6680\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 1s 597us/step - loss: 1.9155 - val_loss: 241.4742\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 1s 559us/step - loss: 0.7651 - val_loss: 243.4407\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 1s 601us/step - loss: 0.7057 - val_loss: 243.0138\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 1s 542us/step - loss: 0.5423 - val_loss: 246.0724\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 0.8612 - val_loss: 244.8003\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 1s 543us/step - loss: 1.1150 - val_loss: 244.2204\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 1s 517us/step - loss: 0.5765 - val_loss: 244.2090\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 1s 505us/step - loss: 0.4533 - val_loss: 242.9638\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 0.6237 - val_loss: 244.4180\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 0.2495 - val_loss: 244.4479\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 0.1364 - val_loss: 244.3229\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 1s 605us/step - loss: 0.1545 - val_loss: 244.3106\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 1s 533us/step - loss: 0.1984 - val_loss: 244.5674\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 0.1359 - val_loss: 244.5059\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 0.1443 - val_loss: 244.6537\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 1s 558us/step - loss: 0.1404 - val_loss: 244.1926\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 1s 534us/step - loss: 0.1365 - val_loss: 245.1673\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.1952 - val_loss: 245.4881\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 0.3527 - val_loss: 245.0547\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 0.5984 - val_loss: 244.5472\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 0.7128 - val_loss: 245.3183\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 0.3259 - val_loss: 244.8953\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 1s 581us/step - loss: 1.5156 - val_loss: 247.1431\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 1s 566us/step - loss: 9.8489 - val_loss: 263.9967\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 1s 549us/step - loss: 7.1972 - val_loss: 252.6989\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 1s 578us/step - loss: 3.8327 - val_loss: 245.0063\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 1s 517us/step - loss: 1.3395 - val_loss: 245.1173\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 0.8712 - val_loss: 245.2752\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 1s 605us/step - loss: 0.5460 - val_loss: 243.7798\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 0.5042 - val_loss: 244.4269\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 1s 535us/step - loss: 1.0207 - val_loss: 243.7086\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 1s 649us/step - loss: 0.8571 - val_loss: 245.4147\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 1s 663us/step - loss: 0.9920 - val_loss: 244.0594\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 1s 597us/step - loss: 0.3503 - val_loss: 244.1593\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 1s 545us/step - loss: 0.3493 - val_loss: 243.5604\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 0.2544 - val_loss: 242.5209\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 1s 529us/step - loss: 0.1616 - val_loss: 243.1478\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 1s 499us/step - loss: 0.1248 - val_loss: 243.3233\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 1s 521us/step - loss: 0.1322 - val_loss: 243.5626\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 1s 601us/step - loss: 0.5204 - val_loss: 245.4202\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 0.7751 - val_loss: 242.8055\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 1s 570us/step - loss: 0.3776 - val_loss: 244.1355\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 1s 567us/step - loss: 0.2495 - val_loss: 243.5243\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 1s 550us/step - loss: 0.2045 - val_loss: 243.9043\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 1s 599us/step - loss: 0.2404 - val_loss: 243.9555\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 0.2533 - val_loss: 243.4329\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 1s 576us/step - loss: 0.4675 - val_loss: 242.7212\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 1s 539us/step - loss: 0.3055 - val_loss: 243.7618\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 1s 600us/step - loss: 0.5101 - val_loss: 245.1981\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 1s 566us/step - loss: 2.3106 - val_loss: 246.5910\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 3.1714 - val_loss: 244.6248\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 1s 524us/step - loss: 1.4970 - val_loss: 243.2652\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 1.1477 - val_loss: 244.4393\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 1s 600us/step - loss: 0.8944 - val_loss: 243.5694\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 0.7312 - val_loss: 243.4915\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 1s 509us/step - loss: 0.7476 - val_loss: 242.5531\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 1s 592us/step - loss: 0.7336 - val_loss: 242.7999\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 1s 504us/step - loss: 0.3321 - val_loss: 242.3970\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 1s 548us/step - loss: 0.6950 - val_loss: 241.3134\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 0.3301 - val_loss: 243.3982\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 0.3400 - val_loss: 243.1150\n",
      "Epoch 518/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 558us/step - loss: 0.3705 - val_loss: 243.0460\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 1s 609us/step - loss: 2.8037 - val_loss: 245.7322\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 1s 642us/step - loss: 1.7426 - val_loss: 243.3545\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 1s 597us/step - loss: 0.9614 - val_loss: 243.4345\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 1s 576us/step - loss: 0.8956 - val_loss: 246.0390\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 1s 606us/step - loss: 1.1591 - val_loss: 243.4845\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 1s 592us/step - loss: 3.0193 - val_loss: 245.3334\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 1.4278 - val_loss: 246.6258\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 1s 530us/step - loss: 0.8151 - val_loss: 244.1462\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 1s 553us/step - loss: 0.8211 - val_loss: 243.7020\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 1s 581us/step - loss: 0.7267 - val_loss: 244.1966\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 1s 547us/step - loss: 0.8989 - val_loss: 243.5403\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 1s 555us/step - loss: 0.9524 - val_loss: 245.8734\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 1s 611us/step - loss: 2.6317 - val_loss: 244.8578\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 1.3803 - val_loss: 243.6736\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 1s 523us/step - loss: 0.5300 - val_loss: 243.8721\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 1s 599us/step - loss: 0.4050 - val_loss: 243.2676\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 1s 564us/step - loss: 0.2520 - val_loss: 242.9409\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 0.6652 - val_loss: 243.0357\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 0.5671 - val_loss: 243.1988\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 1s 551us/step - loss: 0.3538 - val_loss: 243.6422\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 0.3658 - val_loss: 243.4653\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 0.3194 - val_loss: 242.5342\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 1s 554us/step - loss: 0.2712 - val_loss: 243.0224\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 0.3471 - val_loss: 242.3654\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 1s 567us/step - loss: 0.2096 - val_loss: 243.4045\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 0.3997 - val_loss: 243.2492\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 1s 583us/step - loss: 0.5734 - val_loss: 242.4651\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 1s 573us/step - loss: 0.2743 - val_loss: 244.2684\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 1s 568us/step - loss: 0.6159 - val_loss: 244.1950\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 1s 598us/step - loss: 1.5229 - val_loss: 243.6548\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 1s 532us/step - loss: 2.0134 - val_loss: 241.8388\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 1s 522us/step - loss: 0.9724 - val_loss: 242.9009\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 1.1488 - val_loss: 240.5736\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 1s 533us/step - loss: 0.6256 - val_loss: 241.6477\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 1s 546us/step - loss: 0.5748 - val_loss: 241.7126\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 1s 565us/step - loss: 1.2529 - val_loss: 248.0755\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 1s 577us/step - loss: 1.7931 - val_loss: 241.3332\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 1s 456us/step - loss: 1.6311 - val_loss: 242.6709\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 307us/step - loss: 1.8841 - val_loss: 241.7314\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 2.9078 - val_loss: 241.2438\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 3.1841 - val_loss: 238.6813\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.8188 - val_loss: 241.1818\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 1.9485 - val_loss: 245.1754\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.2916 - val_loss: 241.5071\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 1.9248 - val_loss: 246.8001\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 1.4246 - val_loss: 243.3723\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.5664 - val_loss: 241.4827\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.3179 - val_loss: 241.6291\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.2441 - val_loss: 240.7958\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.2346 - val_loss: 241.8457\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.8317 - val_loss: 243.3942\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.3680 - val_loss: 241.6554\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.4216 - val_loss: 241.8938\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.2021 - val_loss: 242.5393\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.4495 - val_loss: 241.9601\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.2747 - val_loss: 241.8976\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 0.2755 - val_loss: 241.5817\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 1.2306 - val_loss: 242.7301\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 1.9198 - val_loss: 240.3146\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.9961 - val_loss: 243.8362\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.8079 - val_loss: 243.9271\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 2.7415 - val_loss: 243.0026\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 2.0306 - val_loss: 242.7397\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.9816 - val_loss: 240.4626\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.8461 - val_loss: 240.9827\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.7703 - val_loss: 241.8381\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.7476 - val_loss: 241.2906\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.4039 - val_loss: 240.7027\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.3039 - val_loss: 240.7874\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2033 - val_loss: 240.8905\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.1388 - val_loss: 240.4585\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.1982 - val_loss: 240.6148\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.6217 - val_loss: 240.7119\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 232us/step - loss: 2.0067 - val_loss: 240.4717\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 4.7449 - val_loss: 245.5927\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 5.4962 - val_loss: 239.4831\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 2.2206 - val_loss: 244.6459\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 1.1030 - val_loss: 242.6899\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.7025 - val_loss: 241.6480\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.6269 - val_loss: 241.6162\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.3956 - val_loss: 240.8916\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1837 - val_loss: 241.3736\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.3598 - val_loss: 241.0882\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.2491 - val_loss: 240.2026\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.3070 - val_loss: 241.5845\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.3126 - val_loss: 241.7259\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.1902 - val_loss: 241.5420\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.1679 - val_loss: 240.7142\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.3763 - val_loss: 242.1268\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.2295 - val_loss: 241.2620\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.1385 - val_loss: 240.9660\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.1538 - val_loss: 241.2945\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.2407 - val_loss: 240.2500\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.5843 - val_loss: 242.8730\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 1.1277 - val_loss: 241.6291\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 1.5332 - val_loss: 240.8508\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 2.1161 - val_loss: 240.4396\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.2993 - val_loss: 239.7253\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 1.1717 - val_loss: 240.5103\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.9927 - val_loss: 239.9658\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.5771 - val_loss: 239.5414\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.8470 - val_loss: 240.7027\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.6532 - val_loss: 244.0588\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 4.1754 - val_loss: 241.0854\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 1.8384 - val_loss: 237.7973\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.6877 - val_loss: 241.4827\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.5926 - val_loss: 240.5847\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.3756 - val_loss: 240.9028\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.3088 - val_loss: 239.0870\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.2313 - val_loss: 239.9323\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.2481 - val_loss: 239.8807\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.4891 - val_loss: 241.2031\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.2506 - val_loss: 240.0370\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 1.0711 - val_loss: 239.5743\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 1.1482 - val_loss: 239.3317\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.5805 - val_loss: 239.4663\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 1.0103 - val_loss: 239.9549\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.7879 - val_loss: 239.7802\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.5578 - val_loss: 240.9065\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.2937 - val_loss: 240.2637\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.2557 - val_loss: 239.5145\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.6858 - val_loss: 240.1880\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 2.2632 - val_loss: 240.1041\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 1.9148 - val_loss: 240.0193\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.8739 - val_loss: 239.5645\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 0.5419 - val_loss: 239.4836\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.3326 - val_loss: 239.2653\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.7704 - val_loss: 241.1269\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.5829 - val_loss: 238.9027\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.3097 - val_loss: 239.1415\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.4283 - val_loss: 239.1611\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.4739 - val_loss: 240.1126\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.3079 - val_loss: 240.1678\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.2238 - val_loss: 240.8524\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.2572 - val_loss: 239.2627\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 0.3414 - val_loss: 239.4346\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 3.4698 - val_loss: 242.2791\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 2.5584 - val_loss: 237.8029\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.3061 - val_loss: 239.5897\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 290us/step - loss: 1.1677 - val_loss: 236.8550\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 1.4587 - val_loss: 239.2868\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.9294 - val_loss: 241.4590\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 3.0865 - val_loss: 238.7204\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.9127 - val_loss: 238.5955\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 2.2470 - val_loss: 239.4501\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 1.0588 - val_loss: 238.3400\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.8635 - val_loss: 240.6686\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.4951 - val_loss: 239.8321\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.2948 - val_loss: 239.1065\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.2614 - val_loss: 239.2056\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.4296 - val_loss: 239.0814\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.2056 - val_loss: 238.8119\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.1775 - val_loss: 239.1960\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2662 - val_loss: 240.5406\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.3466 - val_loss: 239.3230\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.3982 - val_loss: 238.8721\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.3706 - val_loss: 239.1813\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 0.3816 - val_loss: 239.1447\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.3100 - val_loss: 239.7402\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 0.2792 - val_loss: 238.9198\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.1828 - val_loss: 239.3892\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 0.1715 - val_loss: 239.2670\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.3827 - val_loss: 238.2650\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 2.4216 - val_loss: 243.0225\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 6.4757 - val_loss: 238.3622\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 3.6387 - val_loss: 238.4773\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 3.4847 - val_loss: 240.2085\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 4.2901 - val_loss: 239.0129\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 1.7704 - val_loss: 240.9086\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.4064 - val_loss: 240.2344\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.5022 - val_loss: 239.3287\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.3803 - val_loss: 240.2325\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.352 - 0s 254us/step - loss: 0.3580 - val_loss: 239.8760\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.3741 - val_loss: 238.3969\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.4479 - val_loss: 240.2627\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.1818 - val_loss: 239.9823\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.1695 - val_loss: 239.7948\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.1974 - val_loss: 239.6043\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1303 - val_loss: 239.6493\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.0997 - val_loss: 239.7904\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.0674 - val_loss: 239.7622\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.0534 - val_loss: 239.7196\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.0650 - val_loss: 239.6645\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.0809 - val_loss: 240.2008\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.1051 - val_loss: 240.2117\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.1386 - val_loss: 239.9801\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.0798 - val_loss: 239.5595\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.1095 - val_loss: 240.1980\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 282us/step - loss: 0.4080 - val_loss: 239.4408\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.3696 - val_loss: 242.3273\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.7800 - val_loss: 240.0956\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.7386 - val_loss: 239.8943\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.5568 - val_loss: 240.0519\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.3976 - val_loss: 239.9457\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.9234 - val_loss: 242.0333\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.8263 - val_loss: 239.8447\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.6463 - val_loss: 241.1978\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 301us/step - loss: 1.4071 - val_loss: 239.7445\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 2.0206 - val_loss: 239.7604\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.5811 - val_loss: 238.9520\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 1.2857 - val_loss: 237.6564\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 2.2501 - val_loss: 237.7134\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.8120 - val_loss: 239.7679\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.8265 - val_loss: 239.0758\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 1.1545 - val_loss: 236.9799\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.6160 - val_loss: 237.1171\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.3477 - val_loss: 238.9938\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.3400 - val_loss: 238.7751\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.2307 - val_loss: 237.5714\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1386 - val_loss: 238.3014\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.1196 - val_loss: 238.4344\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.1599 - val_loss: 238.3575\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.3044 - val_loss: 239.0861\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.5846 - val_loss: 239.4655\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.2378 - val_loss: 237.9078\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.3610 - val_loss: 238.2091\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.8445 - val_loss: 239.2404\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 1.8172 - val_loss: 237.8386\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 1.3637 - val_loss: 239.8630\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 1.1469 - val_loss: 240.3742\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 3.0190 - val_loss: 238.4600\n",
      "Epoch 740/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 259us/step - loss: 1.3407 - val_loss: 236.7041\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.8351 - val_loss: 237.5556\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.6273 - val_loss: 236.4867\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.3312 - val_loss: 238.1200\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.3458 - val_loss: 237.6292\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.1924 - val_loss: 237.9513\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.6182 - val_loss: 237.0280\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.9714 - val_loss: 238.3910\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.7030 - val_loss: 241.2139\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.8435 - val_loss: 238.3012\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.3583 - val_loss: 238.3270\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.7240 - val_loss: 237.7262\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 1.4040 - val_loss: 240.8836\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 1.2017 - val_loss: 238.0006\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.0552 - val_loss: 238.7354\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 291us/step - loss: 0.4757 - val_loss: 238.2551\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.2715 - val_loss: 237.0875\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.3622 - val_loss: 239.0775\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2413 - val_loss: 238.0008\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.6316 - val_loss: 238.1824\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.2293 - val_loss: 236.6217\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 2.0651 - val_loss: 237.9575\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.4568 - val_loss: 239.4196\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.9842 - val_loss: 238.9299\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.5670 - val_loss: 239.0574\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 1.0869 - val_loss: 241.2646\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.8593 - val_loss: 239.4458\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.3023 - val_loss: 238.8598\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1496 - val_loss: 238.1483\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.1477 - val_loss: 237.6089\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1341 - val_loss: 238.7227\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.0961 - val_loss: 238.3354\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.1167 - val_loss: 238.8497\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.3403 - val_loss: 238.7896\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.0472 - val_loss: 238.5171\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 2.3659 - val_loss: 237.2254\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 2.0235 - val_loss: 240.6233\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 2.0704 - val_loss: 240.8638\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.7978 - val_loss: 237.1420\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.7134 - val_loss: 238.4667\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 1.8259 - val_loss: 237.9994\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 1.9191 - val_loss: 236.9507\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 8.2668 - val_loss: 246.8623\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 2.6036 - val_loss: 238.0085\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.6906 - val_loss: 236.4768\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.4944 - val_loss: 238.0691\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.3155 - val_loss: 237.2198\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.2105 - val_loss: 237.0757\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1117 - val_loss: 237.2976\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.0831 - val_loss: 237.2344\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.1549 - val_loss: 237.3155\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.3957 - val_loss: 236.3162\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.4380 - val_loss: 237.4320\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.3278 - val_loss: 236.7952\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.2541 - val_loss: 237.0400\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.2975 - val_loss: 237.4114\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.1774 - val_loss: 236.9110\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 309us/step - loss: 0.0772 - val_loss: 237.2590\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.1181 - val_loss: 237.0425\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.1545 - val_loss: 236.7840\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.1202 - val_loss: 237.8209\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.1377 - val_loss: 236.9127\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.0663 - val_loss: 237.0517\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 295us/step - loss: 0.0579 - val_loss: 236.9061\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.0936 - val_loss: 237.6590\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.2184 - val_loss: 236.4817\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 1.8683 - val_loss: 237.5232\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 2.7838 - val_loss: 239.4250\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 1.2554 - val_loss: 233.5941\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 1.4900 - val_loss: 234.4524\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.2691 - val_loss: 236.6516\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 1.7911 - val_loss: 240.1487\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 2.1652 - val_loss: 239.2579\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 1.8377 - val_loss: 239.4609\n",
      "Epoch 814/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 246us/step - loss: 1.2139 - val_loss: 237.2039\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 1.3332 - val_loss: 236.5898\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.7588 - val_loss: 236.8191\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.7734 - val_loss: 235.9758\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.4059 - val_loss: 237.8063\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.2351 - val_loss: 235.8933\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.2167 - val_loss: 235.9809\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.2410 - val_loss: 236.1850\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.3525 - val_loss: 236.4098\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.1866 - val_loss: 235.0659\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.8794 - val_loss: 235.3151\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.3666 - val_loss: 235.3693\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.3132 - val_loss: 236.9279\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.3434 - val_loss: 237.9920\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.2064 - val_loss: 235.7520\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 0.3413 - val_loss: 237.2270\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.3389 - val_loss: 236.2550\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 0.4570 - val_loss: 236.0227\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.7416 - val_loss: 236.6448\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.0927 - val_loss: 236.4296\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 323us/step - loss: 0.6665 - val_loss: 235.8168\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.5081 - val_loss: 240.7177\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.7351 - val_loss: 236.2031\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.3482 - val_loss: 237.1165\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.2773 - val_loss: 236.7592\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.8788 - val_loss: 235.8853\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.5516 - val_loss: 235.8486\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.3613 - val_loss: 236.1696\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.2056 - val_loss: 236.8469\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.3989 - val_loss: 237.6080\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.4200 - val_loss: 235.9141\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.4834 - val_loss: 236.0248\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 3.2951 - val_loss: 242.0401\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 4.8295 - val_loss: 234.7389\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 3.1550 - val_loss: 235.8409\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.4007 - val_loss: 234.6722\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.8825 - val_loss: 235.9894\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.4042 - val_loss: 235.3178\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 1.1279 - val_loss: 234.9164\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.5396 - val_loss: 234.7210\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.4051 - val_loss: 234.3483\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.3267 - val_loss: 235.2548\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.1670 - val_loss: 235.6703\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.2018 - val_loss: 235.3994\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.7472 - val_loss: 234.8371\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.3261 - val_loss: 234.7516\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.3030 - val_loss: 234.5388\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.2525 - val_loss: 235.9633\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.3157 - val_loss: 234.9124\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1883 - val_loss: 235.7767\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.1327 - val_loss: 235.5136\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.1052 - val_loss: 236.3835\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.1289 - val_loss: 235.9079\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1483 - val_loss: 235.1185\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.1631 - val_loss: 235.3744\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.1532 - val_loss: 235.7517\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.1003 - val_loss: 235.6577\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.1910 - val_loss: 235.7018\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.2015 - val_loss: 235.2665\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 1.2017 - val_loss: 235.3831\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 3.6067 - val_loss: 237.3531\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 302us/step - loss: 11.6940 - val_loss: 245.9001\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 3.8113 - val_loss: 234.2224\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.4056 - val_loss: 234.8542\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.7521 - val_loss: 236.0967\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.4275 - val_loss: 235.3945\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.3795 - val_loss: 236.2264\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 297us/step - loss: 0.1851 - val_loss: 235.5415\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.1862 - val_loss: 236.4820\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.1284 - val_loss: 235.9052\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.1459 - val_loss: 235.5197\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.1035 - val_loss: 235.6406\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.0872 - val_loss: 235.7336\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.0644 - val_loss: 235.4862\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.0786 - val_loss: 235.6904\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.0867 - val_loss: 235.5980\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.0525 - val_loss: 235.6019\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.0452 - val_loss: 235.4101\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.0672 - val_loss: 234.9009\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.0944 - val_loss: 235.1603\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.1001 - val_loss: 235.1356\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.0897 - val_loss: 235.5387\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.0505 - val_loss: 235.3736\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.0638 - val_loss: 235.6663\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.0893 - val_loss: 235.7329\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.0975 - val_loss: 235.6143\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.2591 - val_loss: 235.4776\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 1.2798 - val_loss: 237.4855\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 1.5021 - val_loss: 237.2785\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 2.6332 - val_loss: 236.1539\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.7631 - val_loss: 236.0199\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 1.5990 - val_loss: 235.7897\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.4650 - val_loss: 238.1763\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 1.7159 - val_loss: 245.9006\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 2.9262 - val_loss: 235.0901\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.8105 - val_loss: 236.8272\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 2.0599 - val_loss: 238.0457\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 1.1820 - val_loss: 234.2499\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.3655 - val_loss: 235.0604\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.2156 - val_loss: 235.0227\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.1979 - val_loss: 235.5784\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 287us/step - loss: 0.2265 - val_loss: 236.0266\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.2793 - val_loss: 236.0762\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 289us/step - loss: 0.1672 - val_loss: 235.4798\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.1484 - val_loss: 234.9866\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.2142 - val_loss: 236.5732\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.2491 - val_loss: 236.2015\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.2534 - val_loss: 235.7505\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 277us/step - loss: 0.7037 - val_loss: 236.3071\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.5440 - val_loss: 235.3350\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.4295 - val_loss: 235.2241\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 1.6304 - val_loss: 235.3211\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.7830 - val_loss: 234.5525\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 1.5645 - val_loss: 239.0037\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 1.8528 - val_loss: 238.8873\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.2840 - val_loss: 234.6208\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.5252 - val_loss: 234.8323\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2206 - val_loss: 235.2995\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.3420 - val_loss: 235.6422\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.1760 - val_loss: 235.9055\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.1686 - val_loss: 235.2604\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.2346 - val_loss: 236.6087\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.7939 - val_loss: 234.3743\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.5394 - val_loss: 236.2394\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.3871 - val_loss: 233.5440\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.5682 - val_loss: 235.6571\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 3.4565 - val_loss: 231.3284\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 1.4152 - val_loss: 234.0106\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 1.2500 - val_loss: 235.7755\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 1.2194 - val_loss: 234.1315\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.6427 - val_loss: 235.5686\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 0.2714 - val_loss: 235.7667\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2730 - val_loss: 234.1312\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.1446 - val_loss: 234.6117\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.0878 - val_loss: 235.0107\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.2668 - val_loss: 235.5313\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.3726 - val_loss: 234.7344\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 0.2071 - val_loss: 235.2685\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.1334 - val_loss: 234.0796\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 0.1637 - val_loss: 235.6035\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 0.3355 - val_loss: 236.0789\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 296us/step - loss: 0.2060 - val_loss: 235.2771\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 298us/step - loss: 0.2993 - val_loss: 236.1830\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 279us/step - loss: 0.3241 - val_loss: 234.3955\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 257us/step - loss: 0.3073 - val_loss: 234.9043\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 308us/step - loss: 0.7085 - val_loss: 235.9495\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 3.2734 - val_loss: 235.2339\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 274us/step - loss: 1.9562 - val_loss: 234.1003\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 255us/step - loss: 2.1351 - val_loss: 233.7690\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.9840 - val_loss: 235.0398\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.5103 - val_loss: 234.3080\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.2277 - val_loss: 233.7185\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.2798 - val_loss: 235.1024\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.3290 - val_loss: 235.1763\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.2278 - val_loss: 233.7620\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.1981 - val_loss: 234.5546\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.1398 - val_loss: 234.6000\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.1772 - val_loss: 234.4296\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.1048 - val_loss: 234.2871\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.1368 - val_loss: 234.6733\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 261us/step - loss: 0.1218 - val_loss: 233.9467\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.3646 - val_loss: 234.7419\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.3697 - val_loss: 235.3958\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.6173 - val_loss: 233.5111\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 273us/step - loss: 0.5537 - val_loss: 236.0249\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.4271 - val_loss: 235.1764\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.4406 - val_loss: 235.6304\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 2.8538 - val_loss: 236.0908\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 2.1218 - val_loss: 238.4570\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.7317 - val_loss: 236.2620\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 300us/step - loss: 1.3666 - val_loss: 237.8117\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 268us/step - loss: 1.4763 - val_loss: 235.1256\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.1582 - val_loss: 235.4587\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.4049 - val_loss: 237.7365\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 1.7461 - val_loss: 236.4975\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.9238 - val_loss: 234.4679\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.6849 - val_loss: 234.8787\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.4802 - val_loss: 234.5000\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2721 - val_loss: 234.4186\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.4185 - val_loss: 235.2448\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.3230 - val_loss: 235.8839\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.3837 - val_loss: 235.0977\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.7378 - val_loss: 236.2696\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.4232 - val_loss: 234.5368\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.1826 - val_loss: 234.5192\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.3490 - val_loss: 237.2261\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.6024 - val_loss: 237.0173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 289us/step\n",
      "174.53951232910157\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "tb_hist= keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val), callbacks=[tb_hist])\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 944us/step - loss: 7078.2414 - val_loss: 1459.9569\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 1175.2586 - val_loss: 740.0504\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 773.0015 - val_loss: 559.1206\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 1s 921us/step - loss: 698.5299 - val_loss: 326.7149\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 547.9244 - val_loss: 558.8856\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 540.4778 - val_loss: 372.8930\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 1s 960us/step - loss: 533.1230 - val_loss: 447.9130\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 475.3098 - val_loss: 539.4418\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 469.4049 - val_loss: 257.4097\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 442.0312 - val_loss: 225.2095\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 415.2483 - val_loss: 290.2826\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 442.3848 - val_loss: 204.6814\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 381.5347 - val_loss: 316.7222\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 371.1888 - val_loss: 281.6550\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 1s 725us/step - loss: 398.7641 - val_loss: 230.3484\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 469.6201 - val_loss: 223.2596\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 406.6633 - val_loss: 283.8198\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 362.8401 - val_loss: 651.1983\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 370.6461 - val_loss: 440.2042\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 509.8612 - val_loss: 1986.9669\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 410.9205 - val_loss: 203.4494\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 348.8074 - val_loss: 293.6888\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 372.2495 - val_loss: 227.2572\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 1s 708us/step - loss: 345.7213 - val_loss: 743.1557\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 335.7756 - val_loss: 749.7211\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 293.6648 - val_loss: 507.3448\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 326.1384 - val_loss: 262.3014\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 376.7918 - val_loss: 384.3826\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 1s 715us/step - loss: 351.4999 - val_loss: 395.4782\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 338.0662 - val_loss: 523.0086\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 318.7651 - val_loss: 787.6151\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 1s 708us/step - loss: 308.6330 - val_loss: 611.3571\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 293.7132 - val_loss: 376.6934\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 356.3653 - val_loss: 631.6727\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 290.0705 - val_loss: 1084.7790\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 300.1646 - val_loss: 576.5313\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 1s 893us/step - loss: 297.3887 - val_loss: 950.8342\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 1s 876us/step - loss: 267.9675 - val_loss: 735.6300\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 1s 949us/step - loss: 311.5905 - val_loss: 1352.2615\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 284.3024 - val_loss: 1911.9154\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 298.9033 - val_loss: 851.5304\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 296.3530 - val_loss: 810.2400\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 1s 872us/step - loss: 306.4684 - val_loss: 557.4211\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 270.6130 - val_loss: 1577.8995\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 237.9020 - val_loss: 1173.6474\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 1s 893us/step - loss: 270.8731 - val_loss: 1265.4131\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 245.1047 - val_loss: 1610.0299\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 1s 914us/step - loss: 259.5419 - val_loss: 1347.5869\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 1s 965us/step - loss: 239.7432 - val_loss: 1079.5940\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 1s 888us/step - loss: 269.6602 - val_loss: 782.6560\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 253.0116 - val_loss: 1208.4584\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 298.9832 - val_loss: 1208.5476\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 331.6154 - val_loss: 748.1842\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 306.0525 - val_loss: 930.0428\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 234.9012 - val_loss: 1930.5607\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 260.9511 - val_loss: 904.1776\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 238.7359 - val_loss: 996.6357\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 306.6281 - val_loss: 983.3757\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 1s 837us/step - loss: 299.0510 - val_loss: 782.4779\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 240.6306 - val_loss: 1894.2205\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 1s 888us/step - loss: 227.2501 - val_loss: 1378.8644\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 247.5658 - val_loss: 1741.1469\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 249.2780 - val_loss: 1165.3334\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 256.1368 - val_loss: 993.9676\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 1s 921us/step - loss: 265.6402 - val_loss: 1322.4883\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 1s 891us/step - loss: 237.9363 - val_loss: 1606.8587\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 1s 881us/step - loss: 240.7030 - val_loss: 1265.3144\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 1s 903us/step - loss: 257.4025 - val_loss: 932.6294\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 1s 941us/step - loss: 252.6656 - val_loss: 2080.4488\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 1s 940us/step - loss: 230.3054 - val_loss: 1498.1483\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 221.4675 - val_loss: 1241.8422\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 236.2133 - val_loss: 1423.2604\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 1s 921us/step - loss: 235.3084 - val_loss: 1453.9853\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 803us/step - loss: 222.0265 - val_loss: 1823.9997\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 232.5118 - val_loss: 1347.9198\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 253.2822 - val_loss: 942.1937\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 265.6740 - val_loss: 1571.9305\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 218.8100 - val_loss: 1892.0486\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 216.4970 - val_loss: 1193.0896\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 211.8451 - val_loss: 2368.3266\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 235.7002 - val_loss: 1740.0353\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 1s 946us/step - loss: 218.7327 - val_loss: 1766.5390\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 240.0129 - val_loss: 1308.2860\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 1s 980us/step - loss: 211.4083 - val_loss: 1407.5452\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 1s 922us/step - loss: 214.1794 - val_loss: 1908.4507\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 248.9169 - val_loss: 1142.6898\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 1s 910us/step - loss: 241.8615 - val_loss: 2281.2825\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 1s 942us/step - loss: 260.6317 - val_loss: 1497.1226\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 1s 897us/step - loss: 219.6376 - val_loss: 1282.5465\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 223.2560 - val_loss: 1337.6130\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 1s 837us/step - loss: 191.1660 - val_loss: 1615.7909\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 1s 893us/step - loss: 207.6438 - val_loss: 1951.5941\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 197.2080 - val_loss: 1542.5767\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 1s 878us/step - loss: 210.0723 - val_loss: 1932.7517\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 1s 965us/step - loss: 191.1163 - val_loss: 1139.5892\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 262.9818 - val_loss: 1869.0321\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 230.6988 - val_loss: 1211.6612\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 202.9869 - val_loss: 1486.2424\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 216.5075 - val_loss: 1718.8226\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 209.9101 - val_loss: 1656.6950\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 231.5306 - val_loss: 851.2287\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 210.9501 - val_loss: 1546.1899\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 223.3274 - val_loss: 981.7707\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 197.9461 - val_loss: 1339.6346\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 259.0413 - val_loss: 1620.7014\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 197.2058 - val_loss: 1360.8393\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 209.1240 - val_loss: 1017.4612\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 199.2191 - val_loss: 1553.5126\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 203.4062 - val_loss: 2057.3571\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 188.2800 - val_loss: 1524.3939\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 218.1667 - val_loss: 1115.4680\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 223.2414 - val_loss: 2004.9206\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 204.5474 - val_loss: 2102.3379\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 224.8072 - val_loss: 1942.6726\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 260.2538 - val_loss: 1389.5774\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 194.9437 - val_loss: 509.6963\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 209.7502 - val_loss: 1548.0477\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 183.2253 - val_loss: 1220.0412\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 173.6642 - val_loss: 1805.1824\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 195.5486 - val_loss: 1530.3289\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 211.0790 - val_loss: 2000.7697\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 194.3484 - val_loss: 1475.3377\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 178.2173 - val_loss: 2066.9426\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 203.3994 - val_loss: 1826.9173\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 187.6428 - val_loss: 1632.7743\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 184.9188 - val_loss: 1951.6712\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 186.4957 - val_loss: 1630.5777\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 218.3431 - val_loss: 2415.8138\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 194.1849 - val_loss: 1392.9437\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 192.6054 - val_loss: 1424.3493\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 199.3347 - val_loss: 1346.2980\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 187.6424 - val_loss: 2430.7537\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 190.9150 - val_loss: 1248.9446\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 188.9480 - val_loss: 1098.6249\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 181.4036 - val_loss: 1577.2485\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 196.8893 - val_loss: 981.5432\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 182.4753 - val_loss: 1446.8776\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 159.8664 - val_loss: 1319.0184\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 157.8824 - val_loss: 1281.1419\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 164.5819 - val_loss: 1608.3238\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 175.6763 - val_loss: 1240.4927\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 216.6408 - val_loss: 1131.6306\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 159.1413 - val_loss: 1473.0434\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 199.5478 - val_loss: 2182.7706\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 183.8681 - val_loss: 1140.1501\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 188.6263 - val_loss: 1373.3313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 176.2270 - val_loss: 2130.1338\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 188.9358 - val_loss: 1146.8537\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 162.7884 - val_loss: 1637.9397\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 157.4599 - val_loss: 1794.7547\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 155.8097 - val_loss: 1697.3818\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 174.1969 - val_loss: 1986.5973\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 157.4514 - val_loss: 1011.0805\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 178.6086 - val_loss: 1611.7966\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 168.6694 - val_loss: 1920.4843\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 180.2781 - val_loss: 1565.6899\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 177.9361 - val_loss: 1323.4098\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 148.2880 - val_loss: 1581.6237\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 162.0074 - val_loss: 1282.6717\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 181.0755 - val_loss: 1099.6689\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 173.9460 - val_loss: 2179.6036\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 175.0573 - val_loss: 1469.0162\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 139.4569 - val_loss: 1423.9306\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 148.9470 - val_loss: 1562.0669\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 159.8448 - val_loss: 1438.0506\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 155.0958 - val_loss: 1726.5330\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 184.7062 - val_loss: 1326.6132\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 171.5560 - val_loss: 1699.9871\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 158.7289 - val_loss: 1430.0379\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 209.4181 - val_loss: 1155.2962\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 161.9811 - val_loss: 1516.7071\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 160.5090 - val_loss: 1295.0634\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 140.3102 - val_loss: 1476.3284\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 168.7055 - val_loss: 2134.4690\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 180.2666 - val_loss: 1574.1156\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 163.2228 - val_loss: 1549.8566\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 155.1098 - val_loss: 1738.1907\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 193.8232 - val_loss: 854.2390\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 167.7968 - val_loss: 985.3829\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 174.3343 - val_loss: 1047.4137\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 159.4141 - val_loss: 1466.4892\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 159.8085 - val_loss: 1056.6010\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 184.6761 - val_loss: 2000.8597\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 172.9875 - val_loss: 1883.4233\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 157.2977 - val_loss: 1223.2390\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 157.3125 - val_loss: 1965.0746\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 164.6963 - val_loss: 1169.4937\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 156.3024 - val_loss: 765.5043\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 165.6710 - val_loss: 1635.2674\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 153.4335 - val_loss: 1948.8172\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 158.7515 - val_loss: 1333.0919\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 170.6674 - val_loss: 2140.4764\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 158.9186 - val_loss: 1113.2978\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 144.8577 - val_loss: 1284.0924\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 147.3768 - val_loss: 1532.1595\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 1s 727us/step - loss: 141.4744 - val_loss: 1492.5442\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 142.0712 - val_loss: 1217.7005\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 137.5517 - val_loss: 1173.1670\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 170.6072 - val_loss: 1623.1652\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 143.4784 - val_loss: 1319.8168\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 148.8330 - val_loss: 1294.3468\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 170.7607 - val_loss: 1193.6965\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 128.3413 - val_loss: 877.2579\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 165.5133 - val_loss: 2000.7374\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 129.7042 - val_loss: 1555.0615\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 142.7915 - val_loss: 1324.3914\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 174.3509 - val_loss: 1176.4619\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 165.5906 - val_loss: 1674.1391\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 148.1932 - val_loss: 1719.9085\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 152.1083 - val_loss: 1838.3877\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 128.2456 - val_loss: 1688.9959\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 135.2370 - val_loss: 1788.2585\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 149.1678 - val_loss: 1508.6652\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 158.8780 - val_loss: 1405.4969\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 145.4892 - val_loss: 1474.7022\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 142.3796 - val_loss: 894.2190\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 142.9228 - val_loss: 1777.3170\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 136.9604 - val_loss: 1418.9586\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 833us/step - loss: 142.8477 - val_loss: 1868.2306\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 157.0415 - val_loss: 1245.3437\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 148.3456 - val_loss: 1220.4088\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 172.0057 - val_loss: 910.9952\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 195.0826 - val_loss: 923.3688\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 178.6530 - val_loss: 1575.8475\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 140.0487 - val_loss: 1237.1036\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 134.2686 - val_loss: 1625.2731\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 140.0985 - val_loss: 1818.8913\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 125.7553 - val_loss: 1495.7940\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 134.5160 - val_loss: 1280.0540\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 131.4912 - val_loss: 1708.0857\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 121.3771 - val_loss: 1081.2431\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 138.2314 - val_loss: 1336.6211\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 144.5068 - val_loss: 1722.0801\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 127.3437 - val_loss: 1482.0096\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 143.9823 - val_loss: 1443.6183\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 132.2387 - val_loss: 1157.7652\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 123.4243 - val_loss: 1485.4756\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 147.5426 - val_loss: 1024.7367\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 132.5265 - val_loss: 1371.5080\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 136.3439 - val_loss: 1298.8021\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 117.8666 - val_loss: 1373.6719\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 146.1003 - val_loss: 1209.4958\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 1s 965us/step - loss: 122.1600 - val_loss: 1470.5038\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 146.042 - 2s 1ms/step - loss: 148.6414 - val_loss: 1298.3032\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 124.6593 - val_loss: 1489.7494\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 135.0158 - val_loss: 1862.1864\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 154.9128 - val_loss: 1669.2387\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 168.0634 - val_loss: 1076.1390\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 127.2579 - val_loss: 1045.7066\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 122.2737 - val_loss: 1319.2275\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 139.7091 - val_loss: 1038.2681\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 138.3114 - val_loss: 1247.2957\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 148.2791 - val_loss: 2129.4612\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 128.7554 - val_loss: 1837.4912\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 149.9451 - val_loss: 1239.1666\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 131.9643 - val_loss: 1159.5700\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 133.4332 - val_loss: 1153.4004\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 135.9177 - val_loss: 1243.7564\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 127.5389 - val_loss: 1422.4585\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 138.8272 - val_loss: 1288.2621\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 118.8245 - val_loss: 1177.3173\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 165.9048 - val_loss: 1590.7192\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 142.9351 - val_loss: 1721.1090\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 124.1272 - val_loss: 1473.9916\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 155.3392 - val_loss: 1792.8135\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 150.1451 - val_loss: 1056.5559\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 132.9216 - val_loss: 1161.3164\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 106.1260 - val_loss: 1223.1767\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 137.4834 - val_loss: 1802.8442\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 120.8284 - val_loss: 1605.2907\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 131.2688 - val_loss: 1536.6992\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 141.2140 - val_loss: 912.1609\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 176.4019 - val_loss: 1346.5511\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 129.1743 - val_loss: 1448.5755\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 117.5747 - val_loss: 838.4049\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 119.6419 - val_loss: 1309.3317\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 136.9830 - val_loss: 1588.4224\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 133.4738 - val_loss: 1338.3972\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 123.0192 - val_loss: 1155.8881\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 137.2100 - val_loss: 1191.7915\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 112.0411 - val_loss: 1610.6440\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 126.6540 - val_loss: 884.3833\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 117.8849 - val_loss: 1503.3851\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 148.0533 - val_loss: 1405.2512\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 120.9195 - val_loss: 1415.1974\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 123.9613 - val_loss: 876.0418\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 130.7228 - val_loss: 1414.8436\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 125.4463 - val_loss: 1582.8905\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 126.9288 - val_loss: 1128.2400\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 123.3323 - val_loss: 983.0990\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 731us/step - loss: 117.5193 - val_loss: 1084.2473\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 120.1165 - val_loss: 1490.7157\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 152.7408 - val_loss: 1367.0203\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 121.5205 - val_loss: 1096.8842\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 133.6473 - val_loss: 1219.1013\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 1s 727us/step - loss: 114.8427 - val_loss: 1299.8776\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 114.0867 - val_loss: 1146.0267\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 111.4819 - val_loss: 1127.7596\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 120.8931 - val_loss: 1215.0404\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 119.2396 - val_loss: 1149.1683\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 132.4510 - val_loss: 1187.8022\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 111.1580 - val_loss: 884.4204\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 119.1054 - val_loss: 1365.9669\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 1s 726us/step - loss: 111.3077 - val_loss: 1339.1541\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 119.4016 - val_loss: 1328.9068\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 134.7789 - val_loss: 1006.0142\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 122.6744 - val_loss: 1125.4960\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 128.4583 - val_loss: 974.2885\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 1s 726us/step - loss: 139.4570 - val_loss: 1166.1935\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 125.6769 - val_loss: 1077.1890\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 110.7419 - val_loss: 1441.8042\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 120.6509 - val_loss: 1427.6769\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 117.5898 - val_loss: 1297.6212\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 117.9691 - val_loss: 1444.2482\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 121.5558 - val_loss: 1320.1689\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 131.3129 - val_loss: 1208.5354\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 127.6761 - val_loss: 926.5169\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 112.4488 - val_loss: 1392.1275\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 129.7028 - val_loss: 892.1960\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 111.1184 - val_loss: 1242.7261\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 130.2474 - val_loss: 1434.0523\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 126.9657 - val_loss: 1890.2938\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 126.7420 - val_loss: 1328.1822\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 118.8470 - val_loss: 1449.9957\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 131.6191 - val_loss: 1480.8704\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 119.5635 - val_loss: 1015.1887\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 113.9939 - val_loss: 935.6987\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 122.3300 - val_loss: 928.2189\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 103.0535 - val_loss: 1106.2450\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 108.8324 - val_loss: 1246.4340\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 109.5523 - val_loss: 1111.4126\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 111.6043 - val_loss: 1252.1541\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 101.6295 - val_loss: 1359.9301\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 126.8832 - val_loss: 1845.7652\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 122.8164 - val_loss: 1129.0158\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 118.8666 - val_loss: 1384.8153\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 115.4018 - val_loss: 1145.5506\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 107.8723 - val_loss: 1049.3566\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 118.2881 - val_loss: 1172.8992\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 116.6444 - val_loss: 1600.4480\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 111.0013 - val_loss: 1034.8552\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 120.1789 - val_loss: 1237.8844\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 115.6762 - val_loss: 1123.6578\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 115.6974 - val_loss: 1137.9261\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 144.4508 - val_loss: 928.4377\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 113.4386 - val_loss: 906.9720\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 1s 934us/step - loss: 113.3439 - val_loss: 1454.8707\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 1s 879us/step - loss: 117.7233 - val_loss: 1257.9821\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 1s 933us/step - loss: 116.4715 - val_loss: 1311.1522\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 103.9331 - val_loss: 1483.8736\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 143.7300 - val_loss: 1724.2227\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 119.4161 - val_loss: 1450.9316\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 102.1535 - val_loss: 1538.0672\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 117.3700 - val_loss: 849.2920\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 1s 876us/step - loss: 109.8356 - val_loss: 1225.5807\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 121.4325 - val_loss: 1129.5936\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 1s 953us/step - loss: 110.3680 - val_loss: 1282.1758\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 1s 937us/step - loss: 121.3562 - val_loss: 923.7172\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 126.5827 - val_loss: 1419.6089\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 1s 906us/step - loss: 122.8526 - val_loss: 1151.5304\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 1s 854us/step - loss: 110.1762 - val_loss: 1046.7179\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 121.3501 - val_loss: 1140.7656\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 106.4825 - val_loss: 1676.6374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 1s 899us/step - loss: 115.1598 - val_loss: 1646.9483\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 134.1884 - val_loss: 1096.1125\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 106.7479 - val_loss: 1340.4446\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 106.1860 - val_loss: 881.6447\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 117.8004 - val_loss: 941.3116\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 130.1931 - val_loss: 1356.5448\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 114.7816 - val_loss: 1172.2396\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 113.4655 - val_loss: 1245.4282\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 99.1427 - val_loss: 1211.3969\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 1s 727us/step - loss: 116.4340 - val_loss: 1303.3803\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 115.7734 - val_loss: 874.8357\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 133.4467 - val_loss: 1433.1468\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 127.1675 - val_loss: 1224.4252\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 109.9027 - val_loss: 1015.4381\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 96.6228 - val_loss: 938.0835\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 102.0705 - val_loss: 1430.3696\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 109.2654 - val_loss: 1111.1487\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 1s 726us/step - loss: 105.9184 - val_loss: 869.1684\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 119.3566 - val_loss: 1374.8000\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 115.9722 - val_loss: 1053.6679\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 106.6898 - val_loss: 1468.3001\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 99.4177 - val_loss: 1353.6584\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 95.5373 - val_loss: 1271.2613\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 106.4743 - val_loss: 1105.3291\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 111.0293 - val_loss: 789.6213\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 111.4440 - val_loss: 1186.5094\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 109.6281 - val_loss: 1184.2518\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 114.1907 - val_loss: 1149.0589\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 111.8754 - val_loss: 1105.9208\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 108.1147 - val_loss: 1340.9918\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 121.5081 - val_loss: 1214.4479\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 103.0778 - val_loss: 798.6910\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 119.1150 - val_loss: 1154.8695\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 107.8402 - val_loss: 974.5866\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 106.2074 - val_loss: 1332.9009\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 108.3987 - val_loss: 943.0909\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 106.7439 - val_loss: 1347.2786\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 117.8634 - val_loss: 1088.7014\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 114.2546 - val_loss: 1357.3487\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 99.2429 - val_loss: 866.3746\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 1s 877us/step - loss: 116.6180 - val_loss: 905.5358\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 109.8609 - val_loss: 1220.6726\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 1s 849us/step - loss: 106.1695 - val_loss: 946.0404\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 118.3470 - val_loss: 1872.1847\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 119.8311 - val_loss: 780.9643\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 1s 837us/step - loss: 128.5204 - val_loss: 841.1479\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 116.6944 - val_loss: 1280.1146\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 110.0442 - val_loss: 1198.2487\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 1s 962us/step - loss: 103.5017 - val_loss: 1172.5086\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 1s 937us/step - loss: 119.3097 - val_loss: 1016.6050\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 113.0338 - val_loss: 1457.6943\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 108.6356- ETA: 0s - loss: 112. - 1s 887us/step - loss: 108.3110 - val_loss: 881.3259\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 114.0366 - val_loss: 497.7715\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 113.0808 - val_loss: 981.3303\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 99.3525 - val_loss: 1199.5914\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 104.3127 - val_loss: 1076.3005\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 103.7969 - val_loss: 884.0015\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 112.7090 - val_loss: 1101.4755\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 111.7208 - val_loss: 1401.1174\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 100.9650 - val_loss: 1401.6679\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 104.0647 - val_loss: 1594.1555\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 110.8560 - val_loss: 1238.9608\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 115.7945 - val_loss: 1147.0394\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 100.6666 - val_loss: 993.8898\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 122.8882 - val_loss: 889.3583\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 105.3012 - val_loss: 850.2504\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 119.3356 - val_loss: 1125.2930\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 108.9496 - val_loss: 1497.2822\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 105.0442 - val_loss: 1487.2059\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 105.2924 - val_loss: 990.7859\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 126.2873 - val_loss: 1099.2947\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 105.1422 - val_loss: 1083.5910\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 757us/step - loss: 98.2221 - val_loss: 1152.6187\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 137.8692 - val_loss: 1358.7062\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 121.2027 - val_loss: 1190.4169\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 109.8272 - val_loss: 1171.6028\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 104.5655 - val_loss: 1046.2449\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 102.8582 - val_loss: 852.5467\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 103.7886 - val_loss: 873.8003\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 99.4983 - val_loss: 1229.0144\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 94.3901 - val_loss: 1306.1045\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 95.8433 - val_loss: 961.7438\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 129.2807 - val_loss: 1002.8072\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 123.2320 - val_loss: 826.3806\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 105.7935 - val_loss: 1178.3464\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 116.2569 - val_loss: 932.8436\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 109.3738 - val_loss: 986.5216\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 96.7109 - val_loss: 1105.9764\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 120.2398 - val_loss: 1580.5857\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 102.8079 - val_loss: 1030.1542\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 95.0282 - val_loss: 970.6926\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 100.1217 - val_loss: 905.7918\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 99.0131 - val_loss: 1118.0171\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 109.4319 - val_loss: 1285.9164\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 98.6918 - val_loss: 929.8677\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 102.9537 - val_loss: 1236.9857\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 95.1755 - val_loss: 764.7859\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 111.7151 - val_loss: 1315.7801\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 112.4785 - val_loss: 648.6704\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 101.4614 - val_loss: 1054.6933\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 104.1482 - val_loss: 1008.4827\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 98.3567 - val_loss: 1113.1599\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 110.9405 - val_loss: 1068.7129\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 104.1371 - val_loss: 1047.2465\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 93.5591 - val_loss: 1128.5836\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 95.7664 - val_loss: 837.2493\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 124.8140 - val_loss: 1165.8221\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 119.4583 - val_loss: 1363.9169\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 97.5994 - val_loss: 791.4178\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 112.0732 - val_loss: 760.1477\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 114.1243 - val_loss: 951.1603\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 109.2677 - val_loss: 1328.3421\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 110.6718 - val_loss: 823.3312\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 104.3089 - val_loss: 1308.1722\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 104.5999 - val_loss: 1337.6810\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 105.2825 - val_loss: 817.2239\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 96.6718 - val_loss: 962.9379\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 100.4037 - val_loss: 1067.0341\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 91.8932 - val_loss: 1285.9782\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 93.6987 - val_loss: 867.6858\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 88.6129 - val_loss: 844.4400\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 100.6909 - val_loss: 727.9794\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 103.3256 - val_loss: 1063.4467\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 108.9608 - val_loss: 1430.9778\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 109.0864 - val_loss: 1105.1222\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 103.6912 - val_loss: 1255.9972\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 101.4540 - val_loss: 777.2528\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 99.8619 - val_loss: 1020.2481\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 108.6753 - val_loss: 1122.7021\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 92.3888 - val_loss: 1074.1401\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 91.2673 - val_loss: 1129.6094\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 94.4091 - val_loss: 828.5053\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 100.7739 - val_loss: 722.5312\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 100.8708 - val_loss: 910.3958\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 110.6165 - val_loss: 1171.3184\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 126.3738 - val_loss: 965.6920\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 90.9640 - val_loss: 1113.2260\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 94.0136 - val_loss: 984.8273\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 88.5470 - val_loss: 917.0155\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 97.9184 - val_loss: 556.8303\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 127.4241 - val_loss: 709.3003\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 91.8996 - val_loss: 1319.0442\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 110.3609 - val_loss: 894.8695\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 105.5578 - val_loss: 656.2770\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 112.8087 - val_loss: 1279.8097\n",
      "Epoch 509/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 831us/step - loss: 102.1439 - val_loss: 897.4527\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 102.5607 - val_loss: 800.0387\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 94.1830 - val_loss: 965.7592\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 98.5286 - val_loss: 953.3431\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 102.2378 - val_loss: 1217.0298\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 92.6644 - val_loss: 1170.7934\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 101.0093 - val_loss: 707.0781\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 102.3672 - val_loss: 861.5997\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 97.0140 - val_loss: 996.9633\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 123.5462 - val_loss: 942.6034\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 93.5191 - val_loss: 1347.3280\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 103.5676 - val_loss: 1067.1674\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 87.0112 - val_loss: 735.0359\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 104.4696 - val_loss: 723.4176\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 102.4676 - val_loss: 1081.3674\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 92.4686 - val_loss: 936.9600\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 97.9792 - val_loss: 620.0979\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 90.5986 - val_loss: 1203.3462\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 107.6734 - val_loss: 924.4432\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 100.9000 - val_loss: 770.0052\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 88.3791 - val_loss: 891.3166\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 96.2049 - val_loss: 727.1621\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 102.6124 - val_loss: 977.9093\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 114.3290 - val_loss: 1093.1649\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 114.8982 - val_loss: 599.7439\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 93.8891 - val_loss: 1018.2154\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 94.6908 - val_loss: 670.0205\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 105.7156 - val_loss: 868.4249\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 112.0746 - val_loss: 901.1519\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 95.2287 - val_loss: 948.6206\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 109.4676 - val_loss: 1327.1632\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 104.0986 - val_loss: 1198.2480\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 95.2669 - val_loss: 1111.3959\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 90.6898 - val_loss: 801.0092\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 103.1347 - val_loss: 660.3569\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 105.2450 - val_loss: 1122.3414\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 129.1666 - val_loss: 1351.6299\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 95.3833 - val_loss: 897.0776\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 97.3559 - val_loss: 1179.0433\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 92.6422 - val_loss: 888.9956\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 88.5208 - val_loss: 1154.9090\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 89.2518 - val_loss: 713.0489\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 1s 832us/step - loss: 107.8781 - val_loss: 745.9810\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 97.0663 - val_loss: 827.4122\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 104.6030 - val_loss: 770.9741\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 91.8604 - val_loss: 965.9451\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 87.2678 - val_loss: 1017.9924\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 86.1802 - val_loss: 1118.1120\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 103.9733 - val_loss: 901.3962\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 98.3157 - val_loss: 730.6976\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 92.5348 - val_loss: 1130.6500\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 102.6513 - val_loss: 871.5578\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 94.5573 - val_loss: 855.0047\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 97.8567 - val_loss: 1061.4631\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 113.0527 - val_loss: 1028.2068\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 110.4833 - val_loss: 584.0570\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 97.9224 - val_loss: 961.5829\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 96.9614 - val_loss: 849.7960\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 98.1601 - val_loss: 750.2892\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 107.4867 - val_loss: 837.2441\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 95.0153 - val_loss: 1182.6881\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 92.4200 - val_loss: 930.9196\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 96.1665 - val_loss: 884.6086\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 104.8413 - val_loss: 816.6570\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 92.1401 - val_loss: 1019.7514\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 94.8492 - val_loss: 790.7526\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 87.3723 - val_loss: 912.6287\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 88.6517 - val_loss: 760.0973\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 92.7861 - val_loss: 956.6988\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 96.5471 - val_loss: 812.0110\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 96.7800 - val_loss: 660.1093\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 116.5195 - val_loss: 621.2032\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 107.4703 - val_loss: 932.6364\n",
      "Epoch 582/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 774us/step - loss: 105.8559 - val_loss: 685.0071\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 84.3330 - val_loss: 756.7840\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 83.1490 - val_loss: 727.6812\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 100.1010 - val_loss: 756.7680\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 92.9607 - val_loss: 786.4417\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 82.2447 - val_loss: 1075.8783\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 93.3004 - val_loss: 793.0435\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 98.7055 - val_loss: 886.1716\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 100.1008 - val_loss: 1070.7700\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 99.2609 - val_loss: 633.5687\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 1s 928us/step - loss: 96.2562 - val_loss: 887.2786\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 88.0637 - val_loss: 530.4592\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 94.8933 - val_loss: 1045.3736\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 94.3439 - val_loss: 862.7165\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 90.0488 - val_loss: 1042.4486\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 96.9438 - val_loss: 1022.4773\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 85.1275 - val_loss: 790.9889\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 86.1937 - val_loss: 593.4079\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 91.6089 - val_loss: 1006.0360\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 106.4624 - val_loss: 747.4823\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 96.1265 - val_loss: 952.0333\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 98.0354 - val_loss: 936.0084\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 1s 824us/step - loss: 87.7295 - val_loss: 869.0323\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 93.1004 - val_loss: 1274.9215\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 99.1022 - val_loss: 1160.5375\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 98.0063 - val_loss: 763.6011\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 98.0472 - val_loss: 741.6567\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 109.8899 - val_loss: 688.5133\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 91.3760 - val_loss: 725.2768\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 107.6072 - val_loss: 493.1688\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 89.6187 - val_loss: 634.1822\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 83.6894 - val_loss: 1029.3195\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 97.2432 - val_loss: 639.5323\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 93.5252 - val_loss: 1039.1068\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 83.2125 - val_loss: 690.9573\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 89.6737 - val_loss: 987.5781\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 90.4716 - val_loss: 726.5839\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 95.5823 - val_loss: 629.3396\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 89.1519 - val_loss: 757.1203\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 93.0776 - val_loss: 669.8869\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 96.2645 - val_loss: 857.5283\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 103.2440 - val_loss: 1125.4709\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 98.3794 - val_loss: 802.7272\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 95.8288 - val_loss: 869.5534\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 99.3620 - val_loss: 1054.2173\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 92.4415 - val_loss: 1069.1017\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 97.2572 - val_loss: 876.7374\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 92.0137 - val_loss: 971.8060\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 96.0686 - val_loss: 923.1129\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 94.9631 - val_loss: 883.3114\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 85.7221 - val_loss: 1092.2240\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 1s 814us/step - loss: 96.1776 - val_loss: 848.9706\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 87.1472 - val_loss: 724.5153\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 95.7971 - val_loss: 511.1341\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 100.4566 - val_loss: 800.8706\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 78.4738 - val_loss: 1077.5380\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 97.5089 - val_loss: 1282.2539\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 89.7249 - val_loss: 1205.1677\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 102.7673 - val_loss: 615.5673\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 101.3835 - val_loss: 986.1711\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 96.0655 - val_loss: 783.4446\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 82.9558 - val_loss: 725.0326\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 1s 843us/step - loss: 85.7804 - val_loss: 802.8121\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 81.7010 - val_loss: 809.4384\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 90.4199 - val_loss: 662.0253\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 89.9086 - val_loss: 1048.0301\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 100.9287 - val_loss: 661.0932\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 106.7548 - val_loss: 921.6205\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 101.0308 - val_loss: 859.6918\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 78.6732 - val_loss: 938.8882\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 88.7670 - val_loss: 710.1293\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 87.6119 - val_loss: 919.0199\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 87.0934 - val_loss: 527.0343\n",
      "Epoch 655/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 727us/step - loss: 101.6966 - val_loss: 479.0034\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 104.9360 - val_loss: 1340.4105\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 1s 806us/step - loss: 94.7830 - val_loss: 665.8995\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 94.4072 - val_loss: 858.7186\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 86.2112 - val_loss: 660.0452\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 90.2254 - val_loss: 488.5865\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 96.2341 - val_loss: 1070.9087\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 93.6058 - val_loss: 900.2891\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 89.1562 - val_loss: 942.7277\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 104.2627 - val_loss: 946.2283\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 92.0137 - val_loss: 757.5845\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 93.2106 - val_loss: 774.3911\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 72.2050 - val_loss: 843.7504\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 82.4048 - val_loss: 698.0498\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 95.2273 - val_loss: 518.0408\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 94.1721 - val_loss: 469.5099\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 87.2516 - val_loss: 536.1161\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 93.8357 - val_loss: 745.8842\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 92.5861 - val_loss: 649.5393\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 77.9383 - val_loss: 885.2369\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 85.2845 - val_loss: 689.2566\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 88.7361 - val_loss: 860.3303\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 85.2594 - val_loss: 578.2252\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 94.4053 - val_loss: 685.3460\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 84.6881 - val_loss: 575.7975\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 77.9550 - val_loss: 849.5067\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 77.2726 - val_loss: 905.9490\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 87.3710 - val_loss: 773.0047\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 91.5841 - val_loss: 806.2791\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 1s 804us/step - loss: 90.8292 - val_loss: 713.2838\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 91.0813 - val_loss: 939.8210\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 94.4387 - val_loss: 747.5221\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 85.4753 - val_loss: 711.8191\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 83.9329 - val_loss: 777.3163\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 87.1940 - val_loss: 601.9573\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 81.4567 - val_loss: 888.2054\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 103.2120 - val_loss: 1059.3051\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 95.4662 - val_loss: 753.3534\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 87.3615 - val_loss: 779.6970\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 82.0606 - val_loss: 837.6474\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 83.9110 - val_loss: 1152.4971\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 87.6791 - val_loss: 1115.5722\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 86.4152 - val_loss: 813.0677\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 84.4421 - val_loss: 543.1603\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 103.4730 - val_loss: 481.2711\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 102.4418 - val_loss: 835.5078\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 88.1969 - val_loss: 813.6010\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 79.0020 - val_loss: 765.2903\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 87.5534 - val_loss: 948.4775\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 1s 727us/step - loss: 96.5353 - val_loss: 631.4812\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 88.8765 - val_loss: 650.8001\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 80.3472 - val_loss: 908.6571\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 92.5560 - val_loss: 1081.4918\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 87.7494 - val_loss: 803.9076\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 83.7393 - val_loss: 956.2571\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 1s 750us/step - loss: 94.7925 - val_loss: 741.2446\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 83.9104 - val_loss: 934.0633\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 97.1320 - val_loss: 1004.2212\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 82.7842 - val_loss: 770.9509\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 87.9096 - val_loss: 856.6258\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 89.3654 - val_loss: 1122.1678\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 92.5119 - val_loss: 1196.5473\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 1s 791us/step - loss: 78.5466 - val_loss: 951.7883\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 103.7537 - val_loss: 855.9502\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 80.7613 - val_loss: 733.1217\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 91.0351 - val_loss: 743.6870\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 80.8413 - val_loss: 873.6434\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 84.8137 - val_loss: 864.4468\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 90.2016 - val_loss: 809.0899\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 89.2979 - val_loss: 605.7854\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 101.6966 - val_loss: 907.0806\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 106.9769 - val_loss: 871.4683\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 1s 812us/step - loss: 88.1196 - val_loss: 1008.0664\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 809us/step - loss: 77.9194 - val_loss: 1101.2737\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 91.7538 - val_loss: 1013.3945\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 91.8142 - val_loss: 930.2810\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 77.0418 - val_loss: 556.0595\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 88.8642 - val_loss: 922.1539\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 90.5456 - val_loss: 746.8547\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 1s 733us/step - loss: 82.5797 - val_loss: 749.2049\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 93.8934 - val_loss: 907.2991\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 91.4298 - val_loss: 433.8170\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 93.6489 - val_loss: 717.8152\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 83.1390 - val_loss: 609.0665\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 87.9946 - val_loss: 1127.4287\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 85.8109 - val_loss: 618.5157\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 77.8547 - val_loss: 603.9972\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 90.6869 - val_loss: 768.7257\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 79.2464 - val_loss: 570.5675\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 81.1704 - val_loss: 680.4799\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 95.0802 - val_loss: 912.6810\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 82.1021 - val_loss: 548.6720\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 88.3968 - val_loss: 1108.3272\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 88.5493 - val_loss: 598.3259\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 80.1630 - val_loss: 933.3631\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 84.6711 - val_loss: 804.8052\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 92.8718 - val_loss: 882.2087\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 1s 841us/step - loss: 85.9243 - val_loss: 847.3282\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 85.9175 - val_loss: 756.8226\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 85.2769 - val_loss: 1177.3849\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 1s 820us/step - loss: 87.5072 - val_loss: 877.7811\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 100.2808 - val_loss: 694.6902\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 88.8136 - val_loss: 755.9130\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 83.0254 - val_loss: 765.0539\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 83.7126 - val_loss: 827.8104\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 83.6220 - val_loss: 744.5009\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 87.1366 - val_loss: 522.8865\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 83.1729 - val_loss: 893.2275\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 82.1080 - val_loss: 628.8490\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 80.0728 - val_loss: 1081.0120\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 94.5673 - val_loss: 777.0603\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 86.0324 - val_loss: 780.3617\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 87.8998 - val_loss: 710.8635\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 97.8185 - val_loss: 698.2040\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 78.0861 - val_loss: 959.7789\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 1s 752us/step - loss: 86.5576 - val_loss: 807.8830\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 85.3689 - val_loss: 936.3714\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 91.6668 - val_loss: 1066.5306\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 86.9514 - val_loss: 934.9390\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 1s 786us/step - loss: 84.4111 - val_loss: 958.0926\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 76.8570 - val_loss: 954.1537\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 80.0614 - val_loss: 1142.7647\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 78.5905 - val_loss: 674.6695\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 1s 727us/step - loss: 79.3481 - val_loss: 760.2789\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 80.3231 - val_loss: 871.7358\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 77.3183 - val_loss: 609.6245\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 82.8296 - val_loss: 1039.3784\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 78.4377 - val_loss: 909.4374\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 79.3199 - val_loss: 884.4281\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 79.3159 - val_loss: 1009.7436\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 96.0865 - val_loss: 1030.6943\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 95.2382 - val_loss: 947.7653\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 85.7211 - val_loss: 1069.3511\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 77.1194 - val_loss: 897.2035\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 1s 770us/step - loss: 81.3377 - val_loss: 854.7723\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 91.5212 - val_loss: 1132.5011\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 99.0391 - val_loss: 808.4081\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 85.4702 - val_loss: 657.3911\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 77.8455 - val_loss: 681.5709\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 88.5255 - val_loss: 1035.5153\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 85.4589 - val_loss: 952.1837\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 84.6067 - val_loss: 873.7343\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 80.1624 - val_loss: 855.7690\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 80.3685 - val_loss: 776.6131\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 81.6388 - val_loss: 642.0180\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 66.3470 - val_loss: 909.8874\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 94.7740 - val_loss: 1028.6592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 86.6908 - val_loss: 751.3616\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 75.8758 - val_loss: 660.9816\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 82.5482 - val_loss: 695.3040\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 89.2163 - val_loss: 786.6302\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 82.8263 - val_loss: 839.6052\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 1s 826us/step - loss: 74.9848 - val_loss: 798.7272\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 85.8807 - val_loss: 637.9236\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 79.0828 - val_loss: 915.8971\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 78.0726 - val_loss: 724.2420\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 90.1026 - val_loss: 730.5143\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 1s 768us/step - loss: 82.7997 - val_loss: 875.1906\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 80.0779 - val_loss: 911.7936\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 86.6485 - val_loss: 585.5596\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 89.8187 - val_loss: 911.5759\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 84.4889 - val_loss: 771.2685\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 1s 784us/step - loss: 82.2467 - val_loss: 468.5708\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 88.3839 - val_loss: 697.8383\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 77.1864 - val_loss: 928.5941\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 88.0373 - val_loss: 765.6360\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 1s 822us/step - loss: 78.1731 - val_loss: 616.2247\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 77.8572 - val_loss: 610.6289\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 79.4945 - val_loss: 649.0170\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 76.0260 - val_loss: 780.7057\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 85.2562 - val_loss: 519.2512\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 88.4367 - val_loss: 1018.2829\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 74.4953 - val_loss: 720.4038\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 83.9640 - val_loss: 703.2055\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 1s 774us/step - loss: 101.1596 - val_loss: 452.8057\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 101.5220 - val_loss: 764.3361\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 91.3674 - val_loss: 889.4828\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 77.2131 - val_loss: 820.7216\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 83.1482 - val_loss: 1079.7582\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 78.8024 - val_loss: 766.8609\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 95.7104 - val_loss: 845.3527\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 90.9295 - val_loss: 918.3862\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 71.8289 - val_loss: 669.1362\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 76.6474 - val_loss: 612.5291\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 76.7542 - val_loss: 508.3209\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 85.4161 - val_loss: 1039.9391\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 86.0650 - val_loss: 822.6409\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 75.5790 - val_loss: 753.4000\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 1s 765us/step - loss: 78.7568 - val_loss: 835.5104\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 80.2672 - val_loss: 818.7227\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 85.4326 - val_loss: 802.9358\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 1s 892us/step - loss: 92.1167 - val_loss: 1072.8314\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 96.1967 - val_loss: 717.5931\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 87.9368 - val_loss: 790.2337\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 94.5459 - val_loss: 750.5978\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 80.7216 - val_loss: 932.3833\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 85.1817 - val_loss: 778.2054\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 83.9150 - val_loss: 731.2049\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 77.3569 - val_loss: 678.5442\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 79.9890 - val_loss: 506.6324\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 73.5934 - val_loss: 898.4586\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 1s 779us/step - loss: 69.8874 - val_loss: 880.2439\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 77.6935 - val_loss: 1135.3509\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 79.8751 - val_loss: 774.4284\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 80.5068 - val_loss: 739.2394\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 79.1332 - val_loss: 738.2230\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 85.6221 - val_loss: 745.6191\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 89.6784 - val_loss: 601.8864\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 1s 809us/step - loss: 77.5306 - val_loss: 530.5283\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 77.9050 - val_loss: 847.9864\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 75.4495 - val_loss: 633.9237\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 81.0154 - val_loss: 773.4141\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 1s 724us/step - loss: 89.2987 - val_loss: 502.6070\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 86.3999 - val_loss: 659.2319\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 74.1790 - val_loss: 718.5915\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 84.2521 - val_loss: 943.4445\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 77.3328 - val_loss: 592.8860\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 83.9966 - val_loss: 617.6279\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 1s 790us/step - loss: 85.6000 - val_loss: 776.2140\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 1s 831us/step - loss: 84.0722 - val_loss: 1175.2214\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 790us/step - loss: 84.4368 - val_loss: 871.3933\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 81.3116 - val_loss: 1023.1147\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 1s 914us/step - loss: 80.7757 - val_loss: 881.1901\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 80.6397 - val_loss: 621.9718\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 86.8316 - val_loss: 627.2440\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 1s 833us/step - loss: 86.7079 - val_loss: 945.2624\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 1s 911us/step - loss: 72.0769 - val_loss: 1044.5453\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 1s 957us/step - loss: 87.4011 - val_loss: 772.7473\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 1s 924us/step - loss: 76.3159 - val_loss: 877.7069\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 87.9472 - val_loss: 925.9749\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 1s 887us/step - loss: 80.4731 - val_loss: 1061.7027\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 83.1852 - val_loss: 741.8024\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 1s 900us/step - loss: 76.9219 - val_loss: 589.5997\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 88.1057 - val_loss: 573.2746\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 1s 878us/step - loss: 81.7723 - val_loss: 857.7550\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 84.6231 - val_loss: 1333.4501\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 85.7267 - val_loss: 720.4335\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 78.7405 - val_loss: 806.2548\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 72.0957 - val_loss: 1112.8976\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 92.4040 - val_loss: 527.6099\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 79.0674 - val_loss: 616.9543\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 83.4720 - val_loss: 783.7533\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 1s 894us/step - loss: 80.1624 - val_loss: 632.3717\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 83.4043 - val_loss: 669.2982\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 1s 890us/step - loss: 77.5849 - val_loss: 751.5066\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 77.4630 - val_loss: 510.9278\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 80.1750 - val_loss: 669.3991\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 89.0491 - val_loss: 447.0998\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 1s 707us/step - loss: 75.8083 - val_loss: 555.8345\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 1s 766us/step - loss: 82.4806 - val_loss: 882.3664\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 1s 711us/step - loss: 81.2840 - val_loss: 709.8591\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 1s 783us/step - loss: 81.7221 - val_loss: 403.2366\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 86.7289 - val_loss: 925.2755\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 1s 715us/step - loss: 86.5663 - val_loss: 826.0758\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 1s 756us/step - loss: 98.8904 - val_loss: 924.5697\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 1s 709us/step - loss: 84.2509 - val_loss: 696.5746\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 77.8770 - val_loss: 688.0854\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 91.6320 - val_loss: 738.7256\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 90.7352 - val_loss: 1051.8195\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 78.6040 - val_loss: 664.2166\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 75.1388 - val_loss: 728.8415\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 83.9924 - val_loss: 568.4515\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 78.2389 - val_loss: 667.3322\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 77.2783 - val_loss: 668.3084\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 86.0512 - val_loss: 1009.6259\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 1s 737us/step - loss: 85.7874 - val_loss: 719.1408\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 73.5289 - val_loss: 420.8350\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 1s 735us/step - loss: 91.3669 - val_loss: 1205.6743\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 87.2306 - val_loss: 907.6407\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 1s 782us/step - loss: 80.0746 - val_loss: 1104.6795\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 81.3442 - val_loss: 653.9733\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 82.1446 - val_loss: 908.9873\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 1s 793us/step - loss: 89.7255 - val_loss: 1109.1959\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 89.1446 - val_loss: 916.5472\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 81.6681 - val_loss: 799.6104\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 1s 819us/step - loss: 81.3997 - val_loss: 757.4591\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 75.8614 - val_loss: 825.6496\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 74.9970 - val_loss: 743.6938\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 84.6869 - val_loss: 756.7555\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 79.4111 - val_loss: 625.9434\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 1s 754us/step - loss: 87.2348 - val_loss: 855.6844\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 84.3381 - val_loss: 725.3561\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 74.8380 - val_loss: 696.4027\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 80.9471 - val_loss: 784.5667\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 73.8492 - val_loss: 776.7661\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 87.5609 - val_loss: 679.0350\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 82.6073 - val_loss: 582.3267\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 1s 877us/step - loss: 86.0611 - val_loss: 723.6548\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 81.2232 - val_loss: 741.0416\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 77.1505 - val_loss: 484.5933\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 80.3546 - val_loss: 596.8567\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 76.8831 - val_loss: 657.5192\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 83.3433 - val_loss: 661.5015\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 75.0912 - val_loss: 819.2764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 1s 876us/step - loss: 77.1347 - val_loss: 495.6403\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 84.0747 - val_loss: 714.4492\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 1s 878us/step - loss: 79.1346 - val_loss: 581.9068\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 1s 982us/step - loss: 74.9145 - val_loss: 836.3777\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 1s 951us/step - loss: 88.9484 - val_loss: 946.5771\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 1s 906us/step - loss: 84.2724 - val_loss: 848.8295\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 1s 928us/step - loss: 84.8238 - val_loss: 806.0796\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 74.9300 - val_loss: 898.4601\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 1s 823us/step - loss: 85.6255 - val_loss: 784.4401\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 85.8725 - val_loss: 928.6715\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 1s 930us/step - loss: 86.9266 - val_loss: 1134.1329\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 1s 881us/step - loss: 79.3766 - val_loss: 926.7108\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 1s 880us/step - loss: 104.2467 - val_loss: 585.3453\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 1s 911us/step - loss: 78.6916 - val_loss: 770.6531\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 76.8743 - val_loss: 751.4113\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 1s 925us/step - loss: 86.2714 - val_loss: 655.9765\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 1s 840us/step - loss: 83.9593 - val_loss: 468.8029\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 85.0194 - val_loss: 802.7817\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 1s 852us/step - loss: 75.0081 - val_loss: 774.6758\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 1s 780us/step - loss: 71.1151 - val_loss: 925.2650\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 83.1284 - val_loss: 750.4985\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 101.2061 - val_loss: 701.7511\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 67.8883 - val_loss: 816.2598\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 85.3280 - val_loss: 908.5575\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 1s 769us/step - loss: 85.7590 - val_loss: 1095.6992\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 80.6812 - val_loss: 569.5513\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 80.5405 - val_loss: 1183.2288\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 89.4283 - val_loss: 728.1819\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 1s 922us/step - loss: 81.4495 - val_loss: 1090.3951\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 79.4083 - val_loss: 862.5514\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 1s 764us/step - loss: 69.3947 - val_loss: 696.2238\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 85.9933 - val_loss: 895.7851\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 71.3406 - val_loss: 653.9361\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 71.1035 - val_loss: 650.8438\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 85.4604 - val_loss: 924.9953\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 70.7576 - val_loss: 700.3847\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 81.2359 - val_loss: 1034.2443\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 1s 921us/step - loss: 73.6232 - val_loss: 649.2650\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 1s 914us/step - loss: 66.2514 - val_loss: 738.4101\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 84.9288 - val_loss: 926.1979\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 84.7618 - val_loss: 807.7732\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 1s 880us/step - loss: 84.9553 - val_loss: 1017.1441\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 1s 932us/step - loss: 73.1610 - val_loss: 821.1636\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 80.7575 - val_loss: 1111.3784\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 1s 898us/step - loss: 69.8722 - val_loss: 661.1339\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 86.2005 - val_loss: 685.3943\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 1s 839us/step - loss: 85.6465 - val_loss: 892.1469\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 1s 964us/step - loss: 75.8326 - val_loss: 774.7687\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 1s 874us/step - loss: 74.6426 - val_loss: 694.7100\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 1s 886us/step - loss: 83.4490 - val_loss: 1119.4711\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 1s 886us/step - loss: 74.2671 - val_loss: 934.0826\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 1s 902us/step - loss: 75.1632 - val_loss: 887.2168\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 319us/step\n",
      "846.4523217773437\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "tb_hist= keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val), callbacks=[tb_hist])\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 2500.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv3d_2: expected ndim=5, found ndim=4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9bed931ba356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# 2. 모델 구성하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\keras_talk\\keras\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\keras_talk\\keras\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\keras_talk\\keras\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv3d_2: expected ndim=5, found ndim=4"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "import keras\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, (3, 3,3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(Conv3D(32, (3, 3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv3D(64, (3, 3,3), activation='relu'))\n",
    "model.add(Conv3D(64, (3, 3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv3D(64, (3, 3,3), activation='relu'))\n",
    "model.add(Conv3D(64, (3, 3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "tb_hist= keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val), callbacks=[tb_hist])\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 2500.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
